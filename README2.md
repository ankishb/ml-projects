#ml-projects

| Title        | DataSet           | Objective  |  Approach |
|:-------------|:-------------|:-----|:----|
| [Flipkart Object Detection](https://github.com/ankishb/ml-projects/tree/master/conditional-object-detection) | <ul><li>Image</li></ul> | <ul><li>Bounding Box prediction</li></ul> | <ul><li>+ Designed a visual feature pipeline with attention on the object in image</li><li>+ Data Augmentation Technique along with its bounding box</li><li>+ Used `Single Stage Detector` Approach</li><li>+ Focal Loss with `YOLO` and `SSD`</li></ul> |
| [Amazon Product Review classification](https://github.com/ankishb/ml-projects/tree/master/amazon-ml) | <ul><li>Text</li></ul> | <ul><li>Classification</li></ul> | <ul><li>Data Cleaning/feature enginnering</li><li>Linear/Non-Linear Model</li><li>`Deep Learning Attention Model`</li><li>`Pretrained Bert Model`</li><li>Ensemble</li></ul> |
| [Hike Friend Recommendation](https://github.com/ankishb/ml-projects/tree/master/hike-friend-recommendation) | <ul><li>+ Very big Dataset(45M observation, graph edge-representation)</li> <li>+ Relational Feature</li><li>+ Category + Numerical</li></ul> | <ul><li>Link Prediction</li></ul> | <ul><li>+ Graph Based features such as (`adamic-adar`, `common-resource-allocation`,...)</li> <li>+ `SVD` feature for each user</li><li>+ `Comunity-clustering`</li><li>+ `Subsemble`(I did this after competition is over, to understand more about sampling and model building)</li><li>+ `neighbour-based` feature(Removed highly cardinal feature)</li><li>+ Also tried `Deep learning approach` (Graph Embedding), but couldn't handle at that time properly</li></ul> |
| [HDFC Risk Prediction](https://github.com/ankishb/ml-projects/tree/master/hdfc-ml) | <ul><li>`2500` unknown predictors</li></ul> | <ul><li>Classification</li></ul> | <ul><li>Feature Understanding(`EDA`)</li><li>feature engineering</li><li>designed feature interaction tools</li><li>ensemble model using `xgboost/lighgbm/catboost` and `linear/non-linear` simple model</li><li>statistical model to understand the feature importance using `p-values`</li></ul> |
| [Club Mahindra Hotel Room Price Prediction](https://github.com/ankishb/ml-projects/tree/master/club-mahindra) | <ul><li>Category + Numerical</li><li>Relational Dataset</li></ul> | <ul><li>Regression</li></ul> | <ul><li>`date-time` based feature</li><li>`Aggregation` based feature</li><li>`Relational` Features</li><li>Ensemble using different set of `tranformed` target space</li></ul> |
| [Cifar-10 Classification using Conditional Feature](https://github.com/ankishb/ml-projects/tree/master/cifar-10-resnet) | <ul><li>Image</li></ul> | <ul><li>Comparison between ResNet and my modified feature pipeline</li><li>Classification</li></ul> | <ul><li>Developed a `weighted feature pipeline using global and local feature`.</li><li>`Global feature put constrained on local feature, to specifically focused on features of object` in image</li><li>`Better attention map around object`, which reflect its learned feature.</li><li>Improved score by `1.37%` over `Resnet`</li></ul> |
| [Facenet](https://github.com/ankishb/ml-projects/tree/master/facenet) | <ul><li>Image</li></ul> | <ul><li>Face Verification</li></ul> | <ul><li>`Matching Network Approach`</li><li>Build a `Student-Attentdance hardware using arduino`</li><li>`Hard Mining Approach`(generate all permutation between classes to handle small dataset)</li><li>`network-in-network` approach to handle overfitting as i have very small dataset.</li><li>Achieved `93%` accuracy</li></ul> |
| [Few Shot Learning(Prototype Network)](https://github.com/ankishb/ml-projects/tree/master/few-shot-classification) | <ul><li>Image</li></ul> | <ul><li>Classification (training on very small dataset)</li></ul> | <ul><li>`Prototype Algorithm` implementation</li><li>There is more to this(will update in future)</li></ul> |
| [Hackerearth Platform Recommendation System](https://github.com/ankishb/ml-projects/tree/master/recommendation-system) | <ul><li>Text</li></ul> | <ul><li>User-Problem Rating Prediction</li></ul> | <ul><li>My main concerns was to handle following question carefully:</li><li>What is the strongest and weakest area of user?</li><li>What is the level of problem?</li><li>What problem user have just solved?</li><li>If user gets stuck at current problem, what problem should help him(to gain confidence and to improve</li> skill in that area)?<li>Exploration and explotation strategy in recommending problem</li><li>And many more?</li></ul> |
| [JP.Morgan House Price Prediction](https://github.com/ankishb/ml-projects/tree/master/jp-morgan) | <ul><li>Category + Numerical</li></ul> | <ul><li>Regression</li></ul> | <ul><li>Date based feature and Dummy feature</li><li>`Interaction based feature` </li><li>`Bayesian optimization`</li><li>`out of fold prediction` to generate `Meta feature` for `ensemble`</li></ul> |
| [Stock Prediction](https://github.com/ankishb/ml-projects/tree/master/small-fun-project/collect-imp-tensor-spyder/time-series-prediction) | <ul><li>Time-Series stock prices</li></ul> | <ul><li>Future price prediction</li><li>Regression</li></ul> | <ul><li>Deep learning approach using RNN and LSTM</li></ul> |