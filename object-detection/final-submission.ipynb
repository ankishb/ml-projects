{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T00:18:52.056478",
     "start_time": "2018-04-04T00:18:50.879887"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard,ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import AveragePooling2D, Multiply, Concatenate, Add\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import os, cv2\n",
    "from preprocessing import BatchGenerator\n",
    "from utils import decode_netout, draw_boxes\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T00:18:52.075535",
     "start_time": "2018-04-04T00:18:52.057712"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test          = pd.read_csv('data/level3_data/test.csv')\n",
    "df               = pd.read_csv('data/level3_data/training_set.csv')\n",
    "\n",
    "train_dir        = 'data/train/images/'\n",
    "test_dir         = 'data/train/images/'\n",
    "LABELS           = ['obj']\n",
    "BOX              = 10\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3\n",
    "NMS_THRESHOLD    = 0.45\n",
    "ANCHORS          = [1.45,5.42, 2.03,2.28, 2.59,5.14, 3.87,2.99, 4.29,4.23, 4.30,5.98, 5.00,1.98, 5.92,3.04, 6.19,4.52, 6.29,6.20]\n",
    "IMAGE_H, IMAGE_W = 224, 224\n",
    "GRID_H,  GRID_W  = 7, 7\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "BATCH_SIZE       = 128\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 10#0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "# from preprocessing import parse_annotation\n",
    "import json\n",
    "\n",
    "argparser = argparse.ArgumentParser()\n",
    "\n",
    "argparser.add_argument(\n",
    "    '-c',\n",
    "    '--conf',\n",
    "    default='config.json',\n",
    "    help='path to configuration file')\n",
    "\n",
    "argparser.add_argument(\n",
    "    '-a',\n",
    "    '--anchors',\n",
    "    default=5,\n",
    "    help='number of anchors to use')\n",
    "\n",
    "def IOU(ann, centroids):\n",
    "    w, h = ann\n",
    "    similarities = []\n",
    "\n",
    "    for centroid in centroids:\n",
    "        c_w, c_h = centroid\n",
    "\n",
    "        if c_w >= w and c_h >= h:\n",
    "            similarity = w*h/(c_w*c_h)\n",
    "        elif c_w >= w and c_h <= h:\n",
    "            similarity = w*c_h/(w*h + (c_w-w)*c_h)\n",
    "        elif c_w <= w and c_h >= h:\n",
    "            similarity = c_w*h/(w*h + c_w*(c_h-h))\n",
    "        else: #means both w,h are bigger than c_w and c_h respectively\n",
    "            similarity = (c_w*c_h)/(w*h)\n",
    "        similarities.append(similarity) # will become (k,) shape\n",
    "\n",
    "    return np.array(similarities)\n",
    "\n",
    "def avg_IOU(anns, centroids):\n",
    "    n,d = anns.shape\n",
    "    sum = 0.\n",
    "\n",
    "    for i in range(anns.shape[0]):\n",
    "        sum+= max(IOU(anns[i], centroids))\n",
    "\n",
    "    return sum/n\n",
    "\n",
    "def print_anchors(centroids):\n",
    "    anchors = centroids.copy()\n",
    "\n",
    "    widths = anchors[:, 0]\n",
    "    sorted_indices = np.argsort(widths)\n",
    "\n",
    "    r = \"anchors: [\"\n",
    "    for i in sorted_indices[:-1]:\n",
    "        r += '%0.2f,%0.2f, ' % (anchors[i,0], anchors[i,1])\n",
    "\n",
    "    #there should not be comma after last anchor, that's why\n",
    "    r += '%0.2f,%0.2f' % (anchors[sorted_indices[-1:],0], anchors[sorted_indices[-1:],1])\n",
    "    r += \"]\"\n",
    "\n",
    "    print(r)\n",
    "    return r\n",
    "\n",
    "def run_kmeans(ann_dims, anchor_num):\n",
    "    ann_num = ann_dims.shape[0]\n",
    "    iterations = 0\n",
    "    prev_assignments = np.ones(ann_num)*(-1)\n",
    "    iteration = 0\n",
    "    old_distances = np.zeros((ann_num, anchor_num))\n",
    "\n",
    "    indices = [random.randrange(ann_dims.shape[0]) for i in range(anchor_num)]\n",
    "    centroids = ann_dims[indices]\n",
    "    anchor_dim = ann_dims.shape[1]\n",
    "\n",
    "    while True:\n",
    "        distances = []\n",
    "        iteration += 1\n",
    "        for i in range(ann_num):\n",
    "            d = 1 - IOU(ann_dims[i], centroids)\n",
    "            distances.append(d)\n",
    "        distances = np.array(distances) # distances.shape = (ann_num, anchor_num)\n",
    "\n",
    "        print(\"iteration {}: dists = {}\".format(iteration, np.sum(np.abs(old_distances-distances))))\n",
    "\n",
    "        #assign samples to centroids\n",
    "        assignments = np.argmin(distances,axis=1)\n",
    "\n",
    "        if (assignments == prev_assignments).all() :\n",
    "            return centroids\n",
    "\n",
    "        #calculate new centroids\n",
    "        centroid_sums=np.zeros((anchor_num, anchor_dim), np.float)\n",
    "        for i in range(ann_num):\n",
    "            centroid_sums[assignments[i]]+=ann_dims[i]\n",
    "        for j in range(anchor_num):\n",
    "            centroids[j] = centroid_sums[j]/(np.sum(assignments==j) + 1e-6)\n",
    "\n",
    "        prev_assignments = assignments.copy()\n",
    "        old_distances = distances.copy()\n",
    "       \n",
    "\n",
    "    \n",
    "    \n",
    "train_data_prepare = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    col = df.iloc[i]\n",
    "    one_file = {}\n",
    "    one_file['filename'] = train_dir + col['image_name']\n",
    "    one_file['width'] = 640\n",
    "    one_file['height'] = 480\n",
    "\n",
    "    one_file['object'] = []\n",
    "    inner_object = {}\n",
    "    inner_object['name'] = 'obj'\n",
    "    inner_object['xmin'] = col['x1']\n",
    "    inner_object['ymin'] = col['y1']\n",
    "    inner_object['xmax'] = col['x2']\n",
    "    inner_object['ymax'] = col['y2']\n",
    "    \n",
    "    \n",
    "    one_file['object'] = [inner_object]\n",
    "    train_data_prepare.append(one_file)\n",
    "    \n",
    "grid_h = GRID_H\n",
    "grid_w = GRID_W\n",
    "# run k_mean to find the anchors\n",
    "annotation_dims = []\n",
    "for image in train_data_prepare:\n",
    "    cell_w = image['width']/grid_w\n",
    "    cell_h = image['height']/grid_h\n",
    "    \n",
    "    for obj in image['object']:\n",
    "        relative_w = (float(obj['xmax']) - float(obj['xmin']))/cell_w\n",
    "        relatice_h = (float(obj[\"ymax\"]) - float(obj['ymin']))/cell_h\n",
    "        annotation_dims.append(tuple(map(float, (relative_w,relatice_h))))\n",
    "\n",
    "annotation_dims = np.array(annotation_dims)\n",
    "\n",
    "\n",
    "def print_anchors(centroids):\n",
    "    anchors = centroids.copy()\n",
    "\n",
    "    widths = anchors[:, 0]\n",
    "    sorted_indices = np.argsort(widths)\n",
    "\n",
    "    r = \"anchors: [\"\n",
    "    for i in sorted_indices[:-1]:\n",
    "        r += '%0.2f,%0.2f, ' % (anchors[i,0], anchors[i,1])\n",
    "\n",
    "    #there should not be comma after last anchor, that's why\n",
    "    r += '%0.2f,%0.2f' % (anchors[sorted_indices[-1:],0], anchors[sorted_indices[-1:],1])\n",
    "    r += \"]\"\n",
    "\n",
    "    print(r)\n",
    "    return r\n",
    "\n",
    "    \n",
    "num_anchors = 10\n",
    "centroids = run_kmeans(annotation_dims, num_anchors)\n",
    "\n",
    "# write anchors to file\n",
    "print('\\naverage IOU for', num_anchors, 'anchors:', '%0.2f' % avg_IOU(annotation_dims, centroids))\n",
    "ANCHORS = print_anchors(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put this printed anchor in the Anchor place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFeatureExtractor(object):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "\n",
    "    # to be defined in each subclass\n",
    "    def __init__(self, input_size):\n",
    "        raise NotImplementedError(\"error message\")\n",
    "\n",
    "    # to be defined in each subclass\n",
    "    def normalize(self, image):\n",
    "        raise NotImplementedError(\"error message\")       \n",
    "\n",
    "    def get_output_shape(self):\n",
    "        return self.feature_extractor.get_output_shape_at(-1)[1:3]\n",
    "\n",
    "    def extract(self, input_image):\n",
    "        return self.feature_extractor(input_image)\n",
    "\n",
    "    \n",
    "class MobileNetFeature(BaseFeatureExtractor):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        input_image = Input(shape=(input_size, input_size, 3))\n",
    "\n",
    "        mobilenet = MobileNet(input_shape=(224,224,3), include_top=False, weights=None)\n",
    "        x = mobilenet(input_image)\n",
    "        self.feature_extractor = Model(input_image, x)  \n",
    "\n",
    "    def normalize(self, image):\n",
    "        image = image / 255.\n",
    "        image = image - 0.5\n",
    "        image = image * 2.\n",
    "\n",
    "        return image\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "max_box_per_image = TRUE_BOX_BUFFER # ANCHORS * BOX\n",
    "nb_box = BOX\n",
    "nb_class = CLASS\n",
    "    \n",
    "input_image     = Input(shape=(input_size, input_size, 3), name='input_img')\n",
    "true_boxes = Input(shape=(1, 1, 1, max_box_per_image , 4))  \n",
    "\n",
    "\n",
    "def build_model(input_image, true_boxes):\n",
    "    input_size = 224\n",
    "    max_box_per_image = TRUE_BOX_BUFFER # ANCHORS * BOX\n",
    "    nb_box = BOX\n",
    "    nb_class = CLASS\n",
    "\n",
    "    feature_extractor = MobileNetFeature(input_size)\n",
    "\n",
    "    # print(feature_extractor.get_output_shape())    \n",
    "    grid_h, grid_w = feature_extractor.get_output_shape()        \n",
    "    features = feature_extractor.extract(input_image)            \n",
    "    ##################################################################\n",
    "\n",
    "    block_res1 = features\n",
    "\n",
    "    features_ = BatchNormalization()(block_res1)\n",
    "    features_ = Activation('relu')(features_)\n",
    "    features_ = Conv2D(256, (1, 1), \n",
    "                       padding='same',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l2(1e-4))(features_)\n",
    "    features_ = BatchNormalization()(features_)\n",
    "    features_ = Activation('relu')(features_)\n",
    "\n",
    "    features_ = Conv2D(256, (3, 3), \n",
    "                       padding='same',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l2(1e-4))(features_)\n",
    "    features_ = BatchNormalization()(features_)\n",
    "    features_ = Activation('relu')(features_)\n",
    "    #################################\n",
    "\n",
    "    block_res2 = features_\n",
    "    features_ = Conv2D(1024, (1, 1), \n",
    "                       padding='same',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l2(1e-4))(features_)\n",
    "\n",
    "    #################################\n",
    "    features_ = Add()([block_res1, features_])\n",
    "\n",
    "    features_ = Conv2D(256, (1, 1), \n",
    "                       padding='same',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l2(1e-4))(features_)\n",
    "    features_ = BatchNormalization()(features_)\n",
    "    features_ = Activation('relu')(features_)\n",
    "\n",
    "    features_ = Conv2D(256, (3, 3), \n",
    "                       padding='same',\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l2(1e-4))(features_)\n",
    "    #################################\n",
    "\n",
    "    new_block1 = features_\n",
    "    features_ = BatchNormalization()(features_)\n",
    "    features_ = Activation('relu')(features_)\n",
    "    new_block2 = features_\n",
    "    #################################\n",
    "\n",
    "    \n",
    "    #################################\n",
    "    # channel attention\n",
    "\n",
    "    c_global_feat = AveragePooling2D(pool_size=(7, 7))(new_block2)\n",
    "    c_global_feat = Conv2D(256, (1, 1), \n",
    "                           padding='same',\n",
    "                           kernel_initializer='he_normal',\n",
    "                           kernel_regularizer=l2(1e-4))(c_global_feat)\n",
    "    #     c_global_feat = BatchNormalization()(c_global_feat)\n",
    "    c_global_feat = Activation('relu')(c_global_feat)\n",
    "\n",
    "    c_global_feat = Conv2D(256, (1, 1), \n",
    "                           padding='same',\n",
    "                           kernel_initializer='he_normal',\n",
    "                           kernel_regularizer=l2(1e-4))(c_global_feat)\n",
    "    c_global_feat = Activation('sigmoid')(c_global_feat)\n",
    "\n",
    "    channel_weighted_feat = Multiply()([new_block2, c_global_feat])\n",
    "    channel_weighted_feat = Conv2D(256, (1, 1), \n",
    "                                   padding='same',\n",
    "                                   kernel_initializer='he_normal',\n",
    "                                   kernel_regularizer=l2(1e-4))(channel_weighted_feat)\n",
    "    #################################\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # spatial attention\n",
    "\n",
    "    s_global_feat = Conv2D(256, (1, 1), \n",
    "                           padding='same',\n",
    "                           kernel_initializer='he_normal',\n",
    "                           kernel_regularizer=l2(1e-4))(new_block2)\n",
    "    s_global_feat = Activation('relu')(s_global_feat)\n",
    "\n",
    "    s_global_feat = Conv2D(1, (1, 1), \n",
    "                           padding='same',\n",
    "                           kernel_initializer='he_normal',\n",
    "                           kernel_regularizer=l2(1e-4))(s_global_feat)\n",
    "    s_global_feat = Activation('sigmoid')(s_global_feat)\n",
    "\n",
    "    spatial_weighted_feat = Multiply()([new_block2, s_global_feat])\n",
    "    spatial_weighted_feat = Conv2D(256, (1, 1), \n",
    "                                   padding='same',\n",
    "                                   kernel_initializer='he_normal',\n",
    "                                   kernel_regularizer=l2(1e-4))(spatial_weighted_feat)\n",
    "    \n",
    "    #################################\n",
    "\n",
    "\n",
    "    #################################\n",
    "    # concat both attention features\n",
    "\n",
    "    concat_s_c_feat = Concatenate(axis=-1)([channel_weighted_feat, spatial_weighted_feat])\n",
    "    concat_s_c_feat = Conv2D(256, (1, 1), \n",
    "                             padding='same',\n",
    "                             kernel_initializer='he_normal',\n",
    "                             kernel_regularizer=l2(1e-4))(concat_s_c_feat)\n",
    "\n",
    "    final_feat = Add()([new_block1, concat_s_c_feat])\n",
    "\n",
    "    #################################\n",
    "    \n",
    "    x = final_feat\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    ##################################################################\n",
    "    # make the object detection layer\n",
    "    output = Conv2D(nb_box * (4 + 1 + nb_class), \n",
    "                    (1,1), strides=(1,1), \n",
    "                    padding='same', \n",
    "                    name='DetectionLayer', \n",
    "                    kernel_initializer='lecun_normal')(x)#(features)\n",
    "    output = Reshape((grid_h, grid_w, nb_box, 4 + 1 + nb_class))(output)\n",
    "\n",
    "    model = Model([input_image, true_boxes], output)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:34:28.064549Z",
     "start_time": "2017-11-26T12:34:27.800510Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, BOX, 1])\n",
    "    \n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    seen = tf.Variable(0.)\n",
    "    total_recall = tf.Variable(0.)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    ### adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "    \n",
    "    ### adjust confidence\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "    \n",
    "#     ### adjust class probabilities\n",
    "    pred_box_class = y_pred[..., 5:]\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "    \n",
    "    ### adjust confidence\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "    \n",
    "    true_box_conf = iou_scores * y_true[..., 4]\n",
    "    \n",
    "#     ### adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "    \n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "    \n",
    "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    \n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wh_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "    \n",
    "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "    \n",
    "#     ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n",
    "    \n",
    "    \"\"\"\n",
    "    Warm-up training\n",
    "    \"\"\"\n",
    "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "    \n",
    "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
    "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
    "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
    "                                   tf.ones_like(coord_mask)],\n",
    "                          lambda: [true_box_xy, \n",
    "                                   true_box_wh,\n",
    "                                   coord_mask])\n",
    "    \n",
    "    \"\"\"\n",
    "    Finalize the loss\n",
    "    \"\"\"\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "    \n",
    "    loss = 3*loss_xy + 3*loss_wh + 2.5*loss_conf + 1.5*loss_class\n",
    "    \n",
    "    nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
    "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:38:44.283547Z",
     "start_time": "2017-11-26T12:38:44.277155Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    'IMAGE_H'         : IMAGE_H, \n",
    "    'IMAGE_W'         : IMAGE_W,\n",
    "    'GRID_H'          : GRID_H,  \n",
    "    'GRID_W'          : GRID_W,\n",
    "    'BOX'             : BOX,\n",
    "    'LABELS'          : LABELS,\n",
    "    'CLASS'           : len(LABELS),\n",
    "    'ANCHORS'         : ANCHORS,\n",
    "    'BATCH_SIZE'      : BATCH_SIZE,\n",
    "    'TRUE_BOX_BUFFER' : TRUE_BOX_BUFFER,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return image / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_prepare = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    col = df.iloc[i]\n",
    "    one_file = {}\n",
    "    one_file['filename'] = train_dir + col['image_name']\n",
    "    one_file['width'] = 640\n",
    "    one_file['height'] = 480\n",
    "\n",
    "    one_file['object'] = []\n",
    "    inner_object = {}\n",
    "    inner_object['name'] = 'obj'\n",
    "    inner_object['xmin'] = col['x1']\n",
    "    inner_object['ymin'] = col['y1']\n",
    "    inner_object['xmax'] = col['x2']\n",
    "    inner_object['ymax'] = col['y2']\n",
    "    \n",
    "    \n",
    "    one_file['object'] = [inner_object]\n",
    "    train_data_prepare.append(one_file)\n",
    "\n",
    "len(train_data_prepare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add lvel2 data if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_aagin = pd.read_csv('/home/ankish1/ankish_save/yolo/data/training.csv')\n",
    "\n",
    "# train_dir = '/home/ankish1/ankish_save/yolo/data/train/images/'\n",
    "# # train_data_prepare = []\n",
    "\n",
    "# for i in range(df_aagin.shape[0]):\n",
    "#     col = df_aagin.iloc[i]\n",
    "#     one_file = {}\n",
    "#     one_file['filename'] = train_dir + col['image_name']\n",
    "#     one_file['width'] = 640\n",
    "#     one_file['height'] = 480\n",
    "\n",
    "#     one_file['object'] = []\n",
    "#     inner_object = {}\n",
    "#     inner_object['name'] = 'obj'\n",
    "#     inner_object['xmin'] = col['x1']\n",
    "#     inner_object['ymin'] = col['y1']\n",
    "#     inner_object['xmax'] = col['x2']\n",
    "#     inner_object['ymax'] = col['y2']\n",
    "    \n",
    "    \n",
    "#     one_file['object'] = [inner_object]\n",
    "#     train_data_prepare.append(one_file)\n",
    "\n",
    "# len(train_data_prepare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do split according"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22000, 2000, {'obj': 22000}, {'obj': 2000})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.random.permutation(len(train_data_prepare))\n",
    "train_idx = idx[:22000] # do split according \n",
    "val_idx = idx[22000:]\n",
    "\n",
    "train_imgs = [train_data_prepare[i] for i in train_idx]\n",
    "seen_train_labels = {}\n",
    "seen_train_labels['obj'] = len(train_imgs)\n",
    "\n",
    "valid_imgs = [train_data_prepare[i] for i in val_idx]\n",
    "seen_valid_labels = {}\n",
    "seen_valid_labels['obj'] = len(valid_imgs)\n",
    "\n",
    "len(train_imgs), len(valid_imgs), seen_train_labels, seen_valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:38:51.836129Z",
     "start_time": "2017-11-26T12:38:51.766843Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batch = BatchGenerator(train_imgs, generator_config, norm=normalize)\n",
    "valid_batch = BatchGenerator(valid_imgs, generator_config, norm=normalize, jitter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = BatchGenerator(train_imgs, generator_config, norm=None)\n",
    "# (i1, b1), g1 = temp.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check available gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=0.001, \n",
    "                           patience=5, \n",
    "                           mode='min', \n",
    "                           verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.2, \n",
    "                              patience=2, \n",
    "                              min_lr=1e-8) \n",
    "\n",
    "LOG_FILE_PATH = 'attention-2nd-{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "EPOCHS = 60\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=LOG_FILE_PATH, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = build_model(input_image, true_boxes)\n",
    "    print(\"built model successfully\")\n",
    "    \n",
    "    \n",
    "optimizer = Adam(lr=0.5e-2, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "parallel_model = multi_gpu_model(model, gpus=4)\n",
    "parallel_model.compile(loss = custom_loss,\n",
    "                       optimizer=optimizer)#,\n",
    "\n",
    "EPOCHS = 100\n",
    "print(\"let's start parallel model with 50 epochs\")\n",
    "parallel_model.fit_generator(generator        = train_batch, \n",
    "                             steps_per_epoch  = len(train_batch), \n",
    "                             epochs           = 100, \n",
    "                             verbose          = 1,\n",
    "                             validation_data  = valid_batch,\n",
    "                             validation_steps = len(valid_batch),\n",
    "                             callbacks        = [reduce_lr, early_stop, checkpoint],\n",
    "                             use_multiprocessing=True,\n",
    "                             workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('weights_last.npy', model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls1 = parallel_model.history.history['loss']\n",
    "val_ls1 = parallel_model.history.history['val_loss']\n",
    "lr1 = parallel_model.history.history['lr']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# increase lr_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999)\n",
    "parallel_model.compile(loss = custom_loss,\n",
    "                       optimizer=optimizer)#,\n",
    "\n",
    "print(\"let's start parallel model again for another 60 epochs\")\n",
    "parallel_model.fit_generator(generator        = train_batch, \n",
    "                             steps_per_epoch  = len(train_batch), \n",
    "                             epochs           = 60, \n",
    "                             verbose          = 1,\n",
    "                             validation_data  = valid_batch,\n",
    "                             validation_steps = len(valid_batch),\n",
    "                             callbacks        = [early_stop, checkpoint, reduce_lr],\n",
    "                             use_multiprocessing=True,\n",
    "                             workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls2 = parallel_model.history.history['loss']\n",
    "val_ls2 = parallel_model.history.history['val_loss']\n",
    "lr2 = parallel_model.history.history['lr']\n",
    "\n",
    "plt.plot(ls2)\n",
    "plt.plot(val_ls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-5, beta_1=0.9, beta_2=0.999)\n",
    "parallel_model.compile(loss = custom_loss,\n",
    "                       optimizer=optimizer)#,\n",
    "\n",
    "print(\"let's start parallel model again for another 50 epochs\")\n",
    "parallel_model.fit_generator(generator        = train_batch, \n",
    "                             steps_per_epoch  = len(train_batch), \n",
    "                             epochs           = 60, \n",
    "                             verbose          = 1,\n",
    "                             validation_data  = valid_batch,\n",
    "                             validation_steps = len(valid_batch),\n",
    "                             callbacks        = [early_stop, checkpoint, reduce_lr],\n",
    "                             use_multiprocessing=True,\n",
    "                             workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls3 = parallel_model.history.history['loss']\n",
    "val_ls3 = parallel_model.history.history['val_loss']\n",
    "lr3 = parallel_model.history.history['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ls1+ls2+ls3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_img, thresh=0.3):\n",
    "#     thresh = 0.3\n",
    "    image = cv2.imread(test_img)\n",
    "    input_image = cv2.resize(image, (224, 224))\n",
    "    input_image = input_image / 255.\n",
    "    input_image = input_image[:,:,::-1]\n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "    dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\n",
    "    \n",
    "    netout = parallel_model.predict([input_image, dummy_array])\n",
    "\n",
    "    boxes = decode_netout(netout[0], \n",
    "                          obj_threshold=thresh,#OBJ_THRESHOLD,\n",
    "                          nms_threshold=0.3,\n",
    "                          anchors=ANCHORS, \n",
    "                          nb_class=CLASS)\n",
    "    count = 1\n",
    "    while not boxes:\n",
    "        thresh = thresh -0.5*count\n",
    "        boxes = decode_netout(netout[0], \n",
    "                              obj_threshold=thresh,#OBJ_THRESHOLD,\n",
    "                              nms_threshold=0.3,\n",
    "                              anchors=ANCHORS, \n",
    "                              nb_class=CLASS)\n",
    "        count += 1\n",
    "    if len(boxes)>1:\n",
    "        score_ = boxes[0].get_score()\n",
    "        index_  = 0\n",
    "        for ii, bb in enumerate(boxes[1:]):\n",
    "            score_1 = bb.get_score()\n",
    "            if score_1>=score_:\n",
    "                index_ = ii+1\n",
    "                score_ = score_1\n",
    "#         print(index_)\n",
    "        return boxes[index_]\n",
    "    else:\n",
    "        return boxes\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "box_pred = []\n",
    "\n",
    "# test_dir = 'data/train/images/'\n",
    "# df_test = pd.read_csv('data/level3_data/test.csv')\n",
    "all_files = df_test['image_name'].values\n",
    "print(len(all_files))\n",
    "\n",
    "\n",
    "for ii, file_ in enumerate(all_files):\n",
    "    box_pred.append(predict(test_dir + file_, 0.4))\n",
    "    if (ii%2000) == 0:\n",
    "        print(\"done till {} images\".format(ii))\n",
    "        \n",
    "empty_pred_idx = []\n",
    "box_pred_values = []\n",
    "count = 0\n",
    "for ii, box_ in enumerate(box_pred):\n",
    "    image_h, image_w = 480, 640\n",
    "#     if not box_:\n",
    "#         print(ii)\n",
    "#         count += 1\n",
    "# count\n",
    "    if box_:\n",
    "        try:\n",
    "#             print(box_[0])\n",
    "            xmin = int(box_[0].xmin * image_w)\n",
    "            ymin = int(box_[0].ymin * image_h)\n",
    "            xmax = int(box_[0].xmax * image_w)\n",
    "            ymax = int(box_[0].ymax * image_h)\n",
    "        except:\n",
    "#             print(box_)\n",
    "            xmin = int(box_.xmin * image_w)\n",
    "            ymin = int(box_.ymin * image_h)\n",
    "            xmax = int(box_.xmax * image_w)\n",
    "            ymax = int(box_.ymax * image_h)\n",
    "\n",
    "    else:\n",
    "        empty_pred_idx.append(ii)\n",
    "        xmin, ymin, xmax, ymax = 999, 999, 999, 999#0, 0, 640, 480\n",
    "        print(\"====\",ii,\"====\")\n",
    "    box_pred_values.append((xmin, ymin, xmax, ymax))\n",
    "    \n",
    "    if ii%2000 == 0:\n",
    "        print(\"reached to {} boxes\".format(ii))\n",
    "    \n",
    "box_pred_values = np.array(box_pred_values)\n",
    "box_pred_values[3], box_pred_values.shape\n",
    "\n",
    "\n",
    "df_pred = pd.DataFrame(columns=['x1','y1','x2','y2'], data=box_pred_values)\n",
    "df_img = pd.DataFrame(data=all_files, columns=['image_name'])\n",
    "sub = pd.concat([df_img, df_pred['x1'], df_pred['x2'], df_pred['y1'], df_pred['y2']], axis=1)\n",
    "sub.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sub.x1 = np.where(sub.x1<-1,-1,sub.x1)\n",
    "sub.y1 = np.where(sub.y1<-1, -1, sub.y1)\n",
    "sub.x2 = np.where(sub.x2>640, 640, sub.x2)\n",
    "sub.y2 = np.where(sub.y2>480, 480, sub.y2)\n",
    "\n",
    "sub.to_csv('final-submission.csv',index=None)\n",
    "\n",
    "print(\"done with prediction step\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,6,figsize=(20,12))\n",
    "axes = ax.flatten()\n",
    "\n",
    "for i in range(24):\n",
    "    idx_r = np.random.randint(sub.shape[0])\n",
    "    # now\n",
    "    image = cv2.imread(test_dir + all_files[idx_r])\n",
    "    box__ = sub.iloc[idx_r]\n",
    "    xmin, ymin, xmax, ymax = box__['x1'], box__['y1'], box__['x2'],box__['y2']\n",
    "\n",
    "    image = cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (0,255,0), 3)\n",
    "    axes[i].imshow(image[:,:,::-1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {
    "height": "122px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "758px",
    "left": "0px",
    "right": "1096px",
    "top": "73px",
    "width": "253px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
