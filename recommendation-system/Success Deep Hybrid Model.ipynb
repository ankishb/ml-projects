{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Dense, Dropout\n",
    "from keras.layers import concatenate\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "M = 3\n",
    "K = 2\n",
    "N_u = 5\n",
    "M_v = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a_u and a_v as the tensor, because we are not sampling anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(N,M)\n",
    "a_u = np.random.randn(N,N_u)\n",
    "a_v = np.random.randn(M,M_v)\n",
    "\n",
    "# X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "a_u = tf.convert_to_tensor(a_u, dtype=tf.float32)\n",
    "a_v = tf.convert_to_tensor(a_v, dtype=tf.float32)\n",
    "\n",
    "\n",
    "def next_batch(batch_size):\n",
    "    '''\n",
    "    returnn data of shape [ [batch,N], [batch,M], [batch,1] ]\n",
    "    fetch index from the matrix of shape [batch,batch]\n",
    "    '''\n",
    "    x_idx = np.random.randint(N,size=(batch_size))\n",
    "    y_idx = np.random.randint(M,size=(batch_size))\n",
    "    \n",
    "    rating_label = []\n",
    "    for i,j in zip(x_idx,y_idx):\n",
    "        rating_label.append(X[i][j])\n",
    "#     rating_label = tf.convert_to_tensor(rating_label,dtype=tf.float32)\n",
    "#     rating_label = tf.reshape(rating_label,shape=[-1,1])\n",
    "    \n",
    "#     return Xn, Xm, rating_label\n",
    "    return x_idx, y_idx, rating_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_user = tf.placeholder(tf.int32,shape=(None,),name='batch-user')\n",
    "input_user_hot = tf.one_hot(input_user,N, name='one-hot-user')\n",
    "user_latent = Dense(K,activation='linear', name='user-latent')(input_user_hot)\n",
    "\n",
    "input_item = tf.placeholder(tf.int32,shape=(None,),name='batch-item')\n",
    "input_item_hot = tf.one_hot(input_item,M, name='one-hot-item')\n",
    "item_latent = Dense(K,activation='linear', name='item-latent')(input_item_hot)\n",
    "\n",
    "info_user = tf.matmul(input_user_hot, a_u)\n",
    "info_user_latent = Dense(K,activation='linear',name='info-user-latent')(info_user)\n",
    "\n",
    "info_item = tf.matmul(input_item_hot, a_v)\n",
    "info_item_latent = Dense(K,activation='linear', name='item-user-latent')(info_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'batch-user:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'user-latent/BiasAdd:0' shape=(?, 2) dtype=float32>,\n",
       " <tf.Tensor 'batch-item:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'item-latent/BiasAdd:0' shape=(?, 2) dtype=float32>,\n",
       " <tf.Tensor 'info-user-latent/BiasAdd:0' shape=(?, 2) dtype=float32>,\n",
       " <tf.Tensor 'item-user-latent/BiasAdd:0' shape=(?, 2) dtype=float32>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_user, user_latent, input_item, item_latent, info_user_latent, info_item_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rating = tf.matmul(user_latent,tf.transpose(item_latent))#,transpose_item_latent)\n",
    "pred_rating = tf.diag_part(pred_rating)\n",
    "pred_rating = tf.reshape(pred_rating,shape=[-1,1])\n",
    "\n",
    "pred_rating_content = tf.matmul(info_user_latent,tf.transpose(info_item_latent))#,transpose_info_item_latent)\n",
    "pred_rating_content = tf.diag_part(pred_rating_content)\n",
    "pred_rating_content = tf.reshape(pred_rating_content, shape=[-1,1])\n",
    "\n",
    "final_rating = pred_rating + pred_rating_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function (mse. no classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = tf.placeholder(tf.float32, shape=(None,),name='rating')\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(pred_rating - actual))\n",
    "loss_user = tf.reduce_mean(tf.square(user_latent - info_user_latent))\n",
    "loss_item = tf.reduce_mean(tf.square(item_latent - info_item_latent))\n",
    "final_loss = loss + loss_user + loss_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_2:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_3:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(final_loss)\n",
    "\n",
    "correct_pred = tf.equal(final_rating, actual)\n",
    "correct_pred = tf.cast(correct_pred, tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_pred)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 2.66976\n",
      "step 1, training accuracy 2.59278\n",
      "step 2, training accuracy 2.64909\n",
      "step 3, training accuracy 3.25894\n",
      "step 4, training accuracy 2.7083\n",
      "step 5, training accuracy 3.10092\n",
      "step 6, training accuracy 2.04663\n",
      "step 7, training accuracy 2.40559\n",
      "step 8, training accuracy 1.98688\n",
      "step 9, training accuracy 4.36548\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 2\n",
    "for i in range(10):\n",
    "    batch = next_batch(batch_size)\n",
    "    feed_data = {input_user : batch[0], input_item : batch[1], actual : batch[2]}\n",
    "#     if i % 2 == 0:\n",
    "#         train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1]})\n",
    "#         print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        \n",
    "    loss_iter = sess.run(final_loss,feed_dict=feed_data)\n",
    "    print('step %d, training accuracy %g' % (i, loss_iter))\n",
    "\n",
    "    sess.run(optimizer, feed_dict=feed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
