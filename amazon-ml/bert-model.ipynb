{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-06 15:09:14--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.200.176, 2404:6800:4002:811::2010\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.200.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 407727028 (389M) [application/zip]\n",
      "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
      "\n",
      "uncased_L-12_H-768_ 100%[===================>] 388.84M  3.63MB/s    in 1m 49s  \n",
      "\n",
      "2019-08-06 15:11:04 (3.57 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
      "\n",
      "--2019-08-06 15:11:04--  https://raw.githubusercontent.com/google-research/bert/master/modeling.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.152.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.152.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 37922 (37K) [text/plain]\n",
      "Saving to: ‘modeling.py’\n",
      "\n",
      "modeling.py         100%[===================>]  37.03K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2019-08-06 15:11:04 (437 KB/s) - ‘modeling.py’ saved [37922/37922]\n",
      "\n",
      "--2019-08-06 15:11:05--  https://raw.githubusercontent.com/google-research/bert/master/optimization.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.152.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.152.133|:443... connected.\n",
      "ERROR: cannot verify raw.githubusercontent.com's certificate, issued by ‘CN=ironport2.iitk.ac.in,OU=Computer Center,O=IIT Kanpur,C=IN’:\n",
      "  Self-signed certificate encountered.\n",
      "To connect to raw.githubusercontent.com insecurely, use `--no-check-certificate'.\n",
      "--2019-08-06 15:11:05--  https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.152.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.152.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34783 (34K) [text/plain]\n",
      "Saving to: ‘run_classifier.py’\n",
      "\n",
      "run_classifier.py   100%[===================>]  33.97K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2019-08-06 15:11:05 (820 KB/s) - ‘run_classifier.py’ saved [34783/34783]\n",
      "\n",
      "--2019-08-06 15:11:06--  https://raw.githubusercontent.com/google-research/bert/master/tokenization.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.152.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.152.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12257 (12K) [text/plain]\n",
      "Saving to: ‘tokenization.py’\n",
      "\n",
      "tokenization.py     100%[===================>]  11.97K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2019-08-06 15:11:06 (322 KB/s) - ‘tokenization.py’ saved [12257/12257]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/optimization.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_model\t       exploration.ipynb  __pycache__\r\n",
      "bert-model.ipynb       modeling.py\t  run_classifier.py\r\n",
      "Dataset\t\t       new_dataset\t  tokenization.py\r\n",
      "embedding-layer.ipynb  optimization.py\t  uncased_L-12_H-768_A-12.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Model output directory: bert_model/outputs\n",
      ">>  BERT pretrained directory: bert_model/uncased_L-12_H-768_A-12\n"
     ]
    }
   ],
   "source": [
    "import modeling\n",
    "import optimization\n",
    "import run_classifier\n",
    "import tokenization\n",
    "\n",
    "\n",
    "import zipfile\n",
    "folder = 'bert_model'\n",
    "# with zipfile.ZipFile(\"uncased_L-12_H-768_A-12.zip\",\"r\") as zip_ref:\n",
    "#     zip_ref.extractall(folder)\n",
    "\n",
    "\n",
    "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
    "BERT_PRETRAINED_DIR = f'{folder}/uncased_L-12_H-768_A-12'\n",
    "OUTPUT_DIR = f'{folder}/outputs'\n",
    "print(f'>> Model output directory: {OUTPUT_DIR}')\n",
    "print(f'>>  BERT pretrained directory: {BERT_PRETRAINED_DIR}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import gc, os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "sns.set(context='notebook', style='whitegrid', palette='deep', font='sans-serif', \n",
    "        font_scale=2, color_codes=True, rc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5959, 3), (2553, 2), (5, 3), (8512, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = pd.read_csv('Dataset/train.csv')\n",
    "# test  = pd.read_csv('Dataset/test.csv')\n",
    "# sub   = pd.read_csv('Dataset/Sample_Submission.csv')\n",
    "# df    = train.append(test,ignore_index=True)\n",
    "\n",
    "# train.shape, test.shape, sub.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8512, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import string\n",
    "# from nltk.corpus import stopwords\n",
    "# stop = stopwords.words('english')\n",
    "# punc = string.punctuation\n",
    "\n",
    "# df['word_count']   = df['Review Text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "# df['char_count']   = df['Review Text'].apply(len)\n",
    "# df['word_density'] = df['char_count'] / (df['word_count']+1)\n",
    "# df['stopw_count']  = df['Review Text'].apply(lambda x: len([w for w in x.split() if w in stop]))\n",
    "# df['punc_count']   = df['Review Text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in punc)))\n",
    "# df['num_count']    = df['Review Text'].apply(lambda x: len([w for w in x.split() if w.isdigit()]))\n",
    "\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Did', 'nothing', 'for', 'me,', \"didn't\", 'help', 'lost', 'even', 'with']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Review Text'][0].split(\" \")[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5959, 3), (2553, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('new_dataset/train.csv')\n",
    "test  = pd.read_csv('new_dataset/test.csv')\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'title', 'topic'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = train['topic'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5959, 21)\n",
      "(4767,) (1192,) (4767, 21) (1192, 21)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy import sparse\n",
    "# final_features = sparse.hstack((df_train[col],train_vectorized )).tocsr()\n",
    "# final_featurest = sparse.hstack((df_test[col],test_vectorized )).tocsr()\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "target = train.target.values\n",
    "y      = to_categorical(target)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_val , Y_train , Y_val = train_test_split(\n",
    "    train['text'], y,test_size = 0.20)\n",
    "print(X_train.shape, X_val.shape, Y_train.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5959,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_len = train['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "word_len.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0ba020c6a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(len(word_len)), word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: word_count min: 1          max: 678        low: 3.0        high: 175.0     \n",
      "Col: word_count min: 1          max: 678        low: 3.0        high: 188.0     \n",
      "Col: word_count min: 1          max: 678        low: 3.0        high: 208.0     \n",
      "Col: word_count min: 1          max: 678        low: 3.0        high: 244.84    \n",
      "Col: word_count min: 1          max: 678        low: 3.0        high: 302.0     \n"
     ]
    }
   ],
   "source": [
    "def get_quantile(df, col, q1, q2):\n",
    "    \"\"\"compute quantile range\n",
    "    args:\n",
    "        col: col name\n",
    "        q1: lower quantile percentile\n",
    "        q2: upper quantile percentile\n",
    "    \"\"\"\n",
    "    df1 = df[[col]].dropna()\n",
    "    lower_bound = np.percentile(df1, q=q1)\n",
    "    upper_bound = np.percentile(df1, q=q2)\n",
    "    lower_bound = np.round(lower_bound,3)\n",
    "    upper_bound = np.round(upper_bound, 3)\n",
    "    min_ = np.round(np.min(df1[col]), 3)\n",
    "    max_ = np.round(np.max(df1[col]), 3)\n",
    "    print(\"Col: {4:<10} min: {0:<10} max: {1:<10} low: {2:<10} high: {3:<10}\".format(min_, max_, lower_bound, upper_bound, col))\n",
    "\n",
    "train['word_count'] = train['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "get_quantile(train, 'word_count', 1, 95)\n",
    "get_quantile(train, 'word_count', 1, 96)\n",
    "get_quantile(train, 'word_count', 1, 97)\n",
    "get_quantile(train, 'word_count', 1, 98)\n",
    "get_quantile(train, 'word_count', 1, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4767, 200), (1192, 200))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,GRU,LSTM,Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import SpatialDropout1D,Dropout,Bidirectional,Conv1D,GlobalMaxPooling1D,MaxPooling1D,Flatten\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=50000,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "\n",
    "max_features = len(word_index) + 1\n",
    "max_words    = 200#302\n",
    "batch_size   = 16\n",
    "epochs       = 10\n",
    "num_classes  = 21\n",
    "\n",
    "# X_test = tokenizer.texts_to_sequences(df_test['text'])\n",
    "# X_test = pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen = max_words)\n",
    "X_val   = pad_sequences(X_val, maxlen   = max_words)\n",
    "\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim, W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None, bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias: eij += self.b\n",
    "        eij = K.tanh(eij)\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True)+K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_examples(lines, set_type, labels=None):\n",
    "#Generate data for the BERT model\n",
    "    guid = f'{set_type}'\n",
    "    examples = []\n",
    "    if guid == 'train':\n",
    "        for line, label in zip(lines, labels):\n",
    "            text_a = line\n",
    "            label = str(label)\n",
    "            examples.append(\n",
    "              run_classifier.InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "    else:\n",
    "        for line in lines:\n",
    "            text_a = line\n",
    "            label = '0'\n",
    "            examples.append(\n",
    "              run_classifier.InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "    return examples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fbe381d2158>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'bert_model/outputs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100000, '_save_checkpoints_secs': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbe32c48e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Model Hyper Parameters\n",
    "TRAIN_BATCH_SIZE  = 16\n",
    "EVAL_BATCH_SIZE   = 32\n",
    "LEARNING_RATE     = 1e-5\n",
    "NUM_TRAIN_EPOCHS  = 10\n",
    "WARMUP_PROPORTION = 0.1\n",
    "MAX_SEQ_LENGTH    = 100\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 100000 #if you wish to finetune a model on a larger dataset, use larger interval\n",
    "# each checpoint weights about 1,5gb\n",
    "ITERATIONS_PER_LOOP = 100000\n",
    "NUM_TPU_CORES   = 8\n",
    "VOCAB_FILE      = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
    "CONFIG_FILE     = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
    "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
    "DO_LOWER_CASE   = BERT_MODEL.startswith('uncased')\n",
    "\n",
    "\n",
    "label_list = list(range(21))\n",
    "tokenizer  = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case = DO_LOWER_CASE)\n",
    "train_examples = create_examples(train[\"text\"].values, 'train', labels = train[\"target\"].values.astype(int))\n",
    "\n",
    "tpu_cluster_resolver = None #Since training will happen on GPU, we won't need a cluster resolver\n",
    "#TPUEstimator also supports training on CPU and GPU. You don't need to define a separate tf.estimator.Estimator.\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster                = tpu_cluster_resolver,\n",
    "    model_dir              = OUTPUT_DIR,\n",
    "    save_checkpoints_steps = SAVE_CHECKPOINTS_STEPS,\n",
    "    tpu_config             = tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop = ITERATIONS_PER_LOOP,\n",
    "        num_shards          = NUM_TPU_CORES,\n",
    "        per_host_input_for_training = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
    "\n",
    "\n",
    "\n",
    "num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "model_fn = run_classifier.model_fn_builder(\n",
    "    bert_config     = modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
    "    num_labels      = len(label_list),\n",
    "    init_checkpoint = INIT_CHECKPOINT,\n",
    "    learning_rate   = LEARNING_RATE,\n",
    "    num_train_steps = num_train_steps,\n",
    "    num_warmup_steps= num_warmup_steps,\n",
    "    use_tpu         = False, #If False training will fall on CPU or GPU, depending on what is available  \n",
    "    use_one_hot_embeddings=True)\n",
    "\n",
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu          = False, #If False training will fall on CPU or GPU, depending on what is available \n",
    "    model_fn         = model_fn,\n",
    "    config           = run_config,\n",
    "    train_batch_size = TRAIN_BATCH_SIZE,\n",
    "    eval_batch_size  = EVAL_BATCH_SIZE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait...\n",
      "INFO:tensorflow:Writing example 0 of 5959\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train\n",
      "INFO:tensorflow:tokens: [CLS] did nothing for me , did not help lost even with working out and eating healthy . did not curb appetite or anything . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2106 2498 2005 2033 1010 2106 2025 2393 2439 2130 2007 2551 2041 1998 5983 7965 1012 2106 2025 13730 18923 2030 2505 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 15 (id = 15)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train\n",
      "INFO:tensorflow:tokens: [CLS] did nothing for me , did not help lost even with working out and eating healthy . did not curb appetite or anything . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2106 2498 2005 2033 1010 2106 2025 2393 2439 2130 2007 2551 2041 1998 5983 7965 1012 2106 2025 13730 18923 2030 2505 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 11 (id = 11)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train\n",
      "INFO:tensorflow:tokens: [CLS] have bought these bags and immediately open one put in some trash and the bag was split down the side . so opened another bag to cover the split bag and it also split down the side ( x ##3 ) . do not buy these you will end up throwing your box away [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2031 4149 2122 8641 1998 3202 2330 2028 2404 1999 2070 11669 1998 1996 4524 2001 3975 2091 1996 2217 1012 2061 2441 2178 4524 2000 3104 1996 3975 4524 1998 2009 2036 3975 2091 1996 2217 1006 1060 2509 1007 1012 2079 2025 4965 2122 2017 2097 2203 2039 6886 2115 3482 2185 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 4 (id = 4)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train\n",
      "INFO:tensorflow:tokens: [CLS] gave me an allergic reaction on my face : ( [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2435 2033 2019 27395 4668 2006 2026 2227 1024 1006 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: train\n",
      "INFO:tensorflow:tokens: [CLS] these do not compare to the name brand wipe ##s . family of little kids , we use lot of wipe ##s . these do not cut through sticky mess ##es and they are small and very thin . might be ok for wiping down less often used places but not good at tack ##ling actual mess ##es . also did not care for the lemon scent , felt it was too strong . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2122 2079 2025 12826 2000 1996 2171 4435 13387 2015 1012 2155 1997 2210 4268 1010 2057 2224 2843 1997 13387 2015 1012 2122 2079 2025 3013 2083 15875 6752 2229 1998 2027 2024 2235 1998 2200 4857 1012 2453 2022 7929 2005 14612 2091 2625 2411 2109 3182 2021 2025 2204 2012 26997 2989 5025 6752 2229 1012 2036 2106 2025 2729 2005 1996 14380 6518 1010 2371 2009 2001 2205 2844 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 17 (id = 17)\n",
      ">> Started training at 2019-08-06 18:53:48.760757 \n",
      "  Num examples = 5959\n",
      "  Batch size = 16\n",
      "INFO:tensorflow:  Num steps = 3724\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (16, 100)\n",
      "INFO:tensorflow:  name = input_mask, shape = (16, 100)\n",
      "INFO:tensorflow:  name = label_ids, shape = (16,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (16, 100)\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (21, 768)\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (21,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from bert_model/outputs/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into bert_model/outputs/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.0624809\n",
      "INFO:tensorflow:examples/sec: 0.999695\n",
      "INFO:tensorflow:global_step/sec: 0.078668\n",
      "INFO:tensorflow:examples/sec: 1.25869\n",
      "INFO:tensorflow:global_step/sec: 0.0857983\n",
      "INFO:tensorflow:examples/sec: 1.37277\n",
      "INFO:tensorflow:global_step/sec: 0.0860072\n",
      "INFO:tensorflow:examples/sec: 1.37611\n",
      "INFO:tensorflow:global_step/sec: 0.0860096\n",
      "INFO:tensorflow:examples/sec: 1.37615\n",
      "INFO:tensorflow:global_step/sec: 0.0858408\n",
      "INFO:tensorflow:examples/sec: 1.37345\n",
      "INFO:tensorflow:global_step/sec: 0.086122\n",
      "INFO:tensorflow:examples/sec: 1.37795\n",
      "INFO:tensorflow:global_step/sec: 0.0861103\n",
      "INFO:tensorflow:examples/sec: 1.37776\n",
      "INFO:tensorflow:global_step/sec: 0.0859995\n",
      "INFO:tensorflow:examples/sec: 1.37599\n",
      "INFO:tensorflow:global_step/sec: 0.0861003\n",
      "INFO:tensorflow:examples/sec: 1.37761\n",
      "INFO:tensorflow:global_step/sec: 0.0860661\n",
      "INFO:tensorflow:examples/sec: 1.37706\n",
      "INFO:tensorflow:global_step/sec: 0.0860522\n",
      "INFO:tensorflow:examples/sec: 1.37684\n",
      "INFO:tensorflow:global_step/sec: 0.0861834\n",
      "INFO:tensorflow:examples/sec: 1.37893\n",
      "INFO:tensorflow:global_step/sec: 0.0861795\n",
      "INFO:tensorflow:examples/sec: 1.37887\n",
      "INFO:tensorflow:global_step/sec: 0.0861243\n",
      "INFO:tensorflow:examples/sec: 1.37799\n",
      "INFO:tensorflow:global_step/sec: 0.0861543\n",
      "INFO:tensorflow:examples/sec: 1.37847\n",
      "INFO:tensorflow:global_step/sec: 0.0862476\n",
      "INFO:tensorflow:examples/sec: 1.37996\n",
      "INFO:tensorflow:global_step/sec: 0.0861599\n",
      "INFO:tensorflow:examples/sec: 1.37856\n",
      "INFO:tensorflow:global_step/sec: 0.0863145\n",
      "INFO:tensorflow:examples/sec: 1.38103\n",
      "INFO:tensorflow:global_step/sec: 0.0858452\n",
      "INFO:tensorflow:examples/sec: 1.37352\n",
      "INFO:tensorflow:global_step/sec: 0.0853938\n",
      "INFO:tensorflow:examples/sec: 1.3663\n",
      "INFO:tensorflow:global_step/sec: 0.085534\n",
      "INFO:tensorflow:examples/sec: 1.36854\n",
      "INFO:tensorflow:global_step/sec: 0.0855213\n",
      "INFO:tensorflow:examples/sec: 1.36834\n",
      "INFO:tensorflow:global_step/sec: 0.0854036\n",
      "INFO:tensorflow:examples/sec: 1.36646\n",
      "INFO:tensorflow:global_step/sec: 0.0855394\n",
      "INFO:tensorflow:examples/sec: 1.36863\n",
      "INFO:tensorflow:global_step/sec: 0.0855897\n",
      "INFO:tensorflow:examples/sec: 1.36943\n",
      "INFO:tensorflow:global_step/sec: 0.0856152\n",
      "INFO:tensorflow:examples/sec: 1.36984\n",
      "INFO:tensorflow:global_step/sec: 0.0855121\n",
      "INFO:tensorflow:examples/sec: 1.36819\n",
      "INFO:tensorflow:global_step/sec: 0.0855322\n",
      "INFO:tensorflow:examples/sec: 1.36851\n",
      "INFO:tensorflow:global_step/sec: 0.0855782\n",
      "INFO:tensorflow:examples/sec: 1.36925\n",
      "INFO:tensorflow:global_step/sec: 0.0854662\n",
      "INFO:tensorflow:examples/sec: 1.36746\n",
      "INFO:tensorflow:global_step/sec: 0.0856033\n",
      "INFO:tensorflow:examples/sec: 1.36965\n",
      "INFO:tensorflow:global_step/sec: 0.0856113\n",
      "INFO:tensorflow:examples/sec: 1.36978\n",
      "INFO:tensorflow:global_step/sec: 0.0854823\n",
      "INFO:tensorflow:examples/sec: 1.36772\n",
      "INFO:tensorflow:global_step/sec: 0.0855905\n",
      "INFO:tensorflow:examples/sec: 1.36945\n",
      "INFO:tensorflow:global_step/sec: 0.0855684\n",
      "INFO:tensorflow:examples/sec: 1.36909\n",
      "INFO:tensorflow:global_step/sec: 0.0854604\n",
      "INFO:tensorflow:examples/sec: 1.36737\n",
      "INFO:tensorflow:Saving checkpoints for 3724 into bert_model/outputs/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.5415827.\n",
      ">> Finished training at 2019-08-07 07:07:17.340563\n"
     ]
    }
   ],
   "source": [
    "num_classes = 21\n",
    "label_dict = {}\n",
    "for i in range(num_classes):\n",
    "    label_dict[str(i)] = i\n",
    "\n",
    "# {'0':0,'1':1,'2':2}\n",
    "\n",
    "import datetime\n",
    "print('Please wait...')\n",
    "train_features = run_classifier.convert_examples_to_features(train_examples,label_dict, MAX_SEQ_LENGTH, tokenizer)\n",
    "print('>> Started training at {} '.format(datetime.datetime.now()))\n",
    "print('  Num examples = {}'.format(len(train_examples)))\n",
    "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
    "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "train_input_fn = run_classifier.input_fn_builder(\n",
    "    features       = train_features,\n",
    "    seq_length     = MAX_SEQ_LENGTH,\n",
    "    is_training    = True,\n",
    "    drop_remainder = True)\n",
    "estimator.train(input_fn = train_input_fn, max_steps = num_train_steps)\n",
    "print('>> Finished training at {}'.format(datetime.datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
    "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
    "\n",
    "    all_input_ids   = []\n",
    "    all_input_mask  = []\n",
    "    all_segment_ids = []\n",
    "    all_label_ids   = []\n",
    "\n",
    "    for feature in features:\n",
    "        all_input_ids.append(feature.input_ids)\n",
    "        all_input_mask.append(feature.input_mask)\n",
    "        all_segment_ids.append(feature.segment_ids)\n",
    "        all_label_ids.append(feature.label_id)\n",
    "\n",
    "    def input_fn(params):\n",
    "        \"\"\"The actual input function.\"\"\"\n",
    "        print(params)\n",
    "        batch_size = 500\n",
    "\n",
    "        num_examples = len(features)\n",
    "\n",
    "        d = tf.data.Dataset.from_tensor_slices({\n",
    "            \"input_ids\":\n",
    "                tf.constant(\n",
    "                    all_input_ids, shape=[num_examples, seq_length], dtype=tf.int32),\n",
    "            \"input_mask\":\n",
    "                tf.constant(\n",
    "                    all_input_mask, shape=[num_examples, seq_length], dtype=tf.int32),\n",
    "            \"segment_ids\":\n",
    "                tf.constant(\n",
    "                    all_segment_ids, shape=[num_examples, seq_length], dtype=tf.int32),\n",
    "            \"label_ids\":\n",
    "                tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
    "        })\n",
    "\n",
    "        if is_training:\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "\n",
    "        d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
    "        return d\n",
    "\n",
    "    return input_fn\n",
    "\n",
    "    \n",
    "# predict_examples = create_examples(df_test['text'].values, 'test')\n",
    "\n",
    "# predict_features = run_classifier.convert_examples_to_features(\n",
    "# predict_examples, {'0':0,'1':1,'2':2}, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "# predict_input_fn = input_fn_builder(\n",
    "#     features       = predict_features,\n",
    "#     seq_length     = MAX_SEQ_LENGTH,\n",
    "#     is_training    = False,\n",
    "#     drop_remainder = False)\n",
    "\n",
    "# result = estimator.predict(input_fn=predict_input_fn)\n",
    "\n",
    "# preds = []\n",
    "# for prediction in result:\n",
    "#     preds.append(np.argmax(prediction['probabilities']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2553\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test\n",
      "INFO:tensorflow:tokens: [CLS] use chi ##a seed in my protein shakes . these tasted like they were mold ##y . throw them out [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2224 9610 2050 6534 1999 2026 5250 10854 1012 2122 12595 2066 2027 2020 18282 2100 1012 5466 2068 2041 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test\n",
      "INFO:tensorflow:tokens: [CLS] use chi ##a seed in my protein shakes . these tasted like they were mold ##y . throw them out [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2224 9610 2050 6534 1999 2026 5250 10854 1012 2122 12595 2066 2027 2020 18282 2100 1012 5466 2068 2041 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test\n",
      "INFO:tensorflow:tokens: [CLS] do not waste your money . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2079 2025 5949 2115 2769 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test\n",
      "INFO:tensorflow:tokens: [CLS] use the book ' fort ##ify your life ' by tier ##ao ##na low dog , md to help me make more informed decisions regarding supplements . went over this supplement from \" brand \" elements & found some negative ##s if you are not vega ##n : < br / > < br / > contains f ##olate as f ##olic acid . f ##olic acid is the synthetic form of f ##olate . < br / > vitamin b1 ##2 as cy ##ano ##co ##bala ##min . cy ##ano ##co ##bala ##min is the synthetic form [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2224 1996 2338 1005 3481 8757 2115 2166 1005 2011 7563 7113 2532 2659 3899 1010 9108 2000 2393 2033 2191 2062 6727 6567 4953 25654 1012 2253 2058 2023 12448 2013 1000 4435 1000 3787 1004 2179 2070 4997 2015 2065 2017 2024 2025 15942 2078 1024 1026 7987 1013 1028 1026 7987 1013 1028 3397 1042 19425 2004 1042 23518 5648 1012 1042 23518 5648 2003 1996 12553 2433 1997 1042 19425 1012 1026 7987 1013 1028 17663 29491 2475 2004 22330 6761 3597 25060 10020 1012 22330 6761 3597 25060 10020 2003 1996 12553 2433 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test\n",
      "INFO:tensorflow:tokens: [CLS] use the book ' fort ##ify your life ' by tier ##ao ##na low dog , md to help me make more informed decisions regarding supplements . went over this supplement from \" brand \" elements & found some negative ##s if you are not vega ##n : < br / > < br / > contains f ##olate as f ##olic acid . f ##olic acid is the synthetic form of f ##olate . < br / > vitamin b1 ##2 as cy ##ano ##co ##bala ##min . cy ##ano ##co ##bala ##min is the synthetic form [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2224 1996 2338 1005 3481 8757 2115 2166 1005 2011 7563 7113 2532 2659 3899 1010 9108 2000 2393 2033 2191 2062 6727 6567 4953 25654 1012 2253 2058 2023 12448 2013 1000 4435 1000 3787 1004 2179 2070 4997 2015 2065 2017 2024 2025 15942 2078 1024 1026 7987 1013 1028 1026 7987 1013 1028 3397 1042 19425 2004 1042 23518 5648 1012 1042 23518 5648 2003 1996 12553 2433 1997 1042 19425 1012 1026 7987 1013 1028 17663 29491 2475 2004 22330 6761 3597 25060 10020 1012 22330 6761 3597 25060 10020 2003 1996 12553 2433 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported string type: <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cbd49df1f89d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m predict_features = run_classifier.convert_examples_to_features(\n\u001b[0;32m----> 4\u001b[0;31m     predict_examples, label_dict, MAX_SEQ_LENGTH, tokenizer)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m predict_input_fn = input_fn_builder(\n",
      "\u001b[0;32m~/kaggle_data_science/kaggle-comp/ml-projects/amazon-ml/run_classifier.py\u001b[0m in \u001b[0;36mconvert_examples_to_features\u001b[0;34m(examples, label_list, max_seq_length, tokenizer)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     feature = convert_single_example(ex_index, example, label_list,\n\u001b[0;32m--> 777\u001b[0;31m                                      max_seq_length, tokenizer)\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_data_science/kaggle-comp/ml-projects/amazon-ml/run_classifier.py\u001b[0m in \u001b[0;36mconvert_single_example\u001b[0;34m(ex_index, example, label_list, max_seq_length, tokenizer)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0mlabel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m   \u001b[0mtokens_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m   \u001b[0mtokens_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_data_science/kaggle-comp/ml-projects/amazon-ml/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0msub_token\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordpiece_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_data_science/kaggle-comp/ml-projects/amazon-ml/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Tokenizes a piece of text.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_data_science/kaggle-comp/ml-projects/amazon-ml/tokenization.py\u001b[0m in \u001b[0;36mconvert_to_unicode\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported string type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported string type: <class 'float'>"
     ]
    }
   ],
   "source": [
    "predict_examples = create_examples(test['text'].values, 'test')\n",
    "\n",
    "predict_features = run_classifier.convert_examples_to_features(\n",
    "    predict_examples, label_dict, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "predict_input_fn = input_fn_builder(\n",
    "    features       = predict_features,\n",
    "    seq_length     = MAX_SEQ_LENGTH,\n",
    "    is_training    = False,\n",
    "    drop_remainder = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 2553\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test\n",
      "INFO:tensorflow:tokens: [CLS] use chi ##a seed in my protein shakes . these tasted like they were mold ##y . throw them out [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2224 9610 2050 6534 1999 2026 5250 10854 1012 2122 12595 2066 2027 2020 18282 2100 1012 5466 2068 2041 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test\n",
      "INFO:tensorflow:tokens: [CLS] use chi ##a seed in my protein shakes . these tasted like they were mold ##y . throw them out [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2224 9610 2050 6534 1999 2026 5250 10854 1012 2122 12595 2066 2027 2020 18282 2100 1012 5466 2068 2041 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test\n",
      "INFO:tensorflow:tokens: [CLS] do not waste your money . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2079 2025 5949 2115 2769 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test\n",
      "INFO:tensorflow:tokens: [CLS] use the book ' fort ##ify your life ' by tier ##ao ##na low dog , md to help me make more informed decisions regarding supplements . went over this supplement from \" brand \" elements & found some negative ##s if you are not vega ##n : < br / > < br / > contains f ##olate as f ##olic acid . f ##olic acid is the synthetic form of f ##olate . < br / > vitamin b1 ##2 as cy ##ano ##co ##bala ##min . cy ##ano ##co ##bala ##min is the synthetic form [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2224 1996 2338 1005 3481 8757 2115 2166 1005 2011 7563 7113 2532 2659 3899 1010 9108 2000 2393 2033 2191 2062 6727 6567 4953 25654 1012 2253 2058 2023 12448 2013 1000 4435 1000 3787 1004 2179 2070 4997 2015 2065 2017 2024 2025 15942 2078 1024 1026 7987 1013 1028 1026 7987 1013 1028 3397 1042 19425 2004 1042 23518 5648 1012 1042 23518 5648 2003 1996 12553 2433 1997 1042 19425 1012 1026 7987 1013 1028 17663 29491 2475 2004 22330 6761 3597 25060 10020 1012 22330 6761 3597 25060 10020 2003 1996 12553 2433 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: test\n",
      "INFO:tensorflow:tokens: [CLS] use the book ' fort ##ify your life ' by tier ##ao ##na low dog , md to help me make more informed decisions regarding supplements . went over this supplement from \" brand \" elements & found some negative ##s if you are not vega ##n : < br / > < br / > contains f ##olate as f ##olic acid . f ##olic acid is the synthetic form of f ##olate . < br / > vitamin b1 ##2 as cy ##ano ##co ##bala ##min . cy ##ano ##co ##bala ##min is the synthetic form [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2224 1996 2338 1005 3481 8757 2115 2166 1005 2011 7563 7113 2532 2659 3899 1010 9108 2000 2393 2033 2191 2062 6727 6567 4953 25654 1012 2253 2058 2023 12448 2013 1000 4435 1000 3787 1004 2179 2070 4997 2015 2065 2017 2024 2025 15942 2078 1024 1026 7987 1013 1028 1026 7987 1013 1028 3397 1042 19425 2004 1042 23518 5648 1012 1042 23518 5648 2003 1996 12553 2433 1997 1042 19425 1012 1026 7987 1013 1028 17663 29491 2475 2004 22330 6761 3597 25060 10020 1012 22330 6761 3597 25060 10020 2003 1996 12553 2433 102\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported string type: <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ad9d51e63335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFullTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVOCAB_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDO_LOWER_CASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m predict_features = run_classifier.convert_examples_to_features(\n\u001b[0;32m----> 3\u001b[0;31m     predict_examples, label_dict, MAX_SEQ_LENGTH, tokenizer)\n\u001b[0m",
      "\u001b[0;32m~/kaggle_data_science/kaggle-comp/ml-projects/amazon-ml/run_classifier.py\u001b[0m in \u001b[0;36mconvert_examples_to_features\u001b[0;34m(examples, label_list, max_seq_length, tokenizer)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     feature = convert_single_example(ex_index, example, label_list,\n\u001b[0;32m--> 777\u001b[0;31m                                      max_seq_length, tokenizer)\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_data_science/kaggle-comp/ml-projects/amazon-ml/run_classifier.py\u001b[0m in \u001b[0;36mconvert_single_example\u001b[0;34m(ex_index, example, label_list, max_seq_length, tokenizer)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0mlabel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m   \u001b[0mtokens_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m   \u001b[0mtokens_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_data_science/kaggle-comp/ml-projects/amazon-ml/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0msub_token\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordpiece_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0msplit_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_data_science/kaggle-comp/ml-projects/amazon-ml/tokenization.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Tokenizes a piece of text.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_data_science/kaggle-comp/ml-projects/amazon-ml/tokenization.py\u001b[0m in \u001b[0;36mconvert_to_unicode\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unsupported string type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported string type: <class 'float'>"
     ]
    }
   ],
   "source": [
    "tokenizer  = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case = DO_LOWER_CASE)\n",
    "predict_features = run_classifier.convert_examples_to_features(\n",
    "    predict_examples, label_dict, MAX_SEQ_LENGTH, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' use chia seed in my protein shakes . these tasted like they were moldy . throw them out',\n",
       "       ' use chia seed in my protein shakes . these tasted like they were moldy . throw them out',\n",
       "       'do not waste your money . ', ...,\n",
       "       'very small and easy to swallow - no flavor at all - but left me with my stomach in knots / horrible bloating each time tried taking it . will not be purchasing again . ',\n",
       "       'good but it increases the bad cholesterol - ldl . < br / > it does not suite me . ',\n",
       "       'will not buy the powder again . '], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
