{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tqdm.pandas()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os, gc\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = '../../ml-toolbox-testing/dataset/glove.6B/glove.6B.300d.txt'\n",
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float16')[:1]\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(glove_file, encoding='latin'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts):\n",
    "    sentences = texts.progress_apply(lambda x: x.split()).values\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab\n",
    "\n",
    "def check_coverage(vocab, embeddings_index):\n",
    "    known_words = {}\n",
    "    unknown_words = {}\n",
    "    nb_known_words = 0\n",
    "    nb_unknown_words = 0\n",
    "    for word in vocab.keys():\n",
    "        if word in embeddings_index:\n",
    "            known_words[word] = embeddings_index[word]\n",
    "            nb_known_words += vocab[word]\n",
    "        elif word.capitalize() in embeddings_index:\n",
    "            known_words[word] = embeddings_index[word.capitalize()]\n",
    "            nb_known_words += vocab[word]\n",
    "        elif word.lower() in embeddings_index:\n",
    "            known_words[word] = embeddings_index[word.lower()]\n",
    "            nb_known_words += vocab[word]\n",
    "        elif word.upper() in embeddings_index:\n",
    "            known_words[word] = embeddings_index[word.upper()]\n",
    "            nb_known_words += vocab[word]\n",
    "        else:\n",
    "            unknown_words[word] = vocab[word]\n",
    "            nb_unknown_words += vocab[word]\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(known_words) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
    "    unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return unknown_words\n",
    "\n",
    "def vocab_check_coverage(df, col_name):\n",
    "#     df = pd.concat([train, test]).reset_index(drop=True)\n",
    "    \n",
    "    vocab = build_vocab(df[col_name])\n",
    "    print(\"Glove : \")\n",
    "    oov_glove = check_coverage(vocab, embeddings_index)\n",
    "    oov_glove = {\"oov_rate\": len(oov_glove) / len(vocab), 'oov_words': oov_glove}\n",
    "#     print(\"Paragram : \")\n",
    "#     oov_paragram = check_coverage(vocab, embed_paragram)\n",
    "#     oov_paragram = {\"oov_rate\": len(oov_paragram) / len(vocab), 'oov_words': oov_paragram}\n",
    "#     print(\"FastText : \")\n",
    "#     oov_fasttext = check_coverage(vocab, embed_fasttext)\n",
    "#     oov_fasttext = {\"oov_rate\": len(oov_fasttext) / len(vocab), 'oov_words': oov_fasttext}\n",
    "#     print(\"Google : \")\n",
    "#     oov_google = check_coverage(vocab, embed_google)\n",
    "#     oov_google = {\"oov_rate\": len(oov_google) / len(vocab), 'oov_words': oov_google}\n",
    "    \n",
    "    return oov_glove#, oov_paragram, oov_fasttext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Extracting GloVe embedding\")\n",
    "# for word in list(embeddings_index.keys()):\n",
    "#     if word is \"don't\":\n",
    "#         print(\"found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5959, 3), (2553, 2), (5, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Dataset/train.csv')\n",
    "test  = pd.read_csv('Dataset/test.csv')\n",
    "sub   = pd.read_csv('Dataset/Sample_Submission.csv')\n",
    "\n",
    "train.shape, test.shape, sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['text', 'title'], dtype='object'),\n",
       " Index(['text', 'title', 'topic'], dtype='object'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.rename(columns={'Review Text':'text', 'Review Title':'title'}, inplace=True)\n",
    "test.rename(columns={'Review Text':'text', 'Review Title':'title'}, inplace=True)\n",
    "test.columns, train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.append(test, ignore_index=True)\n",
    "df['text']  = df['text'].str.lower()\n",
    "df['title'] = df['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8512/8512 [00:00<00:00, 11677.38it/s]\n",
      "100%|██████████| 8512/8512 [00:00<00:00, 44913.83it/s]\n"
     ]
    }
   ],
   "source": [
    "contraction_mapping = {\n",
    "    \"Trump's\" : 'trump is',\"'cause\": 'because','â€™': \"'\",',cause': 'because',';cause': 'because',\"ain't\": 'am not','ain,t': 'am not',\n",
    "    'ain;t': 'am not','ain´t': 'am not','ain’t': 'am not',\"aren't\": 'are not','â€“': '-','â€œ':'\"',\n",
    "    'aren,t': 'are not','aren;t': 'are not','aren´t': 'are not','aren’t': 'are not',\"can't\": 'cannot',\"can't've\": 'cannot have','can,t': 'cannot','can,t,ve': 'cannot have',\n",
    "    'can;t': 'cannot','can;t;ve': 'cannot have',\n",
    "    'can´t': 'cannot','can´t´ve': 'cannot have','can’t': 'cannot','can’t’ve': 'cannot have',\n",
    "    \"could've\": 'could have','could,ve': 'could have','could;ve': 'could have',\"couldn't\": 'could not',\"couldn't've\": 'could not have','couldn,t': 'could not','couldn,t,ve': 'could not have','couldn;t': 'could not',\n",
    "    'couldn;t;ve': 'could not have','couldn´t': 'could not',\n",
    "    'couldn´t´ve': 'could not have','couldn’t': 'could not','couldn’t’ve': 'could not have','could´ve': 'could have',\n",
    "    'could’ve': 'could have',\"didn't\": 'did not','didn,t': 'did not','didn;t': 'did not','didn´t': 'did not',\n",
    "    'didn’t': 'did not',\"doesn't\": 'does not','doesn,t': 'does not','doesn;t': 'does not','doesn´t': 'does not',\n",
    "    'doesn’t': 'does not',\"don't\": 'do not','don,t': 'do not','don;t': 'do not','don´t': 'do not','don’t': 'do not',\n",
    "    \"hadn't\": 'had not',\"hadn't've\": 'had not have','hadn,t': 'had not','hadn,t,ve': 'had not have','hadn;t': 'had not',\n",
    "    'hadn;t;ve': 'had not have','hadn´t': 'had not','hadn´t´ve': 'had not have','hadn’t': 'had not','hadn’t’ve': 'had not have',\"hasn't\": 'has not','hasn,t': 'has not','hasn;t': 'has not','hasn´t': 'has not','hasn’t': 'has not',\n",
    "    \"haven't\": 'have not','haven,t': 'have not','haven;t': 'have not','haven´t': 'have not','haven’t': 'have not',\"he'd\": 'he would',\n",
    "    \"he'd've\": 'he would have',\"he'll\": 'he will',\n",
    "    \"he's\": 'he is','he,d': 'he would','he,d,ve': 'he would have','he,ll': 'he will','he,s': 'he is','he;d': 'he would',\n",
    "    'he;d;ve': 'he would have','he;ll': 'he will','he;s': 'he is','he´d': 'he would','he´d´ve': 'he would have','he´ll': 'he will',\n",
    "    'he´s': 'he is','he’d': 'he would','he’d’ve': 'he would have','he’ll': 'he will','he’s': 'he is',\"how'd\": 'how did',\"how'll\": 'how will',\n",
    "    \"how's\": 'how is','how,d': 'how did','how,ll': 'how will','how,s': 'how is','how;d': 'how did','how;ll': 'how will',\n",
    "    'how;s': 'how is','how´d': 'how did','how´ll': 'how will','how´s': 'how is','how’d': 'how did','how’ll': 'how will',\n",
    "    'how’s': 'how is',\"i'd\": 'i would',\"i'll\": 'i will',\"i'm\": 'i am',\"i've\": 'i have','i,d': 'i would','i,ll': 'i will',\n",
    "    'i,m': 'i am','i,ve': 'i have','i;d': 'i would','i;ll': 'i will','i;m': 'i am','i;ve': 'i have',\"isn't\": 'is not',\n",
    "    'isn,t': 'is not','isn;t': 'is not','isn´t': 'is not','isn’t': 'is not',\"it'd\": 'it would',\"it'll\": 'it will',\"It's\":'it is',\n",
    "    \"it's\": 'it is','it,d': 'it would','it,ll': 'it will','it,s': 'it is','it;d': 'it would','it;ll': 'it will','it;s': 'it is','it´d': 'it would','it´ll': 'it will','it´s': 'it is',\n",
    "    'it’d': 'it would','it’ll': 'it will','it’s': 'it is',\n",
    "    'i´d': 'i would','i´ll': 'i will','i´m': 'i am','i´ve': 'i have','i’d': 'i would','i’ll': 'i will','i’m': 'i am',\n",
    "    'i’ve': 'i have',\"let's\": 'let us','let,s': 'let us','let;s': 'let us','let´s': 'let us',\n",
    "    'let’s': 'let us',\"ma'am\": 'madam','ma,am': 'madam','ma;am': 'madam',\"mayn't\": 'may not','mayn,t': 'may not','mayn;t': 'may not',\n",
    "    'mayn´t': 'may not','mayn’t': 'may not','ma´am': 'madam','ma’am': 'madam',\"might've\": 'might have','might,ve': 'might have','might;ve': 'might have',\"mightn't\": 'might not','mightn,t': 'might not','mightn;t': 'might not','mightn´t': 'might not',\n",
    "    'mightn’t': 'might not','might´ve': 'might have','might’ve': 'might have',\"must've\": 'must have','must,ve': 'must have','must;ve': 'must have',\n",
    "    \"mustn't\": 'must not','mustn,t': 'must not','mustn;t': 'must not','mustn´t': 'must not','mustn’t': 'must not','must´ve': 'must have',\n",
    "    'must’ve': 'must have',\"needn't\": 'need not','needn,t': 'need not','needn;t': 'need not','needn´t': 'need not','needn’t': 'need not',\"oughtn't\": 'ought not','oughtn,t': 'ought not','oughtn;t': 'ought not',\n",
    "    'oughtn´t': 'ought not','oughtn’t': 'ought not',\"sha'n't\": 'shall not','sha,n,t': 'shall not','sha;n;t': 'shall not',\"shan't\": 'shall not',\n",
    "    'shan,t': 'shall not','shan;t': 'shall not','shan´t': 'shall not','shan’t': 'shall not','sha´n´t': 'shall not','sha’n’t': 'shall not',\n",
    "    \"she'd\": 'she would',\"she'll\": 'she will',\"she's\": 'she is','she,d': 'she would','she,ll': 'she will',\n",
    "    'she,s': 'she is','she;d': 'she would','she;ll': 'she will','she;s': 'she is','she´d': 'she would','she´ll': 'she will',\n",
    "    'she´s': 'she is','she’d': 'she would','she’ll': 'she will','she’s': 'she is',\"should've\": 'should have','should,ve': 'should have','should;ve': 'should have',\n",
    "    \"shouldn't\": 'should not','shouldn,t': 'should not','shouldn;t': 'should not','shouldn´t': 'should not','shouldn’t': 'should not','should´ve': 'should have',\n",
    "    'should’ve': 'should have',\"that'd\": 'that would',\"that's\": 'that is','that,d': 'that would','that,s': 'that is','that;d': 'that would',\n",
    "    'that;s': 'that is','that´d': 'that would','that´s': 'that is','that’d': 'that would','that’s': 'that is',\"there'd\": 'there had',\n",
    "    \"there's\": 'there is','there,d': 'there had','there,s': 'there is','there;d': 'there had','there;s': 'there is',\n",
    "    'there´d': 'there had','there´s': 'there is','there’d': 'there had','there’s': 'there is',\n",
    "    \"they'd\": 'they would',\"they'll\": 'they will',\"they're\": 'they are',\"they've\": 'they have',\n",
    "    'they,d': 'they would','they,ll': 'they will','they,re': 'they are','they,ve': 'they have','they;d': 'they would','they;ll': 'they will','they;re': 'they are',\n",
    "    'they;ve': 'they have','they´d': 'they would','they´ll': 'they will','they´re': 'they are','they´ve': 'they have','they’d': 'they would','they’ll': 'they will',\n",
    "    'they’re': 'they are','they’ve': 'they have',\"wasn't\": 'was not','wasn,t': 'was not','wasn;t': 'was not','wasn´t': 'was not',\n",
    "    'wasn’t': 'was not',\"we'd\": 'we would',\"we'll\": 'we will',\"we're\": 'we are',\"we've\": 'we have','we,d': 'we would','we,ll': 'we will',\n",
    "    'we,re': 'we are','we,ve': 'we have','we;d': 'we would','we;ll': 'we will','we;re': 'we are','we;ve': 'we have',\n",
    "    \"weren't\": 'were not','weren,t': 'were not','weren;t': 'were not','weren´t': 'were not','weren’t': 'were not','we´d': 'we would','we´ll': 'we will',\n",
    "    'we´re': 'we are','we´ve': 'we have','we’d': 'we would','we’ll': 'we will','we’re': 'we are','we’ve': 'we have',\"what'll\": 'what will',\"what're\": 'what are',\"what's\": 'what is',\n",
    "    \"what've\": 'what have','what,ll': 'what will','what,re': 'what are','what,s': 'what is','what,ve': 'what have','what;ll': 'what will','what;re': 'what are',\n",
    "    'what;s': 'what is','what;ve': 'what have','what´ll': 'what will',\n",
    "    'what´re': 'what are','what´s': 'what is','what´ve': 'what have','what’ll': 'what will','what’re': 'what are','what’s': 'what is',\n",
    "    'what’ve': 'what have',\"where'd\": 'where did',\"where's\": 'where is','where,d': 'where did','where,s': 'where is','where;d': 'where did',\n",
    "    'where;s': 'where is','where´d': 'where did','where´s': 'where is','where’d': 'where did','where’s': 'where is',\n",
    "    \"who'll\": 'who will',\"who's\": 'who is','who,ll': 'who will','who,s': 'who is','who;ll': 'who will','who;s': 'who is',\n",
    "    'who´ll': 'who will','who´s': 'who is','who’ll': 'who will','who’s': 'who is',\"won't\": 'will not','won,t': 'will not','won;t': 'will not',\n",
    "    'won´t': 'will not','won’t': 'will not',\"wouldn't\": 'would not','wouldn,t': 'would not','wouldn;t': 'would not','wouldn´t': 'would not',\n",
    "    'wouldn’t': 'would not',\"you'd\": 'you would',\"you'll\": 'you will',\"you're\": 'you are','you,d': 'you would','you,ll': 'you will',\n",
    "    'you,re': 'you are','you;d': 'you would','you;ll': 'you will',\n",
    "    'you;re': 'you are','you´d': 'you would','you´ll': 'you will','you´re': 'you are','you’d': 'you would','you’ll': 'you will','you’re': 'you are',\n",
    "    '´cause': 'because','’cause': 'because',\"you've\": \"you have\",\"could'nt\": 'could not',\n",
    "    \"havn't\": 'have not',\"here’s\": \"here is\",'i\"\"m': 'i am',\"i'am\": 'i am',\"i'l\": \"i will\",\"i'v\": 'i have',\"wan't\": 'want',\"was'nt\": \"was not\",\"who'd\": \"who would\",\n",
    "    \"who're\": \"who are\",\"who've\": \"who have\",\"why'd\": \"why would\",\"would've\": \"would have\",\"y'all\": \"you all\",\"y'know\": \"you know\",\"you.i\": \"you i\",\n",
    "    \"your'e\": \"you are\",\"arn't\": \"are not\",\"agains't\": \"against\",\"c'mon\": \"common\",\"doens't\": \"does not\",'don\"\"t': \"do not\",\"dosen't\": \"does not\",\n",
    "    \"dosn't\": \"does not\",\"shoudn't\": \"should not\",\"that'll\": \"that will\",\"there'll\": \"there will\",\"there're\": \"there are\",\n",
    "    \"this'll\": \"this all\",\"u're\": \"you are\", \"ya'll\": \"you all\",\"you'r\": \"you are\",\"you’ve\": \"you have\",\"d'int\": \"did not\",\"did'nt\": \"did not\",\"din't\": \"did not\",\"dont't\": \"do not\",\"gov't\": \"government\",\n",
    "    \"i'ma\": \"i am\",\"is'nt\": \"is not\",\"‘I\":'I',\n",
    "    'ᴀɴᴅ':'and','ᴛʜᴇ':'the','ʜᴏᴍᴇ':'home','ᴜᴘ':'up','ʙʏ':'by','ᴀᴛ':'at','…and':'and','civilbeat':'civil beat',\\\n",
    "    'TrumpCare':'Trump care','Trumpcare':'Trump care', 'OBAMAcare':'Obama care','ᴄʜᴇᴄᴋ':'check','ғᴏʀ':'for','ᴛʜɪs':'this','ᴄᴏᴍᴘᴜᴛᴇʀ':'computer',\\\n",
    "    'ᴍᴏɴᴛʜ':'month','ᴡᴏʀᴋɪɴɢ':'working','ᴊᴏʙ':'job','ғʀᴏᴍ':'from','Sᴛᴀʀᴛ':'start','gubmit':'submit','CO₂':'carbon dioxide','ғɪʀsᴛ':'first',\\\n",
    "    'ᴇɴᴅ':'end','ᴄᴀɴ':'can','ʜᴀᴠᴇ':'have','ᴛᴏ':'to','ʟɪɴᴋ':'link','ᴏғ':'of','ʜᴏᴜʀʟʏ':'hourly','ᴡᴇᴇᴋ':'week','ᴇɴᴅ':'end','ᴇxᴛʀᴀ':'extra',\\\n",
    "    'Gʀᴇᴀᴛ':'great','sᴛᴜᴅᴇɴᴛs':'student','sᴛᴀʏ':'stay','ᴍᴏᴍs':'mother','ᴏʀ':'or','ᴀɴʏᴏɴᴇ':'anyone','ɴᴇᴇᴅɪɴɢ':'needing','ᴀɴ':'an','ɪɴᴄᴏᴍᴇ':'income',\\\n",
    "    'ʀᴇʟɪᴀʙʟᴇ':'reliable','ғɪʀsᴛ':'first','ʏᴏᴜʀ':'your','sɪɢɴɪɴɢ':'signing','ʙᴏᴛᴛᴏᴍ':'bottom','ғᴏʟʟᴏᴡɪɴɢ':'following','Mᴀᴋᴇ':'make',\\\n",
    "    'ᴄᴏɴɴᴇᴄᴛɪᴏɴ':'connection','ɪɴᴛᴇʀɴᴇᴛ':'internet','financialpost':'financial post', 'ʜaᴠᴇ':' have ', 'ᴄaɴ':' can ', 'Maᴋᴇ':' make ', 'ʀᴇʟɪaʙʟᴇ':' reliable ', 'ɴᴇᴇᴅ':' need ',\n",
    "    'ᴏɴʟʏ':' only ', 'ᴇxᴛʀa':' extra ', 'aɴ':' an ', 'aɴʏᴏɴᴇ':' anyone ', 'sᴛaʏ':' stay ', 'Sᴛaʀᴛ':' start', 'SHOPO':'shop',\n",
    "    }\n",
    "\n",
    "\n",
    "def correct_contraction(x, dic):\n",
    "    for word in dic.keys():\n",
    "        if word in x:\n",
    "            x = x.replace(word, dic[word])\n",
    "    return x\n",
    "\n",
    "df['text']  = df['text'].progress_apply(lambda x: correct_contraction(x, contraction_mapping))\n",
    "df['title'] = df['title'].progress_apply(lambda x: correct_contraction(x, contraction_mapping))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8512/8512 [00:00<00:00, 105318.18it/s]\n",
      "100%|██████████| 8512/8512 [00:00<00:00, 174170.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import os,operator\n",
    "\n",
    "extra_punct = [\n",
    "    ',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&',\n",
    "    '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    "    '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n",
    "    '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
    "    '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n",
    "    '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
    "    '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "    'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
    "    '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
    "    '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\n",
    "\n",
    "\n",
    "import string\n",
    "my_punct = list(string.punctuation)\n",
    "all_punct = list(set(my_punct + extra_punct))\n",
    "\n",
    "special_punc_mappings = {\"—\": \"-\", \"–\": \"-\", \"_\": \"-\", '”': '\"', \"″\": '\"', '“': '\"', '•': '.', '−': '-',\n",
    "                         \"’\": \"'\", \"‘\": \"'\", \"´\": \"'\", \"`\": \"'\", '\\u200b': ' ', '\\xa0': ' ','،':'','„':'',\n",
    "                         '…': ' ... ', '\\ufeff': ''}\n",
    "\n",
    "def spacing_punctuation(text):\n",
    "    \"\"\"\n",
    "    add space before and after punctuation and symbols\n",
    "    \"\"\"\n",
    "    for punc in all_punct:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, f' {punc} ')\n",
    "    return text\n",
    "\n",
    "def clean_special_punctuations(text):\n",
    "    for punc in special_punc_mappings:\n",
    "        if punc in text:\n",
    "            text = text.replace(punc, special_punc_mappings[punc])\n",
    "    # remove_diacritics don´t' ->  'don t'\n",
    "    #text = remove_diacritics(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text = spacing_punctuation(text)\n",
    "    text = clean_special_punctuations(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"text\"] = df[\"text\"].progress_apply(preprocess)\n",
    "df['text'] = df['text'].str.replace(r'\\b\\w\\b','').str.replace(r'\\s+', ' ')\n",
    "df['text'].replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "df['text'].replace({'  ':' '}, regex=True, inplace=True)\n",
    "\n",
    "df[\"title\"] = df[\"title\"].progress_apply(preprocess)\n",
    "df['title'] = df['title'].str.replace(r'\\b\\w\\b','').str.replace(r'\\s+', ' ')\n",
    "df['title'].replace({r'[^\\x00-\\x7F]+':''}, regex=True, inplace=True)\n",
    "df['title'].replace({'  ':' '}, regex=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8512/8512 [00:00<00:00, 25389.09it/s]\n",
      "100%|██████████| 8512/8512 [00:00<00:00, 111728.40it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'@[a-zA-Z0-9_]+', '', text)   \n",
    "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)   \n",
    "    text = re.sub(r'www.[^ ]+', '', text)  \n",
    "    text = re.sub(r'[a-zA-Z0-9]*www[a-zA-Z0-9]*com[a-zA-Z0-9]*', '', text)  \n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)   \n",
    "    text = [token for token in text.split() if len(token) > 2]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "df['text']   = df['text'].progress_apply(clean_text)\n",
    "df['title']  = df['title'].progress_apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8512/8512 [00:00<00:00, 104619.16it/s]\n",
      "100%|██████████| 8512/8512 [00:00<00:00, 145592.56it/s]\n"
     ]
    }
   ],
   "source": [
    "def clean_text(x):\n",
    "    x = str(x)\n",
    "    for punct in \"/-'\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
    "        x = x.replace(punct, '')\n",
    "    return x\n",
    "\n",
    "df['text'] = df['text'].progress_apply(clean_text)\n",
    "df['title'] = df['title'].progress_apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8512/8512 [00:00<00:00, 174444.16it/s]\n",
      "100%|██████████| 8512/8512 [00:00<00:00, 589617.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove : \n",
      "Found embeddings for 92.28% of vocab\n",
      "Found embeddings for  99.45% of all text\n",
      "Glove : \n",
      "Found embeddings for 94.63% of vocab\n",
      "Found embeddings for  99.18% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov_glove1 = vocab_check_coverage(df, 'text')\n",
    "oov_glove2 = vocab_check_coverage(df, 'title')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.4915], dtype=float16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index['vanilla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oov_glove2['oov_words'][:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def splitting(data):\n",
    "#     new=[]\n",
    "#     for sentences in data:\n",
    "#         yes = sentences.split(\". \")\n",
    "#         new.append(yes) \n",
    "#     return new\n",
    "    \n",
    "# train['new_text'] = splitting(train['text'])\n",
    "# test['new_text'] = splitting(test['text'])\n",
    "\n",
    "\n",
    "# def cleaning1(data):\n",
    "#     new_text=[]\n",
    "#     for sentences in data:\n",
    "#         matching = [s for s in sentences if 'reply posted' not in s]\n",
    "#         new_text.append(matching)\n",
    "        \n",
    "#     return new_text\n",
    "\n",
    "# train['new_text'] = cleaning1(train['new_text'])\n",
    "# test['new_text'] = cleaning1(test['new_text'])\n",
    "\n",
    "\n",
    "# def cleaning2(data):\n",
    "#     new_text=[]\n",
    "#     for sentences in data:\n",
    "#         matching = [s for s in sentences if 'help center' not in s]\n",
    "#         new_text.append(matching)\n",
    "        \n",
    "#     return new_text\n",
    "\n",
    "# train['new_text'] = cleaning2(train['new_text'])\n",
    "# test['new_text'] = cleaning2(test['new_text'])\n",
    "\n",
    "\n",
    "# def cleaning3(data):\n",
    "#     new_text=[]\n",
    "    \n",
    "#     for sentences in data:\n",
    "#         if(len(sentences)>1):\n",
    "#             matching = [s for s in sentences if len(s) >= 15]\n",
    "#             new_text.append(matching)\n",
    "            \n",
    "#         else:\n",
    "#             matching = [s for s in sentences if len(s) >= 2]\n",
    "#             new_text.append(matching)\n",
    "        \n",
    "#     return new_text\n",
    "\n",
    "# train['new_text'] = cleaning3(train['new_text'])\n",
    "# test['new_text'] = cleaning3(test['new_text'])\n",
    "\n",
    "# def don(d):\n",
    "#     n=[]\n",
    "#     for s in d:\n",
    "#         res = \".\".join(s)\n",
    "#         n.append(res)\n",
    "#     return n\n",
    "\n",
    "# train['text'] = don(train['new_text'])\n",
    "# test['text']  = don(test['new_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f69ebb84c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['wc_text']  = df['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "df['wc_title'] = df['title'].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(20, 4))\n",
    "ax[0].scatter(range(df.shape[0]), df['wc_text'])\n",
    "ax[1].scatter(range(df.shape[0]), df['wc_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs('new_dataset')\n",
    "# train.to_csv('new_dataset/train1.csv', index=None)\n",
    "# test.to_csv('new_dataset/test1.csv', index=None)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: wc_text    min: 1          max: 403        low: 2.0        high: 119.0     \n",
      "Col: wc_title   min: 1          max: 17         low: 1.0        high: 8.0       \n",
      "Col: wc_text    min: 1          max: 403        low: 2.0        high: 144.0     \n",
      "Col: wc_title   min: 1          max: 17         low: 1.0        high: 10.0      \n",
      "Col: wc_text    min: 1          max: 403        low: 2.0        high: 196.0     \n",
      "Col: wc_title   min: 1          max: 17         low: 1.0        high: 12.0      \n"
     ]
    }
   ],
   "source": [
    "def get_quantile(df, col, q1, q2):\n",
    "    \"\"\"compute quantile range\n",
    "    args:\n",
    "        col: col name\n",
    "        q1: lower quantile percentile\n",
    "        q2: upper quantile percentile\n",
    "    \"\"\"\n",
    "    df1 = df[[col]].dropna()\n",
    "    lower_bound = np.percentile(df1, q=q1)\n",
    "    upper_bound = np.percentile(df1, q=q2)\n",
    "    lower_bound = np.round(lower_bound,3)\n",
    "    upper_bound = np.round(upper_bound, 3)\n",
    "    min_ = np.round(np.min(df1[col]), 3)\n",
    "    max_ = np.round(np.max(df1[col]), 3)\n",
    "    print(\"Col: {4:<10} min: {0:<10} max: {1:<10} low: {2:<10} high: {3:<10}\".format(min_, max_, lower_bound, upper_bound, col))\n",
    "\n",
    "get_quantile(df, 'wc_text', 1, 95)\n",
    "get_quantile(df, 'wc_title', 1, 95)\n",
    "\n",
    "get_quantile(df, 'wc_text', 1, 97)\n",
    "get_quantile(df, 'wc_title', 1, 97)\n",
    "\n",
    "get_quantile(df, 'wc_text', 1, 99)\n",
    "get_quantile(df, 'wc_title', 1, 99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim, W_regularizer=None, b_regularizer=None, W_constraint=None, b_constraint=None, bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias: eij += self.b\n",
    "        eij = K.tanh(eij)\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True)+K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D\n",
    "# from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "\n",
    "# max_features = 50000\n",
    "# num_classes  = 21\n",
    "# max_words    = 200\n",
    "# filter_sizes = [1,2,3,5]\n",
    "# num_filters  = 36\n",
    "# inp = Input(shape=(max_words,))\n",
    "# x = Embedding(max_features, 300, trainable=False)(inp)\n",
    "# x = Reshape((max_words, 300, 1))(x)\n",
    "# maxpool_pool = []\n",
    "# for i in range(len(filter_sizes)):\n",
    "#     conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], 300),\n",
    "#                                  kernel_initializer='he_normal', activation='relu')(x)\n",
    "#     maxpool_pool.append(MaxPool2D(pool_size=(max_words - filter_sizes[i] + 1, 1))(conv))\n",
    "# z = Concatenate(axis=1)(maxpool_pool)   \n",
    "# z = Flatten()(z)\n",
    "# z = Dropout(0.1)(z)\n",
    "# outp = Dense(num_classes, activation=\"softmax\")(z)\n",
    "# model = Model(inputs=inp, outputs=outp)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras import Model\n",
    "\n",
    "from keras.layers import Bidirectional, CuDNNLSTM, LSTM, CuDNNGRU, GRU, Embedding\n",
    "from keras.layers import Dense, Input, Dropout, Activation, Conv1D, Flatten, Concatenate\n",
    "from keras.layers import SpatialDropout1D, Dropout, GlobalMaxPooling1D, MaxPooling1D\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping,ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9387, 2830)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer1 = Tokenizer()\n",
    "tokenizer1.fit_on_texts(list(df['text']))\n",
    "word_index1 = tokenizer1.word_index\n",
    "\n",
    "tokenizer2 = Tokenizer()\n",
    "tokenizer2.fit_on_texts(list(df['title']))\n",
    "word_index2 = tokenizer2.word_index\n",
    "\n",
    "len(word_index1), len(word_index2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8512, 200), (8512, 17))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features1 = len(word_index1) + 1\n",
    "max_features2 = len(word_index2) + 1\n",
    "\n",
    "max_words1 = 200\n",
    "max_words2 = 17\n",
    "\n",
    "text = tokenizer1.texts_to_sequences(df['text'])\n",
    "text = pad_sequences(text, maxlen = max_words1)\n",
    "\n",
    "title = tokenizer2.texts_to_sequences(df['title'])\n",
    "title = pad_sequences(title, maxlen = max_words2)\n",
    "\n",
    "text.shape, title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size   = 32\n",
    "epochs       = 40\n",
    "num_classes  = 21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'attention_3/Sum_1:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'attention_4/Sum_1:0' shape=(?, 64) dtype=float32>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp1 = Input(shape=(max_words1,))\n",
    "inp2 = Input(shape=(max_words2,))\n",
    "\n",
    "x1 = Embedding(max_features1, 300, trainable=True)(inp1)\n",
    "x2 = Embedding(max_features2, 300, trainable=True)(inp2)\n",
    "\n",
    "x1 = Bidirectional(LSTM(128, return_sequences=True))(x1)\n",
    "x1 = Bidirectional(LSTM(64, return_sequences=True))(x1)\n",
    "x1 = Attention(max_words1)(x1)\n",
    "\n",
    "x2 = Bidirectional(LSTM(64, return_sequences=True))(x2)\n",
    "x2 = Bidirectional(LSTM(32, return_sequences=True))(x2)\n",
    "x2 = Attention(max_words2)(x2)\n",
    "\n",
    "x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 200, 300)     2816400     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 17, 300)      849300      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 200, 256)     439296      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 17, 128)      186880      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 200, 128)     164352      bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 17, 64)       41216       bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 128)          328         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         (None, 64)           81          bidirectional_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192)          0           attention_3[0][0]                \n",
      "                                                                 attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          24704       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 21)           1365        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,532,178\n",
      "Trainable params: 4,532,178\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Concatenate(axis=-1)([x1, x2])\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(num_classes, activation=\"softmax\")(x)\n",
    "modelATT = Model(inputs=[inp1, inp2], outputs=x)\n",
    "modelATT.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=Adam(lr=1e-2), metrics=['accuracy'])\n",
    "modelATT.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5959, 5), (2553, 2))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_len = train.shape[0]\n",
    "ts_len = test.shape[0]\n",
    "# train.shape[0] + test.shape[0], df.shape[0]\n",
    "train1 = df.iloc[:tr_len]\n",
    "test1  = df.iloc[tr_len:]\n",
    "train1.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping(df, col_name):\n",
    "    cat_codes = df[col_name].astype('category')\n",
    "    \n",
    "    class_mapping = {}\n",
    "    i = 0\n",
    "    for col in cat_codes.cat.categories:\n",
    "        class_mapping[col] = i\n",
    "        i += 1\n",
    "    \n",
    "    class_mapping_reverse = {}\n",
    "    for key, value in class_mapping.items():\n",
    "        class_mapping_reverse[value] = key\n",
    "\n",
    "    return class_mapping, class_mapping_reverse\n",
    "\n",
    "cl_map, cl_map_inv = get_mapping(train1, 'topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5959, 217) (2553, 217)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4171, 217), (4171,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1['target'] = train1['topic'].astype('category').cat.codes\n",
    "train1['target'] = train1['target'].astype('int')\n",
    "\n",
    "text_title = np.concatenate([text, title], axis=1)\n",
    "tr_text_title = text_title[:tr_len]\n",
    "ts_text_title = text_title[tr_len:]\n",
    "print(tr_text_title.shape, ts_text_title.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    tr_text_title, train1['target'], shuffle=True,\n",
    "    stratify=train1['target'], test_size=0.3, random_state=1337\n",
    ")\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4171, 200), (4171, 17), (1788, 200), (1788, 17))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_text  = X_train[:,:200]\n",
    "X_tr_title = X_train[:,200:]\n",
    "\n",
    "X_ts_text  = X_test[:,:200]\n",
    "X_ts_title = X_test[:,200:]\n",
    "\n",
    "X_tr_text.shape, X_tr_title.shape, X_ts_text.shape, X_ts_title.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4171, 21), (1788, 21))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "Y_train = to_categorical(Y_train, num_classes=num_classes)\n",
    "Y_test  = to_categorical(Y_test, num_classes=num_classes)\n",
    "Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.60750658e-05, 1.85060810e-05, 1.85060810e-05, ...,\n",
       "       1.95252374e-05, 1.60750658e-05, 5.45514998e-06])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "def get_class_weights(y):\n",
    "    \"\"\" \n",
    "    Example:\n",
    "        model.fit(X_t, y, batch_size=10, epochs=2,validation_split=0.1,sample_weight=sample_wts)\n",
    "    \n",
    "    \"\"\"\n",
    "    return class_weight.compute_sample_weight('balanced', y)\n",
    "\n",
    "cls_wts = get_class_weights(Y_train)\n",
    "cls_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4171,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_wts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelATT.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=Adam(lr=1e-2), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4171 samples, validate on 1788 samples\n",
      "Epoch 1/40\n",
      "4171/4171 [==============================] - 113s 27ms/step - loss: 8.4009e-05 - acc: 0.0173 - val_loss: 3.0743 - val_acc: 0.0358\n",
      "Epoch 2/40\n",
      "4171/4171 [==============================] - 103s 25ms/step - loss: 8.3744e-05 - acc: 0.0254 - val_loss: 3.0808 - val_acc: 0.0229\n",
      "Epoch 00002: early stopping\n",
      "CPU times: user 11min 22s, sys: 58.9 s, total: 12min 21s\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "early_stop = EarlyStopping(monitor=\"val_acc\", patience=1, verbose=1)\n",
    "history    = modelATT.fit(\n",
    "    [X_tr_text, X_tr_title], Y_train,\n",
    "    validation_data = ([X_ts_text, X_ts_title], Y_test),\n",
    "    epochs          = epochs,\n",
    "    batch_size      = batch_size,\n",
    "    verbose         = 1,\n",
    "    sample_weight   = cls_wts,\n",
    "    callbacks       = [early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "\n",
    "def tfidf_feature(train, test, col_name, min_df=3, analyzer='word', \n",
    "                  token_pattern=r'\\w{1,}', ngram=3, stopwords='english', \n",
    "                  n_component=120, decom_flag=False, which_method='svd', \n",
    "                  max_features=None):\n",
    "    \"\"\"return tfidf feature\n",
    "    Args:\n",
    "        train, test: dataframe\n",
    "        col_name: column name of text feature\n",
    "        min_df: if Int, then it represent count of the minimum words in corpus (remove very rare word)\n",
    "        analyzer: [‘word’, ‘char’]\n",
    "        ngram: max range of ngram\n",
    "        token_pattern: [using: r'\\w{1,}'] [by default: '(?u)\\b\\w\\w+\\b']\n",
    "        stopwords: ['english' or customized by remove specific words]\n",
    "        n_component: n_component of svd feature transform\n",
    "        decom_flag: Wheteher to run svd/nmf on top of that or not (by default: False)\n",
    "        which_method: which to run [svd or nmf] on top of tfidf (by default: False)\n",
    "        max_features: max no of features to keep, based on frequency. It will keep words with higher freq\n",
    "    return:\n",
    "        Transformed feature space of the text data, as well as tfidf function instance\n",
    "        if svd_flag== True : train_tf, test_tf, tfv, svd\n",
    "        else : train_tf, test_tf, tfv\n",
    "    example:\n",
    "        train_tfv, test_tfv, tfv = tfidf_feature(X_train, X_test, ['text'], min_df=3)\n",
    "        train_svd, test_svd, complete_tfv, tfv, svd = tfidf_feature(X_train, X_test, ['text'], \n",
    "            min_df=3, svd_component=3, svd_flag=True)\n",
    "\n",
    "    \"\"\"\n",
    "    tfv = TfidfVectorizer(min_df=min_df,  max_features=max_features, \n",
    "                strip_accents='unicode', analyzer=analyzer, max_df=1.0, \n",
    "                token_pattern=token_pattern, ngram_range=(1, ngram), \n",
    "                use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
    "                stop_words = stopwords)\n",
    "\n",
    "    complete_df = pd.concat([train[col_name], test[col_name]], axis=0)\n",
    "#         return complete_df\n",
    "#         print(complete_df.shape, complete_df.columns)\n",
    "\n",
    "    tfv.fit(list(complete_df[:].values))\n",
    "\n",
    "    if decom_flag is False:\n",
    "        train_tfv =  tfv.transform(train[col_name].values.ravel()) \n",
    "        test_tfv  = tfv.transform(test[col_name].values.ravel())\n",
    "\n",
    "        del complete_df\n",
    "        gc.collect()\n",
    "        return train_tfv, test_tfv, tfv\n",
    "    else:\n",
    "        complete_tfv = tfv.transform(complete_df[:].values.ravel())\n",
    "        \n",
    "        if which_method is 'svd':\n",
    "            svd = TruncatedSVD(n_components=n_component)\n",
    "            svd.fit(complete_tfv)\n",
    "            complete_dec = svd.transform(complete_tfv)\n",
    "        else:\n",
    "            nmf = NMF(n_components=n_component, random_state=1234, alpha=0, l1_ratio=0)\n",
    "            nmf.fit(complete_tfv)            \n",
    "            complete_dec = nmf.fit_transform(complete_tfv)            \n",
    "        \n",
    "        \n",
    "        complete_dec = pd.DataFrame(data=complete_dec)\n",
    "        complete_dec.columns = [which_method+'_'+str(i) for i in range(n_component)]\n",
    "\n",
    "        train_dec = complete_dec.iloc[:train.shape[0]]\n",
    "        test_dec = complete_dec.iloc[train.shape[0]:].reset_index(drop=True)\n",
    "\n",
    "        del complete_dec, complete_df\n",
    "        gc.collect()\n",
    "        return train_dec, test_dec, complete_tfv, tfv\n",
    "\n",
    "def countvect_feature(train, test, col_name, min_df=3, analyzer='word', token_pattern=r'\\w{1,}', ngram=3, stopwords='english', max_features=None):\n",
    "    \"\"\"return CountVectorizer feature\n",
    "    Args:\n",
    "        train, test: dataset\n",
    "        col_name: columns name of the text feature\n",
    "        min_df: if Int, then it represent count of the minimum words in corpus (remove very rare word)\n",
    "        analyzer: [‘word’, ‘char’]\n",
    "        ngram: max range of ngram\n",
    "        token_pattern: [using: r'\\w{1,}'] [by default: '(?u)\\b\\w\\w+\\b']\n",
    "        stopwords: ['english' or customized by remove specific words]\n",
    "        max_features: max no of features to keep, based on frequency. It will keep words with higher freq\n",
    "    return:\n",
    "        Count feature space of the text data, as well as its function instance\n",
    "    \"\"\"\n",
    "    ctv = CountVectorizer(min_df=min_df,  max_features=max_features, \n",
    "                strip_accents='unicode', analyzer=analyzer, \n",
    "                token_pattern=token_pattern, ngram_range=(1, ngram), \n",
    "                stop_words = stopwords)\n",
    "\n",
    "    complete_df = pd.concat([train[col_name], test[col_name]], axis=0)\n",
    "    ctv.fit(list(complete_df[:].values))\n",
    "\n",
    "    train_tf =  ctv.transform(train[col_name].values.ravel()) \n",
    "    test_tf  = ctv.transform(test[col_name].values.ravel())\n",
    "\n",
    "    del complete_df\n",
    "    gc.collect()\n",
    "    return train_tf, test_tf, ctv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tfidfs = []\n",
    "for ngram in [1,2,3,4,5]:\n",
    "    out_tfidfs.append(tfidf_feature(train, test, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tfidf1 = tfidf_feature(train, test, 'text', ngram=1)\n",
    "out_tfidf2 = tfidf_feature(train, test, 'text', ngram=2)\n",
    "out_tfidf3 = tfidf_feature(train, test, 'text', ngram=3)\n",
    "out_tfidf4 = tfidf_feature(train, test, 'text', ngram=5)\n",
    "\n",
    "out_vect1 = countvect_feature(train, test, 'text', ngram=1)\n",
    "out_vect2 = countvect_feature(train, test, 'text', ngram=2)\n",
    "out_vect3 = countvect_feature(train, test, 'text', ngram=3)\n",
    "out_vect4 = countvect_feature(train, test, 'text', ngram=5)\n",
    "\n",
    "print('tf-idf features: ', out_tfidf1[0].shape, \n",
    "     out_tfidf2[0].shape, out_tfidf3[0].shape, out_tfidf4[0].shape)\n",
    "print('count-vect features: ', out_vect1[0].shape, \n",
    "     out_vect2[0].shape, out_vect3[0].shape, out_vect4[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = train['topic'].astype('category').cat.codes\n",
    "train['target'] = train['target'].astype('int')\n",
    "all_class = list(train['target'].unique())\n",
    "print(len(all_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['target'] == 1].shape, out_tfidf1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_tfidf1[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train, Y_train)\n",
    "# pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_tfidf1[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "clf = MultinomialNB().fit(X_train, Y_train)\n",
    "print(\"tfidf1 : \", clf.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_tfidf2[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "clf = MultinomialNB().fit(X_train, Y_train)\n",
    "print(\"tfidf2 : \", clf.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_tfidf3[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "clf = MultinomialNB().fit(X_train, Y_train)\n",
    "print(\"tfidf3 : \", clf.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_tfidf4[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "clf = MultinomialNB().fit(X_train, Y_train)\n",
    "print(\"tfidf4 : \", clf.score(X_test, Y_test))\n",
    "\n",
    "print(\"==\"*25)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_vect1[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "clf = MultinomialNB().fit(X_train, Y_train)\n",
    "print(\"count-vect1 : \", clf.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_vect2[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "clf = MultinomialNB().fit(X_train, Y_train)\n",
    "print(\"count-vect2 : \", clf.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_vect3[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "clf = MultinomialNB().fit(X_train, Y_train)\n",
    "print(\"count-vect3 : \", clf.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_vect4[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "clf = MultinomialNB().fit(X_train, Y_train)\n",
    "print(\"count-vect4 : \", clf.score(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(penalty='l2', dual=False, \n",
    "    C=0.01, fit_intercept=True, intercept_scaling=1, class_weight='balanced', \n",
    "    random_state=1234, max_iter=100, multi_class='warn', verbose=0, n_jobs=-1)\n",
    "logistic_reg.fit(X_train, Y_train)\n",
    "print(logistic_reg.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_tfidf1[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "logistic_reg.fit(X_train, Y_train)\n",
    "print(\"tfidf1 : \", logistic_reg.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_tfidf2[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "logistic_reg.fit(X_train, Y_train)\n",
    "print(\"tfidf2 : \", logistic_reg.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_tfidf3[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "logistic_reg.fit(X_train, Y_train)\n",
    "print(\"tfidf3 : \", logistic_reg.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_tfidf4[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "logistic_reg.fit(X_train, Y_train)\n",
    "print(\"tfidf4 : \", logistic_reg.score(X_test, Y_test))\n",
    "\n",
    "print(\"==\"*25)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_vect1[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "logistic_reg.fit(X_train, Y_train)\n",
    "print(\"count-vect1 : \", logistic_reg.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_vect2[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "logistic_reg.fit(X_train, Y_train)\n",
    "print(\"count-vect2 : \", logistic_reg.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_vect3[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "logistic_reg.fit(X_train, Y_train)\n",
    "print(\"count-vect3 : \", logistic_reg.score(X_test, Y_test))\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    out_vect4[0], train['target'], stratify=train['target'], test_size=0.3\n",
    ")\n",
    "logistic_reg.fit(X_train, Y_train)\n",
    "print(\"count-vect4 : \", logistic_reg.score(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('Dataset/Sample_Submission.csv')\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg.fit(out_vect3[0], train['target'])\n",
    "pred = logistic_reg.predict(out_vect3[1])\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def category_encoder(df)\n",
    "test.drop('topic', axis=1, inplace=True)\n",
    "test['target'] = pred\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['topic'] = test['target'].apply(lambda x: class_mapping_reverse[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('target', axis=1, inplace=True)\n",
    "# os.makedirs('submission')\n",
    "test.to_csv('submission/linear_model1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping(df, col_name):\n",
    "    cat_codes = df[col_name].astype('category')\n",
    "    \n",
    "    class_mapping = {}\n",
    "    i = 0\n",
    "    for col in cat_codes.cat.categories:\n",
    "        class_mapping[col] = i\n",
    "        i += 1\n",
    "    \n",
    "    class_mapping_reverse = {}\n",
    "    for key, value in class_mapping.items():\n",
    "        class_mapping_reverse[value] = key\n",
    "\n",
    "    return class_mapping, class_mapping_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping, class_mapping_reverse = get_mapping(train, 'topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "params = {}\n",
    "params['alpha'] = 1\n",
    "passive_agg = PassiveAggressiveClassifier(C=params['alpha'], early_stopping=False, validation_fraction=0.3, n_iter_no_change=5, shuffle=True, verbose=0, n_jobs=-1, random_state=1234, loss='hinge', class_weight='balanced', average=False, n_iter=None)\n",
    "ridge_clf = RidgeClassifier(alpha=params['alpha'], fit_intercept=True, normalize=True, class_weight='balanced', random_state=1234)\n",
    "logistic_reg = LogisticRegression(penalty='l2', dual=False, C=params['alpha'], fit_intercept=True, intercept_scaling=1, class_weight='balanced', random_state=1234, max_iter=100, multi_class='warn', verbose=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_clf.fit(X_train, Y_train)\n",
    "print(ridge_clf.score(X_test, Y_test))\n",
    "print(\"==============\")\n",
    "\n",
    "passive_agg.fit(X_train, Y_train)\n",
    "print(passive_agg.score(X_test, Y_test))\n",
    "print(\"==============\")\n",
    "\n",
    "logistic_reg.fit(X_train, Y_train)\n",
    "print(logistic_reg.score(X_test, Y_test))\n",
    "print(\"==============\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for alpha in [0.01, 0.1, 0.5, 1, 5, 10]:\n",
    "    logistic_reg = LogisticRegression(penalty='l2', dual=False, \n",
    "        C=alpha, fit_intercept=True, intercept_scaling=1, class_weight='balanced', \n",
    "        random_state=1234, max_iter=100, multi_class='warn', verbose=0, n_jobs=-1)\n",
    "    logistic_reg.fit(X_train, Y_train)\n",
    "    pred = logistic_reg.score(X_test, Y_test)\n",
    "    print(pred)\n",
    "#     print(f1_score(ts_y, pred, average='micro', sample_weight=None))\n",
    "#     print(logistic_reg.score(ts_x, ts_y))\n",
    "print(\"==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for alpha in np.linspace(0.0001,0.1,10):\n",
    "    logistic_reg = LogisticRegression(penalty='l2', dual=False, \n",
    "        C=alpha, fit_intercept=True, intercept_scaling=1, class_weight='balanced', \n",
    "        random_state=1234, max_iter=100, multi_class='warn', verbose=0, n_jobs=-1)\n",
    "    logistic_reg.fit(X_train, Y_train)\n",
    "    pred = logistic_reg.score(X_test, Y_test)\n",
    "    print(alpha, \" : \", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Usage: plot_document_classification_20newsgroups.py [options]\n",
    "\n",
    "Options:\n",
    "  -h, --help            show this help message and exit\n",
    "  --report              Print a detailed classification report.\n",
    "  --chi2_select=SELECT_CHI2\n",
    "                        Select some number of features using a chi-squared\n",
    "                        test\n",
    "  --confusion_matrix    Print the confusion matrix.\n",
    "  --top10               Print ten most discriminative terms per class for\n",
    "                        every classifier.\n",
    "  --all_categories      Whether to use all categories or not.\n",
    "  --use_hashing         Use a hashing vectorizer.\n",
    "  --n_features=N_FEATURES\n",
    "                        n_features when using the hashing vectorizer.\n",
    "  --filtered            Remove newsgroup information that is easily overfit:\n",
    "                        headers, signatures, and quoting.\n",
    "\n",
    "Loading 20 newsgroups dataset for categories:\n",
    "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "data loaded\n",
    "2034 documents - 3.980MB (training set)\n",
    "1353 documents - 2.867MB (test set)\n",
    "4 categories\n",
    "\n",
    "Extracting features from the training data using a sparse vectorizer\n",
    "done in 0.412178s at 9.655MB/s\n",
    "n_samples: 2034, n_features: 33809\n",
    "\n",
    "Extracting features from the test data using the same vectorizer\n",
    "done in 0.351330s at 8.162MB/s\n",
    "n_samples: 1353, n_features: 33809\n",
    "\n",
    "================================================================================\n",
    "Ridge Classifier\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "RidgeClassifier(solver='sag', tol=0.01)\n",
    "train time: 0.132s\n",
    "test time:  0.001s\n",
    "accuracy:   0.896\n",
    "dimensionality: 33809\n",
    "density: 1.000000\n",
    "\n",
    "\n",
    "================================================================================\n",
    "Perceptron\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "Perceptron(max_iter=50)\n",
    "train time: 0.017s\n",
    "test time:  0.002s\n",
    "accuracy:   0.888\n",
    "dimensionality: 33809\n",
    "density: 0.255302\n",
    "\n",
    "\n",
    "================================================================================\n",
    "Passive-Aggressive\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "PassiveAggressiveClassifier(max_iter=50)\n",
    "train time: 0.031s\n",
    "test time:  0.002s\n",
    "accuracy:   0.904\n",
    "dimensionality: 33809\n",
    "density: 0.694674\n",
    "\n",
    "\n",
    "================================================================================\n",
    "kNN\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "KNeighborsClassifier(n_neighbors=10)\n",
    "train time: 0.002s\n",
    "test time:  0.317s\n",
    "accuracy:   0.858\n",
    "\n",
    "================================================================================\n",
    "Random forest\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "RandomForestClassifier(n_estimators=100)\n",
    "train time: 1.671s\n",
    "test time:  0.071s\n",
    "accuracy:   0.840\n",
    "\n",
    "================================================================================\n",
    "L2 penalty\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "LinearSVC(dual=False, tol=0.001)\n",
    "train time: 0.145s\n",
    "test time:  0.002s\n",
    "accuracy:   0.900\n",
    "dimensionality: 33809\n",
    "density: 1.000000\n",
    "\n",
    "\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "SGDClassifier(max_iter=50)\n",
    "train time: 0.030s\n",
    "test time:  0.002s\n",
    "accuracy:   0.902\n",
    "dimensionality: 33809\n",
    "density: 0.579380\n",
    "\n",
    "\n",
    "================================================================================\n",
    "L1 penalty\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "LinearSVC(dual=False, penalty='l1', tol=0.001)\n",
    "train time: 0.301s\n",
    "test time:  0.002s\n",
    "accuracy:   0.873\n",
    "dimensionality: 33809\n",
    "density: 0.005553\n",
    "\n",
    "\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "SGDClassifier(max_iter=50, penalty='l1')\n",
    "train time: 0.093s\n",
    "test time:  0.002s\n",
    "accuracy:   0.887\n",
    "dimensionality: 33809\n",
    "density: 0.022901\n",
    "\n",
    "\n",
    "================================================================================\n",
    "Elastic-Net penalty\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "SGDClassifier(max_iter=50, penalty='elasticnet')\n",
    "train time: 0.252s\n",
    "test time:  0.002s\n",
    "accuracy:   0.899\n",
    "dimensionality: 33809\n",
    "density: 0.187472\n",
    "\n",
    "\n",
    "================================================================================\n",
    "NearestCentroid (aka Rocchio classifier)\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "NearestCentroid()\n",
    "train time: 0.004s\n",
    "test time:  0.002s\n",
    "accuracy:   0.855\n",
    "\n",
    "================================================================================\n",
    "Naive Bayes\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "MultinomialNB(alpha=0.01)\n",
    "train time: 0.003s\n",
    "test time:  0.001s\n",
    "accuracy:   0.899\n",
    "dimensionality: 33809\n",
    "density: 1.000000\n",
    "\n",
    "\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "BernoulliNB(alpha=0.01)\n",
    "train time: 0.004s\n",
    "test time:  0.003s\n",
    "accuracy:   0.884\n",
    "dimensionality: 33809\n",
    "density: 1.000000\n",
    "\n",
    "\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "ComplementNB(alpha=0.1)\n",
    "train time: 0.004s\n",
    "test time:  0.001s\n",
    "accuracy:   0.911\n",
    "dimensionality: 33809\n",
    "density: 1.000000\n",
    "\n",
    "\n",
    "================================================================================\n",
    "LinearSVC with L1-based feature selection\n",
    "________________________________________________________________________________\n",
    "Training:\n",
    "Pipeline(steps=[('feature_selection',\n",
    "                 SelectFromModel(estimator=LinearSVC(dual=False, penalty='l1',\n",
    "                                                     tol=0.001))),\n",
    "                ('classification', LinearSVC())])\n",
    "train time: 0.252s\n",
    "test time:  0.002s\n",
    "accuracy:   0.880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_train[i] # feature count vector for training case i\n",
    "# y_train[i] # label for training case i\n",
    "\n",
    "# The count vectors are defined as:\n",
    "\n",
    "# p = sum of all feature count vectors with label 1\n",
    "\n",
    "# p = tf_train[y_train==1].sum(0) + 1\n",
    "\n",
    "# q = sum of all feature count vectors with label 0\n",
    "\n",
    "# q = tf_train[y_train==0].sum(0) + 1\n",
    "\n",
    "# Notice that we add 1 to both count vectors to ensure that every token appear at least one time in each class.\n",
    "\n",
    "# The log-count ratio r is:\n",
    "\n",
    "# r = np.log((p/p.sum()) / (q/q.sum()))\n",
    "\n",
    "# And b:\n",
    "\n",
    "# b = np.log(len(p) / len(q))\n",
    "\n",
    "# Just the ratio of number of positive and negative training cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_preds = tf_test @ r.T + b\n",
    "preds = pre_preds.T > 0\n",
    "accuracy = (preds == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tfidf1[0][train['target'] == 5].sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tfidf1[0][train['target'] == 4].sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.equal(out_tfidf1[0][train['target'] == 5].sum(0), \n",
    "                out_tfidf1[0][train['target'] == 3].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tfidf1[0][train['target'] == 5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tfidf1[0][train['target'] == 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train[train['target'] == 2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tfidf1[0][idx].sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts):\n",
    "    output = []\n",
    "    for i in texts:\n",
    "        s = [token.lemma_ for token in nlp(i)]\n",
    "        output.append(' '.join(s))\n",
    "    return output\n",
    "\n",
    "# train['text1'] = train['text'].progress_apply(lemmatization)\n",
    "# test['text1']  = test['text'].progress_apply(lemmatization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.append(test, ignore_index=True)\n",
    "df['text1'] = df['text'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:5]['text'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(text):\n",
    "    return []\n",
    "    for i in texts:\n",
    "        s = [token.lemma_ for token in nlp(i)]\n",
    "        output.append(' '.join(s))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_tokenize(df1['text'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter=PorterStemmer()\n",
    "\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter=PorterStemmer()\n",
    "porter.stem('helping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in df1['text'][1].split(\" \"):\n",
    "    print(porter.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del df1, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.append(test, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "cv = CountVectorizer(max_df=0.95,min_df=2,stop_words='english')\n",
    "term_matrix = cv.fit_transform(df['text'])\n",
    "# print(term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, n_jobs=4)\n",
    "lda.fit(term_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = lda.components_[0]\n",
    "top_words_indices = topic.argsort()[-10:]\n",
    "for index in top_words_indices:\n",
    "    print(cv.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word_dict = {}\n",
    "for index,topic in enumerate(lda.components_):\n",
    "    words = [cv.get_feature_names()[i] for i in topic.argsort()[-10:]]\n",
    "    topic_word_dict[index] = words\n",
    "    print('Top words for topic {}'.format(index))\n",
    "    print(words)\n",
    "    print('-'*120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topics = lda.transform(term_matrix)\n",
    "data['topic'] = topics.argmax(axis=1)\n",
    "\n",
    "\n",
    "def assign_topics(row):\n",
    "    topic = row['topic']\n",
    "    words = topic_word_dict[topic]\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "data['topic words'] = data.apply(assign_topics,axis=1)\n",
    "print(data.head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
