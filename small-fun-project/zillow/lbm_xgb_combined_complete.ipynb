{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "# gc ==> garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zillow_data_dictionary.xlsx',\n",
       " 'sample_submission.csv',\n",
       " 'properties_2016.csv',\n",
       " 'train_2016_v2.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading data from disk ...\n"
     ]
    }
   ],
   "source": [
    "##### READ IN RAW DATA\n",
    "\n",
    "print( \"\\nReading data from disk ...\")\n",
    "prop = pd.read_csv('data/properties_2016.csv')\n",
    "train = pd.read_csv(\"data/train_2016_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing data for LightGBM ...\n"
     ]
    }
   ],
   "source": [
    "##### PROCESS DATA FOR LIGHTGBM\n",
    "\n",
    "print( \"\\nProcessing data for LightGBM ...\" )\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\t\n",
    "    if dtype == np.float64:\n",
    "        prop[c] = prop[c].astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90275, 53) (90275,)\n"
     ]
    }
   ],
   "source": [
    "df_train = train.merge(prop, how='left', on='parcelid')\n",
    "df_train.fillna(df_train.median(),inplace = True)\n",
    "\n",
    "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', \n",
    "                         'propertyzoningdesc', 'propertycountylandusecode', \n",
    "                         'fireplacecnt', 'fireplaceflag'], axis=1)\n",
    "y_train = df_train['logerror'].values\n",
    "print(x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hashottuborspa', 'taxdelinquencyflag'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtypes[x_train.dtypes == object].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0], dtype=object), array([nan, 'Y'], dtype=object))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['hashottuborspa'].unique(), x_train['taxdelinquencyflag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns = x_train.columns\n",
    "\n",
    "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
    "    x_train[c] = (x_train[c] == True)\n",
    "\n",
    "del df_train; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True]), array([False]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['hashottuborspa'].unique(), x_train['taxdelinquencyflag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    False\n",
       " 1    False\n",
       " 2    False\n",
       " 3    False\n",
       " 4    False\n",
       " Name: taxdelinquencyflag, dtype: bool, 0    True\n",
       " 1    True\n",
       " 2    True\n",
       " 3    True\n",
       " 4    True\n",
       " Name: hashottuborspa, dtype: bool)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['taxdelinquencyflag'].head(), x_train['hashottuborspa'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 90275 entries, 0 to 90274\n",
      "Data columns (total 53 columns):\n",
      "airconditioningtypeid           90275 non-null float32\n",
      "architecturalstyletypeid        90275 non-null float32\n",
      "basementsqft                    90275 non-null float32\n",
      "bathroomcnt                     90275 non-null float32\n",
      "bedroomcnt                      90275 non-null float32\n",
      "buildingclasstypeid             90275 non-null float32\n",
      "buildingqualitytypeid           90275 non-null float32\n",
      "calculatedbathnbr               90275 non-null float32\n",
      "decktypeid                      90275 non-null float32\n",
      "finishedfloor1squarefeet        90275 non-null float32\n",
      "calculatedfinishedsquarefeet    90275 non-null float32\n",
      "finishedsquarefeet12            90275 non-null float32\n",
      "finishedsquarefeet13            90275 non-null float32\n",
      "finishedsquarefeet15            90275 non-null float32\n",
      "finishedsquarefeet50            90275 non-null float32\n",
      "finishedsquarefeet6             90275 non-null float32\n",
      "fips                            90275 non-null float32\n",
      "fullbathcnt                     90275 non-null float32\n",
      "garagecarcnt                    90275 non-null float32\n",
      "garagetotalsqft                 90275 non-null float32\n",
      "hashottuborspa                  90275 non-null bool\n",
      "heatingorsystemtypeid           90275 non-null float32\n",
      "latitude                        90275 non-null float32\n",
      "longitude                       90275 non-null float32\n",
      "lotsizesquarefeet               90275 non-null float32\n",
      "poolcnt                         90275 non-null float32\n",
      "poolsizesum                     90275 non-null float32\n",
      "pooltypeid10                    90275 non-null float32\n",
      "pooltypeid2                     90275 non-null float32\n",
      "pooltypeid7                     90275 non-null float32\n",
      "propertylandusetypeid           90275 non-null float32\n",
      "rawcensustractandblock          90275 non-null float32\n",
      "regionidcity                    90275 non-null float32\n",
      "regionidcounty                  90275 non-null float32\n",
      "regionidneighborhood            90275 non-null float32\n",
      "regionidzip                     90275 non-null float32\n",
      "roomcnt                         90275 non-null float32\n",
      "storytypeid                     90275 non-null float32\n",
      "threequarterbathnbr             90275 non-null float32\n",
      "typeconstructiontypeid          90275 non-null float32\n",
      "unitcnt                         90275 non-null float32\n",
      "yardbuildingsqft17              90275 non-null float32\n",
      "yardbuildingsqft26              90275 non-null float32\n",
      "yearbuilt                       90275 non-null float32\n",
      "numberofstories                 90275 non-null float32\n",
      "structuretaxvaluedollarcnt      90275 non-null float32\n",
      "taxvaluedollarcnt               90275 non-null float32\n",
      "assessmentyear                  90275 non-null float32\n",
      "landtaxvaluedollarcnt           90275 non-null float32\n",
      "taxamount                       90275 non-null float32\n",
      "taxdelinquencyflag              90275 non-null bool\n",
      "taxdelinquencyyear              90275 non-null float32\n",
      "censustractandblock             90275 non-null float32\n",
      "dtypes: bool(2), float32(51)\n",
      "memory usage: 18.4 MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RUN LIGHTGBM\n",
    "\n",
    "params = {}\n",
    "params['max_bin'] = 10\n",
    "params['learning_rate'] = 0.0021 # shrinkage_rate\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'l1'          # or 'mae'\n",
    "params['sub_feature'] = 0.5      # feature_fraction -- OK, back to .5, but maybe later increase this\n",
    "params['bagging_fraction'] = 0.85 # sub_row\n",
    "params['bagging_freq'] = 40\n",
    "params['num_leaves'] = 512        # num_leaf\n",
    "params['min_data'] = 500         # min_data_in_leaf\n",
    "params['min_hessian'] = 0.05     # min_sum_hessian_in_leaf\n",
    "params['verbose'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(x_train, y_train)\n",
    "d_eval = lgb.Dataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit lightgbm model\n"
     ]
    }
   ],
   "source": [
    "print(\"fit lightgbm model\")\n",
    "clf = lgb.train(params, d_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nArrays are not almost equal to 7 decimals\n\n(mismatch 100.0%)\n x: array([0.0108497, 0.0113083, 0.0082246, ..., 0.0140485, 0.0103898,\n       0.0144195])\n y: array([ 0.0276, -0.1684, -0.004 , ..., -0.2679,  0.0602,  0.4207])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-eb01feefbd5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/testing/nose_tools/utils.py\u001b[0m in \u001b[0;36massert_almost_equal\u001b[0;34m(actual, desired, decimal, err_msg, verbose)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0massert_array_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# If one of desired/actual is not finite, handle it specially here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/testing/nose_tools/utils.py\u001b[0m in \u001b[0;36massert_array_almost_equal\u001b[0;34m(x, y, decimal, err_msg, verbose)\u001b[0m\n\u001b[1;32m    961\u001b[0m     assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,\n\u001b[1;32m    962\u001b[0m              \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Arrays are not almost equal to %d decimals'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdecimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m              precision=decimal)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/testing/nose_tools/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    777\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not almost equal to 7 decimals\n\n(mismatch 100.0%)\n x: array([0.0108497, 0.0113083, 0.0082246, ..., 0.0140485, 0.0103898,\n       0.0144195])\n y: array([ 0.0276, -0.1684, -0.004 , ..., -0.2679,  0.0602,  0.4207])"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(x_train)\n",
    "np.testing.assert_almost_equal(pred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting LightGBM model ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Training only accepts Dataset object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-131fdc3ce5db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFitting LightGBM model ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m430\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# check dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training only accepts Dataset object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Training only accepts Dataset object"
     ]
    }
   ],
   "source": [
    "print(\"\\nFitting LightGBM model ...\")\n",
    "clf = lgb.train(params, d_train, 430)\n",
    "\n",
    "del d_train; gc.collect()\n",
    "del x_train; gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lgb_train = lgb.Dataset(X_train, y_train)\n",
    "# lgb_eval = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "# params = {\n",
    "#     'objective': 'regression',\n",
    "#     'metric': 'auc',\n",
    "#     'verbose': -1,\n",
    "#     'boost_from_average': False,\n",
    "#     'min_data': 1,\n",
    "#     'num_leaves': 2,\n",
    "#     'learning_rate': 1,\n",
    "#     'min_data_in_bin': 1,\n",
    "#     'min_data_per_group': 1,\n",
    "#     'cat_smooth': 1,\n",
    "#     'cat_l2': 0,\n",
    "#     'max_cat_to_onehot': 1,\n",
    "#     'zero_as_missing': True,\n",
    "#     'categorical_column': 0\n",
    "# }\n",
    "# evals_result = {}\n",
    "# gbm = lgb.train(params, lgb_train,\n",
    "#                 num_boost_round=1,\n",
    "#                 valid_sets=lgb_eval,\n",
    "#                 verbose_eval=True,\n",
    "#                 evals_result=evals_result)\n",
    "# pred = gbm.predict(X_train)\n",
    "# np.testing.assert_almost_equal(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting LightGBM model ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d_train\n",
    "x_train = x_train.values.astype(np.float32, copy=False)\n",
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "\n",
    "##### RUN LIGHTGBM\n",
    "\n",
    "params = {}\n",
    "params['max_bin'] = 10\n",
    "params['learning_rate'] = 0.0021 # shrinkage_rate\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'l1'          # or 'mae'\n",
    "params['sub_feature'] = 0.5      # feature_fraction -- OK, back to .5, but maybe later increase this\n",
    "params['bagging_fraction'] = 0.85 # sub_row\n",
    "params['bagging_freq'] = 40\n",
    "params['num_leaves'] = 512        # num_leaf\n",
    "params['min_data'] = 500         # min_data_in_leaf\n",
    "params['min_hessian'] = 0.05     # min_sum_hessian_in_leaf\n",
    "params['verbose'] = 0\n",
    "\n",
    "print(\"\\nFitting LightGBM model ...\")\n",
    "clf = lgb.train(params, d_train, 430)\n",
    "\n",
    "del d_train; gc.collect()\n",
    "del x_train; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zillow_data_dictionary.xlsx',\n",
       " 'sample_submission.csv',\n",
       " 'properties_2016.csv',\n",
       " 'train_2016_v2.csv']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepare for LightGBM prediction ...\n",
      "   Read sample file ...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrepare for LightGBM prediction ...\")\n",
    "print(\"   Read sample file ...\")\n",
    "sample = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParcelId  201610  201611  201612  201710  201711  201712\n",
       "0  10754147       0       0       0       0       0       0\n",
       "1  10759547       0       0       0       0       0       0\n",
       "2  10843547       0       0       0       0       0       0\n",
       "3  10859147       0       0       0       0       0       0\n",
       "4  10879947       0       0       0       0       0       0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can force the Garbage Collector to release unreferenced\n",
    "# memory with gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airconditioningtypeid', 'architecturalstyletypeid', 'basementsqft',\n",
       "       'bathroomcnt', 'bedroomcnt', 'buildingclasstypeid',\n",
       "       'buildingqualitytypeid', 'calculatedbathnbr', 'decktypeid',\n",
       "       'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet',\n",
       "       'finishedsquarefeet12', 'finishedsquarefeet13', 'finishedsquarefeet15',\n",
       "       'finishedsquarefeet50', 'finishedsquarefeet6', 'fips', 'fullbathcnt',\n",
       "       'garagecarcnt', 'garagetotalsqft', 'hashottuborspa',\n",
       "       'heatingorsystemtypeid', 'latitude', 'longitude', 'lotsizesquarefeet',\n",
       "       'poolcnt', 'poolsizesum', 'pooltypeid10', 'pooltypeid2', 'pooltypeid7',\n",
       "       'propertylandusetypeid', 'rawcensustractandblock', 'regionidcity',\n",
       "       'regionidcounty', 'regionidneighborhood', 'regionidzip', 'roomcnt',\n",
       "       'storytypeid', 'threequarterbathnbr', 'typeconstructiontypeid',\n",
       "       'unitcnt', 'yardbuildingsqft17', 'yardbuildingsqft26', 'yearbuilt',\n",
       "       'numberofstories', 'structuretaxvaluedollarcnt', 'taxvaluedollarcnt',\n",
       "       'assessmentyear', 'landtaxvaluedollarcnt', 'taxamount',\n",
       "       'taxdelinquencyflag', 'taxdelinquencyyear', 'censustractandblock'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Merge with property data ...\n",
      "   ...\n",
      "   ...\n",
      "   ...\n",
      "   Preparing x_test...\n",
      "   ...\n"
     ]
    }
   ],
   "source": [
    "sample['parcelid'] = sample['ParcelId']\n",
    "print(\"   Merge with property data ...\")\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "print(\"   ...\")\n",
    "del sample, prop; gc.collect()\n",
    "\n",
    "print(\"   ...\")\n",
    "x_test = df_test[train_columns]\n",
    "print(\"   ...\")\n",
    "del df_test; gc.collect()\n",
    "print(\"   Preparing x_test...\")\n",
    "\n",
    "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "    x_test[c] = (x_test[c] == True)\n",
    "print(\"   ...\")\n",
    "x_test = x_test.values.astype(np.float32, copy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start LightGBM prediction ...\n",
      "\n",
      "Unadjusted LightGBM predictions:\n",
      "          0\n",
      "0  0.035491\n",
      "1  0.038709\n",
      "2  0.009419\n",
      "3  0.007204\n",
      "4  0.008871\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStart LightGBM prediction ...\")\n",
    "# num_threads > 1 will predict very slow in kernal\n",
    "clf.reset_parameter({\"num_threads\":1})\n",
    "p_test = clf.predict(x_test)\n",
    "\n",
    "del x_test; gc.collect()\n",
    "\n",
    "print( \"\\nUnadjusted LightGBM predictions:\" )\n",
    "print( pd.DataFrame(p_test).head() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Re-reading properties file ...\n",
      "\n",
      "Processing data for XGBoost ...\n"
     ]
    }
   ],
   "source": [
    "##### RE-READ PROPERTIES FILE\n",
    "##### (I tried keeping a copy, but the program crashed.)\n",
    "\n",
    "print( \"\\nRe-reading properties file ...\")\n",
    "properties = pd.read_csv('data/properties_2016.csv')\n",
    "\n",
    "\n",
    "\n",
    "##### PROCESS DATA FOR XGBOOST\n",
    "\n",
    "print( \"\\nProcessing data for XGBoost ...\")\n",
    "count  = 0\n",
    "for c in properties.columns:\n",
    "    properties[c]=properties[c].fillna(-1)\n",
    "    if properties[c].dtype == 'object':\n",
    "        count += 1\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(properties[c].values))\n",
    "        properties[c] = lbl.transform(list(properties[c].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (90275, 57)\n",
      "Shape test: (2985217, 57)\n"
     ]
    }
   ],
   "source": [
    "train_df = train.merge(properties, how='left', on='parcelid')\n",
    "x_train = train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\n",
    "x_test = properties.drop(['parcelid'], axis=1)\n",
    "# shape        \n",
    "print('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing outliers:\n",
      "Shape train: (88525, 57)\n",
      "Shape test: (2985217, 57)\n"
     ]
    }
   ],
   "source": [
    "# drop out ouliers\n",
    "train_df=train_df[ train_df.logerror > -0.4 ]\n",
    "train_df=train_df[ train_df.logerror < 0.418 ]\n",
    "x_train=train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\n",
    "y_train = train_df[\"logerror\"].values.astype(np.float32)\n",
    "y_mean = np.mean(y_train)\n",
    "\n",
    "print('After removing outliers:')     \n",
    "print('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up data for XGBoost ...\n",
      "\n",
      "XGBoost tuned with CV in:\n",
      "   https://www.kaggle.com/aharless/xgboost-without-outliers-tweak \n",
      "num_boost_rounds=242\n",
      "\n",
      "Training XGBoost ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "##### RUN XGBOOST\n",
    "\n",
    "print(\"\\nSetting up data for XGBoost ...\")\n",
    "# xgboost params\n",
    "xgb_params = {\n",
    "    'eta': 0.037,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'lambda': 0.8,   \n",
    "    'alpha': 0.4, \n",
    "    'base_score': y_mean,\n",
    "    'silent': 1\n",
    "}\n",
    "# Enough with the ridiculously overfit parameters.\n",
    "# I'm going back to my version 20 instead of copying Jayaraman.\n",
    "# I want a num_boost_rounds that's chosen by my CV,\n",
    "# not one that's chosen by overfitting the public leaderboard.\n",
    "# (There may be underlying differences between the train and test data\n",
    "#  that will affect some parameters, but they shouldn't affect that.)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "# cross-validation\n",
    "#print( \"Running XGBoost CV ...\" )\n",
    "#cv_result = xgb.cv(xgb_params, \n",
    "#                   dtrain, \n",
    "#                   nfold=5,\n",
    "#                   num_boost_round=350,\n",
    "#                   early_stopping_rounds=50,\n",
    "#                   verbose_eval=10, \n",
    "#                   show_stdv=False\n",
    "#                  )\n",
    "#num_boost_rounds = len(cv_result)\n",
    "\n",
    "# num_boost_rounds = 150\n",
    "num_boost_rounds = 242\n",
    "print(\"\\nXGBoost tuned with CV in:\")\n",
    "print(\"   https://www.kaggle.com/aharless/xgboost-without-outliers-tweak \")\n",
    "print(\"num_boost_rounds=\"+str(num_boost_rounds))\n",
    "\n",
    "# train model\n",
    "print( \"\\nTraining XGBoost ...\")\n",
    "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting with XGBoost ...\n",
      "\n",
      "XGBoost predictions:\n",
      "          0\n",
      "0 -0.040630\n",
      "1 -0.034169\n",
      "2  0.055068\n",
      "3  0.084436\n",
      "4 -0.000358\n"
     ]
    }
   ],
   "source": [
    "print( \"\\nPredicting with XGBoost ...\")\n",
    "xgb_pred = model.predict(dtest)\n",
    "\n",
    "print( \"\\nXGBoost predictions:\" )\n",
    "print( pd.DataFrame(xgb_pred).head() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2985217,), (2985217,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test.shape,xgb_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "XGB_WEIGHT = 0.6500\n",
    "BASELINE_WEIGHT = 0.0056\n",
    "\n",
    "BASELINE_PRED = 0.0115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.44e-05"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASELINE_PRED*BASELINE_WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combining XGBoost, LightGBM, and baseline predicitons ...\n",
      "\n",
      "Combined predictions:\n",
      "          0\n",
      "0 -0.014122\n",
      "1 -0.008814\n",
      "2  0.039102\n",
      "3  0.057429\n",
      "4  0.002887\n"
     ]
    }
   ],
   "source": [
    "##### COMBINE PREDICTIONS\n",
    "\n",
    "print( \"\\nCombining XGBoost, LightGBM, and baseline predicitons ...\" )\n",
    "lgb_weight = 1 - XGB_WEIGHT - BASELINE_WEIGHT\n",
    "pred = XGB_WEIGHT*xgb_pred + BASELINE_WEIGHT*BASELINE_PRED + lgb_weight*p_test\n",
    "\n",
    "print( \"\\nCombined predictions:\" )\n",
    "print( pd.DataFrame(pred).head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing results for write ...\n"
     ]
    }
   ],
   "source": [
    "##### WRITE THE RESULTS\n",
    "\n",
    "print( \"\\nPreparing results for write ...\" )\n",
    "y_pred=[]\n",
    "\n",
    "for i,predict in enumerate(pred):\n",
    "    y_pred.append(str(round(predict,4)))\n",
    "y_pred=np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'ParcelId': properties['parcelid'].astype(np.int32),\n",
    "        '201610': y_pred, '201611': y_pred, '201612': y_pred,\n",
    "        '201710': y_pred, '201711': y_pred, '201712': y_pred})\n",
    "# set col 'ParceID' to first col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = output.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "output = output[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing results to disk ...\n",
      "\n",
      "Finished ...\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print( \"\\nWriting results to disk ...\" )\n",
    "output.to_csv('sub{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False)\n",
    "\n",
    "print( \"\\nFinished ...\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
