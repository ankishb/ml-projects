{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os, gc\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((341424, 24), (146765, 23), (146765, 2), (24, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df  = pd.read_csv('data/test.csv')\n",
    "sub_df   = pd.read_csv('data/sample_submission.csv')\n",
    "info_df  = pd.read_csv('data/data_dict.csv')\n",
    "\n",
    "train_df.shape, test_df.shape, sub_df.shape, info_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booking_date</th>\n",
       "      <th>checkin_date</th>\n",
       "      <th>checkout_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23/01/15</td>\n",
       "      <td>11/04/15</td>\n",
       "      <td>16/04/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28/01/15</td>\n",
       "      <td>01/02/15</td>\n",
       "      <td>05/02/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02/05/15</td>\n",
       "      <td>11/06/15</td>\n",
       "      <td>16/06/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02/09/15</td>\n",
       "      <td>14/12/15</td>\n",
       "      <td>19/12/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01/12/15</td>\n",
       "      <td>12/01/16</td>\n",
       "      <td>13/01/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20/01/16</td>\n",
       "      <td>20/01/16</td>\n",
       "      <td>21/01/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22/08/16</td>\n",
       "      <td>20/10/16</td>\n",
       "      <td>25/10/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10/09/16</td>\n",
       "      <td>18/09/16</td>\n",
       "      <td>24/09/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>03/08/16</td>\n",
       "      <td>21/11/16</td>\n",
       "      <td>24/11/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>03/02/17</td>\n",
       "      <td>28/02/17</td>\n",
       "      <td>01/03/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23/09/17</td>\n",
       "      <td>18/10/17</td>\n",
       "      <td>20/10/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25/01/18</td>\n",
       "      <td>25/01/18</td>\n",
       "      <td>26/01/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28/01/18</td>\n",
       "      <td>06/04/18</td>\n",
       "      <td>08/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>08/03/12</td>\n",
       "      <td>11/03/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "      <td>07/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21/01/15</td>\n",
       "      <td>21/01/15</td>\n",
       "      <td>23/01/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>03/08/15</td>\n",
       "      <td>13/10/15</td>\n",
       "      <td>16/10/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>03/08/15</td>\n",
       "      <td>09/10/15</td>\n",
       "      <td>13/10/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24/11/16</td>\n",
       "      <td>18/01/17</td>\n",
       "      <td>22/01/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24/11/16</td>\n",
       "      <td>22/01/17</td>\n",
       "      <td>25/01/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24/11/16</td>\n",
       "      <td>25/01/17</td>\n",
       "      <td>27/01/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30/12/17</td>\n",
       "      <td>19/01/18</td>\n",
       "      <td>22/01/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>22/10/18</td>\n",
       "      <td>07/11/18</td>\n",
       "      <td>09/11/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25/03/15</td>\n",
       "      <td>05/04/15</td>\n",
       "      <td>07/04/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28/03/15</td>\n",
       "      <td>02/04/15</td>\n",
       "      <td>05/04/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>22/02/16</td>\n",
       "      <td>27/03/16</td>\n",
       "      <td>29/03/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>05/10/16</td>\n",
       "      <td>17/10/16</td>\n",
       "      <td>20/10/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>02/01/17</td>\n",
       "      <td>28/04/17</td>\n",
       "      <td>29/04/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "      <td>07/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>04/11/15</td>\n",
       "      <td>20/11/15</td>\n",
       "      <td>21/11/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>31/03/18</td>\n",
       "      <td>13/04/18</td>\n",
       "      <td>15/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>31/03/18</td>\n",
       "      <td>12/03/12</td>\n",
       "      <td>18/03/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>07/04/18</td>\n",
       "      <td>16/04/18</td>\n",
       "      <td>17/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>27/02/15</td>\n",
       "      <td>23/03/15</td>\n",
       "      <td>25/03/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>30/03/15</td>\n",
       "      <td>18/05/15</td>\n",
       "      <td>20/05/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>03/02/18</td>\n",
       "      <td>26/03/18</td>\n",
       "      <td>29/03/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>03/04/18</td>\n",
       "      <td>03/04/18</td>\n",
       "      <td>04/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>03/03/15</td>\n",
       "      <td>27/05/15</td>\n",
       "      <td>28/05/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>04/05/15</td>\n",
       "      <td>07/06/15</td>\n",
       "      <td>10/06/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>26/09/15</td>\n",
       "      <td>16/11/15</td>\n",
       "      <td>19/11/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>08/02/17</td>\n",
       "      <td>23/03/17</td>\n",
       "      <td>27/03/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>27/09/16</td>\n",
       "      <td>20/10/16</td>\n",
       "      <td>23/10/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>11/10/17</td>\n",
       "      <td>11/10/17</td>\n",
       "      <td>13/10/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>23/12/17</td>\n",
       "      <td>31/12/17</td>\n",
       "      <td>03/01/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "      <td>07/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>06/02/15</td>\n",
       "      <td>09/02/15</td>\n",
       "      <td>10/02/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>11/02/15</td>\n",
       "      <td>08/04/15</td>\n",
       "      <td>11/04/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>10/08/15</td>\n",
       "      <td>08/09/15</td>\n",
       "      <td>11/09/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10/08/15</td>\n",
       "      <td>03/09/15</td>\n",
       "      <td>05/09/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>10/08/15</td>\n",
       "      <td>05/09/15</td>\n",
       "      <td>08/09/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>23/05/16</td>\n",
       "      <td>10/06/16</td>\n",
       "      <td>12/06/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>25/07/17</td>\n",
       "      <td>28/08/17</td>\n",
       "      <td>30/08/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>10/02/18</td>\n",
       "      <td>10/02/18</td>\n",
       "      <td>12/02/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>20/04/18</td>\n",
       "      <td>17/07/18</td>\n",
       "      <td>19/07/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>24/03/12</td>\n",
       "      <td>25/03/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>23/06/15</td>\n",
       "      <td>21/08/15</td>\n",
       "      <td>23/08/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>23/10/15</td>\n",
       "      <td>01/12/15</td>\n",
       "      <td>03/12/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>03/03/16</td>\n",
       "      <td>28/03/16</td>\n",
       "      <td>30/03/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>30/05/16</td>\n",
       "      <td>15/09/16</td>\n",
       "      <td>18/09/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>30/05/16</td>\n",
       "      <td>18/09/16</td>\n",
       "      <td>20/09/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>30/05/16</td>\n",
       "      <td>20/09/16</td>\n",
       "      <td>21/09/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>30/05/16</td>\n",
       "      <td>24/09/16</td>\n",
       "      <td>26/09/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>30/05/16</td>\n",
       "      <td>22/09/16</td>\n",
       "      <td>24/09/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>08/11/17</td>\n",
       "      <td>21/12/17</td>\n",
       "      <td>22/12/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>26/03/18</td>\n",
       "      <td>04/04/18</td>\n",
       "      <td>05/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>01/06/18</td>\n",
       "      <td>07/09/18</td>\n",
       "      <td>10/09/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>13/09/18</td>\n",
       "      <td>13/09/18</td>\n",
       "      <td>14/09/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "      <td>08/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>05/12/15</td>\n",
       "      <td>31/03/16</td>\n",
       "      <td>02/04/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>05/12/15</td>\n",
       "      <td>28/03/16</td>\n",
       "      <td>31/03/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10/07/18</td>\n",
       "      <td>31/07/18</td>\n",
       "      <td>04/08/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10/07/18</td>\n",
       "      <td>05/08/18</td>\n",
       "      <td>07/08/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>10/07/18</td>\n",
       "      <td>05/08/18</td>\n",
       "      <td>07/08/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>21/03/12</td>\n",
       "      <td>25/03/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "      <td>09/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>23/03/12</td>\n",
       "      <td>26/03/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>08/05/15</td>\n",
       "      <td>10/08/15</td>\n",
       "      <td>12/08/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>08/05/15</td>\n",
       "      <td>14/05/15</td>\n",
       "      <td>17/05/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>09/12/15</td>\n",
       "      <td>17/02/16</td>\n",
       "      <td>19/02/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>13/06/17</td>\n",
       "      <td>25/07/17</td>\n",
       "      <td>26/07/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "      <td>07/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>25/05/15</td>\n",
       "      <td>06/06/15</td>\n",
       "      <td>08/06/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>22/04/17</td>\n",
       "      <td>31/05/17</td>\n",
       "      <td>02/06/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>12/09/17</td>\n",
       "      <td>24/11/17</td>\n",
       "      <td>25/11/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>06/09/18</td>\n",
       "      <td>23/09/18</td>\n",
       "      <td>27/09/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>17/03/18</td>\n",
       "      <td>06/04/18</td>\n",
       "      <td>08/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>17/04/17</td>\n",
       "      <td>06/05/17</td>\n",
       "      <td>09/05/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>19/04/17</td>\n",
       "      <td>09/05/17</td>\n",
       "      <td>11/05/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>10/10/17</td>\n",
       "      <td>21/10/17</td>\n",
       "      <td>22/10/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>15/03/18</td>\n",
       "      <td>03/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>15/03/18</td>\n",
       "      <td>08/04/18</td>\n",
       "      <td>11/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>26/10/18</td>\n",
       "      <td>10/11/18</td>\n",
       "      <td>12/11/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>21/03/18</td>\n",
       "      <td>06/04/18</td>\n",
       "      <td>07/04/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341324</th>\n",
       "      <td>04/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341325</th>\n",
       "      <td>06/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341326</th>\n",
       "      <td>06/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341327</th>\n",
       "      <td>06/02/19</td>\n",
       "      <td>07/02/19</td>\n",
       "      <td>08/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341328</th>\n",
       "      <td>01/12/18</td>\n",
       "      <td>12/02/19</td>\n",
       "      <td>14/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341329</th>\n",
       "      <td>06/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "      <td>22/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341330</th>\n",
       "      <td>07/02/19</td>\n",
       "      <td>12/02/19</td>\n",
       "      <td>14/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341331</th>\n",
       "      <td>02/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341332</th>\n",
       "      <td>07/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341333</th>\n",
       "      <td>07/02/19</td>\n",
       "      <td>11/02/19</td>\n",
       "      <td>12/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341334</th>\n",
       "      <td>05/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341335</th>\n",
       "      <td>07/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "      <td>22/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341336</th>\n",
       "      <td>11/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341337</th>\n",
       "      <td>25/12/18</td>\n",
       "      <td>23/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341338</th>\n",
       "      <td>08/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341339</th>\n",
       "      <td>08/02/19</td>\n",
       "      <td>15/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341340</th>\n",
       "      <td>08/02/19</td>\n",
       "      <td>15/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341341</th>\n",
       "      <td>22/01/19</td>\n",
       "      <td>17/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341342</th>\n",
       "      <td>08/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "      <td>28/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341343</th>\n",
       "      <td>08/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341344</th>\n",
       "      <td>08/02/19</td>\n",
       "      <td>22/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341345</th>\n",
       "      <td>08/02/19</td>\n",
       "      <td>18/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341346</th>\n",
       "      <td>09/02/19</td>\n",
       "      <td>11/02/19</td>\n",
       "      <td>13/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341347</th>\n",
       "      <td>09/02/19</td>\n",
       "      <td>09/02/19</td>\n",
       "      <td>11/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341348</th>\n",
       "      <td>09/02/19</td>\n",
       "      <td>11/02/19</td>\n",
       "      <td>12/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341349</th>\n",
       "      <td>09/02/19</td>\n",
       "      <td>09/02/19</td>\n",
       "      <td>12/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341350</th>\n",
       "      <td>07/02/19</td>\n",
       "      <td>12/02/19</td>\n",
       "      <td>15/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341351</th>\n",
       "      <td>10/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341352</th>\n",
       "      <td>10/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341353</th>\n",
       "      <td>10/02/19</td>\n",
       "      <td>26/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341354</th>\n",
       "      <td>06/02/19</td>\n",
       "      <td>14/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341355</th>\n",
       "      <td>11/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "      <td>22/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341356</th>\n",
       "      <td>11/02/19</td>\n",
       "      <td>15/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341357</th>\n",
       "      <td>11/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341358</th>\n",
       "      <td>11/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341359</th>\n",
       "      <td>12/02/19</td>\n",
       "      <td>22/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341360</th>\n",
       "      <td>12/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341361</th>\n",
       "      <td>12/02/19</td>\n",
       "      <td>14/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341362</th>\n",
       "      <td>09/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341363</th>\n",
       "      <td>12/02/19</td>\n",
       "      <td>15/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341364</th>\n",
       "      <td>11/02/19</td>\n",
       "      <td>22/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341365</th>\n",
       "      <td>06/12/18</td>\n",
       "      <td>17/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341366</th>\n",
       "      <td>12/02/19</td>\n",
       "      <td>22/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341367</th>\n",
       "      <td>12/02/19</td>\n",
       "      <td>14/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341368</th>\n",
       "      <td>08/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "      <td>26/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341369</th>\n",
       "      <td>12/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341370</th>\n",
       "      <td>12/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341371</th>\n",
       "      <td>12/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341372</th>\n",
       "      <td>12/02/19</td>\n",
       "      <td>18/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341373</th>\n",
       "      <td>12/02/19</td>\n",
       "      <td>28/02/19</td>\n",
       "      <td>02/03/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341374</th>\n",
       "      <td>13/02/19</td>\n",
       "      <td>22/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341375</th>\n",
       "      <td>13/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341376</th>\n",
       "      <td>18/01/19</td>\n",
       "      <td>14/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341377</th>\n",
       "      <td>13/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341378</th>\n",
       "      <td>13/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "      <td>02/03/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341379</th>\n",
       "      <td>13/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341380</th>\n",
       "      <td>14/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "      <td>18/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341381</th>\n",
       "      <td>14/02/19</td>\n",
       "      <td>26/02/19</td>\n",
       "      <td>01/03/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341382</th>\n",
       "      <td>14/02/19</td>\n",
       "      <td>14/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341383</th>\n",
       "      <td>14/02/19</td>\n",
       "      <td>26/02/19</td>\n",
       "      <td>01/03/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341384</th>\n",
       "      <td>14/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341385</th>\n",
       "      <td>14/02/19</td>\n",
       "      <td>15/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341386</th>\n",
       "      <td>15/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "      <td>26/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341387</th>\n",
       "      <td>15/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341388</th>\n",
       "      <td>15/02/19</td>\n",
       "      <td>15/02/19</td>\n",
       "      <td>16/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341389</th>\n",
       "      <td>15/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341390</th>\n",
       "      <td>15/02/19</td>\n",
       "      <td>17/02/19</td>\n",
       "      <td>18/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341391</th>\n",
       "      <td>15/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341392</th>\n",
       "      <td>16/02/19</td>\n",
       "      <td>18/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341393</th>\n",
       "      <td>16/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341394</th>\n",
       "      <td>16/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341395</th>\n",
       "      <td>16/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341396</th>\n",
       "      <td>16/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341397</th>\n",
       "      <td>17/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "      <td>28/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341398</th>\n",
       "      <td>18/02/19</td>\n",
       "      <td>19/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341399</th>\n",
       "      <td>18/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341400</th>\n",
       "      <td>19/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341401</th>\n",
       "      <td>19/02/19</td>\n",
       "      <td>22/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341402</th>\n",
       "      <td>19/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341403</th>\n",
       "      <td>19/02/19</td>\n",
       "      <td>20/02/19</td>\n",
       "      <td>22/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341404</th>\n",
       "      <td>20/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341405</th>\n",
       "      <td>20/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341406</th>\n",
       "      <td>20/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "      <td>02/03/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341407</th>\n",
       "      <td>25/02/19</td>\n",
       "      <td>26/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341408</th>\n",
       "      <td>20/02/19</td>\n",
       "      <td>21/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341409</th>\n",
       "      <td>22/01/19</td>\n",
       "      <td>23/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341410</th>\n",
       "      <td>21/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "      <td>28/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341411</th>\n",
       "      <td>31/01/19</td>\n",
       "      <td>21/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341412</th>\n",
       "      <td>21/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "      <td>26/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341413</th>\n",
       "      <td>21/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "      <td>26/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341414</th>\n",
       "      <td>21/02/19</td>\n",
       "      <td>23/02/19</td>\n",
       "      <td>24/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341415</th>\n",
       "      <td>23/02/19</td>\n",
       "      <td>25/02/19</td>\n",
       "      <td>28/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341416</th>\n",
       "      <td>25/02/19</td>\n",
       "      <td>26/02/19</td>\n",
       "      <td>28/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341417</th>\n",
       "      <td>22/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "      <td>02/03/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341418</th>\n",
       "      <td>26/02/19</td>\n",
       "      <td>26/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341419</th>\n",
       "      <td>11/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "      <td>01/03/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341420</th>\n",
       "      <td>27/02/19</td>\n",
       "      <td>28/02/19</td>\n",
       "      <td>01/03/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341421</th>\n",
       "      <td>27/02/19</td>\n",
       "      <td>27/02/19</td>\n",
       "      <td>28/02/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341422</th>\n",
       "      <td>27/02/19</td>\n",
       "      <td>28/02/19</td>\n",
       "      <td>01/03/19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341423</th>\n",
       "      <td>28/02/19</td>\n",
       "      <td>01/03/19</td>\n",
       "      <td>02/03/19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341424 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       booking_date checkin_date checkout_date\n",
       "0          05/04/18     05/04/18      06/04/18\n",
       "1          23/01/15     11/04/15      16/04/15\n",
       "2          28/01/15     01/02/15      05/02/15\n",
       "3          02/05/15     11/06/15      16/06/15\n",
       "4          02/09/15     14/12/15      19/12/15\n",
       "5          01/12/15     12/01/16      13/01/16\n",
       "6          20/01/16     20/01/16      21/01/16\n",
       "7          22/08/16     20/10/16      25/10/16\n",
       "8          10/09/16     18/09/16      24/09/16\n",
       "9          03/08/16     21/11/16      24/11/16\n",
       "10         03/02/17     28/02/17      01/03/17\n",
       "11         23/09/17     18/10/17      20/10/17\n",
       "12         25/01/18     25/01/18      26/01/18\n",
       "13         28/01/18     06/04/18      08/04/18\n",
       "14         05/04/18     05/04/18      06/04/18\n",
       "15         05/04/18     08/03/12      11/03/12\n",
       "16         05/04/18     06/04/18      07/04/18\n",
       "17         21/01/15     21/01/15      23/01/15\n",
       "18         03/08/15     13/10/15      16/10/15\n",
       "19         03/08/15     09/10/15      13/10/15\n",
       "20         24/11/16     18/01/17      22/01/17\n",
       "21         24/11/16     22/01/17      25/01/17\n",
       "22         24/11/16     25/01/17      27/01/17\n",
       "23         30/12/17     19/01/18      22/01/18\n",
       "24         22/10/18     07/11/18      09/11/18\n",
       "25         05/04/18     05/04/18      06/04/18\n",
       "26         25/03/15     05/04/15      07/04/15\n",
       "27         28/03/15     02/04/15      05/04/15\n",
       "28         22/02/16     27/03/16      29/03/16\n",
       "29         05/10/16     17/10/16      20/10/16\n",
       "30         02/01/17     28/04/17      29/04/17\n",
       "31         05/04/18     06/04/18      07/04/18\n",
       "32         04/11/15     20/11/15      21/11/15\n",
       "33         31/03/18     13/04/18      15/04/18\n",
       "34         31/03/18     12/03/12      18/03/12\n",
       "35         07/04/18     16/04/18      17/04/18\n",
       "36         05/04/18     05/04/18      06/04/18\n",
       "37         27/02/15     23/03/15      25/03/15\n",
       "38         30/03/15     18/05/15      20/05/15\n",
       "39         03/02/18     26/03/18      29/03/18\n",
       "40         03/04/18     03/04/18      04/04/18\n",
       "41         05/04/18     05/04/18      06/04/18\n",
       "42         03/03/15     27/05/15      28/05/15\n",
       "43         04/05/15     07/06/15      10/06/15\n",
       "44         26/09/15     16/11/15      19/11/15\n",
       "45         08/02/17     23/03/17      27/03/17\n",
       "46         05/04/18     05/04/18      06/04/18\n",
       "47         27/09/16     20/10/16      23/10/16\n",
       "48         11/10/17     11/10/17      13/10/17\n",
       "49         23/12/17     31/12/17      03/01/18\n",
       "50         05/04/18     06/04/18      07/04/18\n",
       "51         06/02/15     09/02/15      10/02/15\n",
       "52         11/02/15     08/04/15      11/04/15\n",
       "53         10/08/15     08/09/15      11/09/15\n",
       "54         10/08/15     03/09/15      05/09/15\n",
       "55         10/08/15     05/09/15      08/09/15\n",
       "56         23/05/16     10/06/16      12/06/16\n",
       "57         25/07/17     28/08/17      30/08/17\n",
       "58         10/02/18     10/02/18      12/02/18\n",
       "59         20/04/18     17/07/18      19/07/18\n",
       "60         05/04/18     24/03/12      25/03/12\n",
       "61         23/06/15     21/08/15      23/08/15\n",
       "62         23/10/15     01/12/15      03/12/15\n",
       "63         03/03/16     28/03/16      30/03/16\n",
       "64         30/05/16     15/09/16      18/09/16\n",
       "65         30/05/16     18/09/16      20/09/16\n",
       "66         30/05/16     20/09/16      21/09/16\n",
       "67         30/05/16     24/09/16      26/09/16\n",
       "68         30/05/16     22/09/16      24/09/16\n",
       "69         08/11/17     21/12/17      22/12/17\n",
       "70         26/03/18     04/04/18      05/04/18\n",
       "71         01/06/18     07/09/18      10/09/18\n",
       "72         13/09/18     13/09/18      14/09/18\n",
       "73         05/04/18     06/04/18      08/04/18\n",
       "74         05/12/15     31/03/16      02/04/16\n",
       "75         05/12/15     28/03/16      31/03/16\n",
       "76         10/07/18     31/07/18      04/08/18\n",
       "77         10/07/18     05/08/18      07/08/18\n",
       "78         10/07/18     05/08/18      07/08/18\n",
       "79         05/04/18     21/03/12      25/03/12\n",
       "80         05/04/18     06/04/18      09/04/18\n",
       "81         05/04/18     23/03/12      26/03/12\n",
       "82         08/05/15     10/08/15      12/08/15\n",
       "83         08/05/15     14/05/15      17/05/15\n",
       "84         05/04/18     05/04/18      06/04/18\n",
       "85         09/12/15     17/02/16      19/02/16\n",
       "86         13/06/17     25/07/17      26/07/17\n",
       "87         05/04/18     06/04/18      07/04/18\n",
       "88         25/05/15     06/06/15      08/06/15\n",
       "89         22/04/17     31/05/17      02/06/17\n",
       "90         12/09/17     24/11/17      25/11/17\n",
       "91         06/09/18     23/09/18      27/09/18\n",
       "92         17/03/18     06/04/18      08/04/18\n",
       "93         17/04/17     06/05/17      09/05/17\n",
       "94         19/04/17     09/05/17      11/05/17\n",
       "95         10/10/17     21/10/17      22/10/17\n",
       "96         15/03/18     03/04/18      06/04/18\n",
       "97         15/03/18     08/04/18      11/04/18\n",
       "98         26/10/18     10/11/18      12/11/18\n",
       "99         21/03/18     06/04/18      07/04/18\n",
       "...             ...          ...           ...\n",
       "341324     04/02/19     19/02/19      21/02/19\n",
       "341325     06/02/19     24/02/19      25/02/19\n",
       "341326     06/02/19     23/02/19      24/02/19\n",
       "341327     06/02/19     07/02/19      08/02/19\n",
       "341328     01/12/18     12/02/19      14/02/19\n",
       "341329     06/02/19     20/02/19      22/02/19\n",
       "341330     07/02/19     12/02/19      14/02/19\n",
       "341331     02/02/19     16/02/19      17/02/19\n",
       "341332     07/02/19     17/02/19      20/02/19\n",
       "341333     07/02/19     11/02/19      12/02/19\n",
       "341334     05/02/19     16/02/19      19/02/19\n",
       "341335     07/02/19     19/02/19      22/02/19\n",
       "341336     11/02/19     17/02/19      19/02/19\n",
       "341337     25/12/18     23/02/19      25/02/19\n",
       "341338     08/02/19     21/02/19      23/02/19\n",
       "341339     08/02/19     15/02/19      17/02/19\n",
       "341340     08/02/19     15/02/19      17/02/19\n",
       "341341     22/01/19     17/02/19      19/02/19\n",
       "341342     08/02/19     25/02/19      28/02/19\n",
       "341343     08/02/19     17/02/19      19/02/19\n",
       "341344     08/02/19     22/02/19      27/02/19\n",
       "341345     08/02/19     18/02/19      21/02/19\n",
       "341346     09/02/19     11/02/19      13/02/19\n",
       "341347     09/02/19     09/02/19      11/02/19\n",
       "341348     09/02/19     11/02/19      12/02/19\n",
       "341349     09/02/19     09/02/19      12/02/19\n",
       "341350     07/02/19     12/02/19      15/02/19\n",
       "341351     10/02/19     21/02/19      24/02/19\n",
       "341352     10/02/19     20/02/19      23/02/19\n",
       "341353     10/02/19     26/02/19      27/02/19\n",
       "341354     06/02/19     14/02/19      16/02/19\n",
       "341355     11/02/19     20/02/19      22/02/19\n",
       "341356     11/02/19     15/02/19      16/02/19\n",
       "341357     11/02/19     23/02/19      25/02/19\n",
       "341358     11/02/19     17/02/19      19/02/19\n",
       "341359     12/02/19     22/02/19      24/02/19\n",
       "341360     12/02/19     25/02/19      27/02/19\n",
       "341361     12/02/19     14/02/19      16/02/19\n",
       "341362     09/02/19     16/02/19      19/02/19\n",
       "341363     12/02/19     15/02/19      16/02/19\n",
       "341364     11/02/19     22/02/19      24/02/19\n",
       "341365     06/12/18     17/02/19      19/02/19\n",
       "341366     12/02/19     22/02/19      25/02/19\n",
       "341367     12/02/19     14/02/19      16/02/19\n",
       "341368     08/02/19     25/02/19      26/02/19\n",
       "341369     12/02/19     17/02/19      19/02/19\n",
       "341370     12/02/19     21/02/19      23/02/19\n",
       "341371     12/02/19     20/02/19      21/02/19\n",
       "341372     12/02/19     18/02/19      19/02/19\n",
       "341373     12/02/19     28/02/19      02/03/19\n",
       "341374     13/02/19     22/02/19      24/02/19\n",
       "341375     13/02/19     23/02/19      24/02/19\n",
       "341376     18/01/19     14/02/19      17/02/19\n",
       "341377     13/02/19     17/02/19      21/02/19\n",
       "341378     13/02/19     27/02/19      02/03/19\n",
       "341379     13/02/19     20/02/19      23/02/19\n",
       "341380     14/02/19     16/02/19      18/02/19\n",
       "341381     14/02/19     26/02/19      01/03/19\n",
       "341382     14/02/19     14/02/19      16/02/19\n",
       "341383     14/02/19     26/02/19      01/03/19\n",
       "341384     14/02/19     17/02/19      20/02/19\n",
       "341385     14/02/19     15/02/19      16/02/19\n",
       "341386     15/02/19     24/02/19      26/02/19\n",
       "341387     15/02/19     16/02/19      17/02/19\n",
       "341388     15/02/19     15/02/19      16/02/19\n",
       "341389     15/02/19     24/02/19      25/02/19\n",
       "341390     15/02/19     17/02/19      18/02/19\n",
       "341391     15/02/19     23/02/19      25/02/19\n",
       "341392     16/02/19     18/02/19      19/02/19\n",
       "341393     16/02/19     19/02/19      21/02/19\n",
       "341394     16/02/19     19/02/19      20/02/19\n",
       "341395     16/02/19     21/02/19      24/02/19\n",
       "341396     16/02/19     20/02/19      23/02/19\n",
       "341397     17/02/19     27/02/19      28/02/19\n",
       "341398     18/02/19     19/02/19      20/02/19\n",
       "341399     18/02/19     23/02/19      24/02/19\n",
       "341400     19/02/19     23/02/19      25/02/19\n",
       "341401     19/02/19     22/02/19      23/02/19\n",
       "341402     19/02/19     20/02/19      21/02/19\n",
       "341403     19/02/19     20/02/19      22/02/19\n",
       "341404     20/02/19     25/02/19      27/02/19\n",
       "341405     20/02/19     21/02/19      23/02/19\n",
       "341406     20/02/19     27/02/19      02/03/19\n",
       "341407     25/02/19     26/02/19      27/02/19\n",
       "341408     20/02/19     21/02/19      23/02/19\n",
       "341409     22/01/19     23/02/19      25/02/19\n",
       "341410     21/02/19     27/02/19      28/02/19\n",
       "341411     31/01/19     21/02/19      23/02/19\n",
       "341412     21/02/19     23/02/19      26/02/19\n",
       "341413     21/02/19     24/02/19      26/02/19\n",
       "341414     21/02/19     23/02/19      24/02/19\n",
       "341415     23/02/19     25/02/19      28/02/19\n",
       "341416     25/02/19     26/02/19      28/02/19\n",
       "341417     22/02/19     27/02/19      02/03/19\n",
       "341418     26/02/19     26/02/19      27/02/19\n",
       "341419     11/02/19     27/02/19      01/03/19\n",
       "341420     27/02/19     28/02/19      01/03/19\n",
       "341421     27/02/19     27/02/19      28/02/19\n",
       "341422     27/02/19     28/02/19      01/03/19\n",
       "341423     28/02/19     01/03/19      02/03/19\n",
       "\n",
       "[341424 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['booking_date','checkin_date','checkout_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1621, 1619, 1616)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_df['booking_date'].unique())), len(set(test_df['booking_date'].unique())),\\\n",
    "len(set(train_df['booking_date'].unique()).intersection(set(test_df['booking_date'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1532, 1523, 1521)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_df['checkin_date'].unique())), len(set(test_df['checkin_date'].unique())),\\\n",
    "len(set(train_df['checkin_date'].unique()).intersection(set(test_df['checkin_date'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reservation_id</th>\n",
       "      <th>booking_date</th>\n",
       "      <th>checkin_date</th>\n",
       "      <th>checkout_date</th>\n",
       "      <th>channel_code</th>\n",
       "      <th>main_product_code</th>\n",
       "      <th>numberofadults</th>\n",
       "      <th>numberofchildren</th>\n",
       "      <th>persontravellingid</th>\n",
       "      <th>resort_region_code</th>\n",
       "      <th>resort_type_code</th>\n",
       "      <th>room_type_booked_code</th>\n",
       "      <th>roomnights</th>\n",
       "      <th>season_holidayed_code</th>\n",
       "      <th>state_code_residence</th>\n",
       "      <th>state_code_resort</th>\n",
       "      <th>total_pax</th>\n",
       "      <th>member_age_buckets</th>\n",
       "      <th>booking_type_code</th>\n",
       "      <th>memberid</th>\n",
       "      <th>cluster_code</th>\n",
       "      <th>reservationstatusid_code</th>\n",
       "      <th>resort_id</th>\n",
       "      <th>amount_spent_per_room_night_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07659f3758d8aee27f5a7e2887adeacb67021cb95ada1b...</td>\n",
       "      <td>05/04/18</td>\n",
       "      <td>05/04/18</td>\n",
       "      <td>06/04/18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>F</td>\n",
       "      <td>C</td>\n",
       "      <td>4e07408562bedb8b60ce05c1decfe3ad16b72230967de0...</td>\n",
       "      <td>7.706428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03930f033646d073462b35d411616323597715ac4fc398...</td>\n",
       "      <td>23/01/15</td>\n",
       "      <td>11/04/15</td>\n",
       "      <td>16/04/15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>39fa9ec190eee7b6f4dff1100d6343e10918d044c75eac...</td>\n",
       "      <td>6.662563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d145a32920e6587ad95bfe299d80c0affa268220535aaf...</td>\n",
       "      <td>28/01/15</td>\n",
       "      <td>01/02/15</td>\n",
       "      <td>05/02/15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>535fa30d7e25dd8a49f1536779734ec8286108d115da50...</td>\n",
       "      <td>7.871602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cfd77f44811ed62f25a220b53324cdbafc662a4c9e5f04...</td>\n",
       "      <td>02/05/15</td>\n",
       "      <td>11/06/15</td>\n",
       "      <td>16/06/15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...</td>\n",
       "      <td>5.344943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>937cff9e4dcfc2459620153dfc8b9962ac22bea67dfb29...</td>\n",
       "      <td>02/09/15</td>\n",
       "      <td>14/12/15</td>\n",
       "      <td>19/12/15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...</td>\n",
       "      <td>7.059346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      reservation_id booking_date  \\\n",
       "0  07659f3758d8aee27f5a7e2887adeacb67021cb95ada1b...     05/04/18   \n",
       "1  03930f033646d073462b35d411616323597715ac4fc398...     23/01/15   \n",
       "2  d145a32920e6587ad95bfe299d80c0affa268220535aaf...     28/01/15   \n",
       "3  cfd77f44811ed62f25a220b53324cdbafc662a4c9e5f04...     02/05/15   \n",
       "4  937cff9e4dcfc2459620153dfc8b9962ac22bea67dfb29...     02/09/15   \n",
       "\n",
       "  checkin_date checkout_date  channel_code  main_product_code  numberofadults  \\\n",
       "0     05/04/18      06/04/18             3                  1               2   \n",
       "1     11/04/15      16/04/15             1                  1               2   \n",
       "2     01/02/15      05/02/15             1                  1               2   \n",
       "3     11/06/15      16/06/15             1                  1               2   \n",
       "4     14/12/15      19/12/15             1                  1               2   \n",
       "\n",
       "   numberofchildren  persontravellingid  resort_region_code  resort_type_code  \\\n",
       "0                 0                  46                   3                 3   \n",
       "1                 0                  46                   3                 3   \n",
       "2                 0                  47                   1                 5   \n",
       "3                 2                  46                   2                 2   \n",
       "4                 0                  46                   2                 2   \n",
       "\n",
       "   room_type_booked_code  roomnights  season_holidayed_code  \\\n",
       "0                      3           1                    2.0   \n",
       "1                      4           5                    2.0   \n",
       "2                      4           4                    2.0   \n",
       "3                      3           5                    2.0   \n",
       "4                      4           5                    2.0   \n",
       "\n",
       "   state_code_residence  state_code_resort  total_pax member_age_buckets  \\\n",
       "0                   7.0                  3          3                  F   \n",
       "1                   7.0                  5          2                  F   \n",
       "2                   7.0                  1          2                  F   \n",
       "3                   7.0                  2          2                  F   \n",
       "4                   7.0                  2          2                  F   \n",
       "\n",
       "   booking_type_code                                           memberid  \\\n",
       "0                  1  3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...   \n",
       "1                  1  3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...   \n",
       "2                  1  3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...   \n",
       "3                  1  3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...   \n",
       "4                  1  3d1539e56495b6991f0a3ef5a61ca3d03ce4fff7380e9a...   \n",
       "\n",
       "  cluster_code reservationstatusid_code  \\\n",
       "0            F                        C   \n",
       "1            F                        A   \n",
       "2            E                        A   \n",
       "3            D                        A   \n",
       "4            D                        A   \n",
       "\n",
       "                                           resort_id  \\\n",
       "0  4e07408562bedb8b60ce05c1decfe3ad16b72230967de0...   \n",
       "1  39fa9ec190eee7b6f4dff1100d6343e10918d044c75eac...   \n",
       "2  535fa30d7e25dd8a49f1536779734ec8286108d115da50...   \n",
       "3  d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...   \n",
       "4  d4735e3a265e16eee03f59718b9b5d03019c07d8b6c51f...   \n",
       "\n",
       "   amount_spent_per_room_night_scaled  \n",
       "0                            7.706428  \n",
       "1                            6.662563  \n",
       "2                            7.871602  \n",
       "3                            5.344943  \n",
       "4                            7.059346  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.apply(lambda x: pd.Series.value_counts(x).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important points:\n",
    "\n",
    "- There are only `season_holidayed_code` & `state_code_residence` columns that contains `nan` values.\n",
    "- All variables are categorical except `ids` (which are `hash code`) and `amount_spent_per_room_night_scaled` (which is `float` and `target`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.groupby('memberid')['amount_spent_per_room_night_scaled'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.amount_spent_per_room_night_scaled.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_df.amount_spent_per_room_night_scaled, '-p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(train_df.memberid)), len(set(test_df.memberid)), \\\n",
    "len(set(train_df.memberid).intersection(set(test_df.memberid))))\n",
    "\n",
    "print(len(set(train_df.reservation_id)), len(set(test_df.reservation_id)), \\\n",
    "len(set(train_df.reservation_id).intersection(set(test_df.reservation_id))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, gc\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "def train_lgb_model(X_train, y_train, X_valid, y_valid, features, param, X_test, num_round):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_train, X_valid: training and valid data\n",
    "        y_train, y_valid: training and valid target\n",
    "        X_test: test-data\n",
    "        features: training features\n",
    "    Return:\n",
    "        oof-pred, test_preds model, model_imp\n",
    "    \"\"\"\n",
    "    _train = lgb.Dataset(X_train[features], label=y_train, feature_name=list(features))\n",
    "    _valid = lgb.Dataset(X_valid[features], label=y_valid,feature_name=list(features))\n",
    "    \n",
    "    clf = lgb.train(param, _train, num_round, \n",
    "                    valid_sets = [_train, _valid], \n",
    "                    verbose_eval=200, \n",
    "                    early_stopping_rounds = 25)                  \n",
    "    \n",
    "    oof = clf.predict(X_valid[features], num_iteration=clf.best_iteration)\n",
    "    test_pred = clf.predict(X_test[features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    lgb_imp = pd.DataFrame(data=[clf.feature_name(), list(clf.feature_importance())]).T\n",
    "    lgb_imp.columns = ['feature','imp']\n",
    "    \n",
    "    return oof, test_pred, clf, lgb_imp\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def run_cv_lgb(train_df, target, test_df, leaves=None):\n",
    "\n",
    "    param = {\n",
    "        'bagging_freq'           : 5,\n",
    "        'bagging_fraction'       : 0.33,\n",
    "        'boost_from_average'     : 'false',\n",
    "        'boost'                  : 'gbdt',\n",
    "        'feature_fraction'       : 0.3,\n",
    "        'learning_rate'          : 0.01,\n",
    "        'max_depth'              : -1,\n",
    "        'metric'                 : 'rmse',\n",
    "        'min_data_in_leaf'       : 100,\n",
    "#         'min_sum_hessian_in_leaf': 10.0,\n",
    "        'num_leaves'             : 30,\n",
    "        'num_threads'            : 4,\n",
    "        'tree_learner'           : 'serial',\n",
    "        'objective'              : 'root_mean_squared_error',\n",
    "        'verbosity'              : 1,\n",
    "    #     'lambda_l1'              : 0.001,\n",
    "        'lambda_l2'              : 0.1\n",
    "    }   \n",
    "    if leaves is not None:\n",
    "        param['num_leaves'] = leaves\n",
    "        print(\"using leaves: \", param['num_leaves'])\n",
    "\n",
    "    random_seed = 1234\n",
    "    n_splits = 3\n",
    "    num_round = 10000\n",
    "    feature_imp = pd.DataFrame()\n",
    "    \n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    oof_lgb = np.zeros(len(train_df))\n",
    "    predictions = np.zeros((len(test_df),n_splits))\n",
    "\n",
    "    clfs = []\n",
    "    \n",
    "    for fold_, (train_index, valid_index) in enumerate(folds.split(train_df, target)):\n",
    "        print(train_index.shape, valid_index.shape)\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "    \n",
    "        y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "        X_train, X_valid = train_df.iloc[train_index,:], train_df.iloc[valid_index,:]\n",
    "        features = X_train.columns\n",
    "        \n",
    "#         X_train.drop(['disbursal_week','disbursal_day'], axis=1, inplace=True)\n",
    "#         X_valid.drop(['disbursal_week','disbursal_day'], axis=1, inplace=True)\n",
    "\n",
    "        num_round = 10000\n",
    "        oof, test_pred, clf, lgb_imp = train_lgb_model(X_train, y_train, \n",
    "                                                       X_valid, y_valid, \n",
    "                                                       features, param, \n",
    "                                                       test_df, num_round)\n",
    "        lgb_imp['fold'] = fold_\n",
    "        feature_imp = pd.concat([feature_imp, lgb_imp], axis=0)\n",
    "    \n",
    "        oof_lgb[valid_index] = oof\n",
    "        predictions[:,fold_] = test_pred\n",
    "        clfs.append(clf)\n",
    "        \n",
    "        score = mean_squared_error(y_valid, oof)\n",
    "        print( \"  rmse = \", 100*np.sqrt(score) )\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    feature_imp.imp = feature_imp.imp.astype('float')\n",
    "    feature_imp = feature_imp.groupby(['feature'])['imp'].mean()\n",
    "    feature_imp = pd.DataFrame(data=[feature_imp.index, feature_imp.values]).T\n",
    "    feature_imp.columns=['feature','imp']\n",
    "    feature_imp = feature_imp.sort_values(by='imp')\n",
    "\n",
    "    return clfs, feature_imp, oof_lgb, predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "train_df1 = copy.deepcopy(train_df)\n",
    "test_df1 = copy.deepcopy(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df1.drop(['reservation_id', 'memberid'], axis=1, inplace=True)\n",
    "test_df1.drop(['reservation_id', 'memberid'], axis=1, inplace=True)\n",
    "\n",
    "target = train_df.amount_spent_per_room_night_scaled\n",
    "train_df1.drop('amount_spent_per_room_night_scaled', axis=1, inplace=True)\n",
    "\n",
    "train_df1 = train_df1.astype('object')\n",
    "test_df1  = test_df1.astype('object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.concat([train_df1, test_df1], axis=0).reset_index(drop=True)\n",
    "\n",
    "for col in complete_df.columns:\n",
    "    complete_df[col] = complete_df[col].astype('category').cat.codes\n",
    "    \n",
    "del train_df1, test_df1\n",
    "gc.collect()\n",
    "\n",
    "train_df1 = complete_df.iloc[:train_df.shape[0]]\n",
    "test_df1  = complete_df.iloc[train_df.shape[0]:]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using leaves:  50\n",
      "(227616,) (113808,)\n",
      "Fold 0\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[200]\ttraining's rmse: 1.46449\tvalid_1's rmse: 1.46804\n",
      "[400]\ttraining's rmse: 1.03143\tvalid_1's rmse: 1.0345\n",
      "[600]\ttraining's rmse: 1.0144\tvalid_1's rmse: 1.01885\n",
      "[800]\ttraining's rmse: 1.00885\tvalid_1's rmse: 1.01489\n",
      "[1000]\ttraining's rmse: 1.00497\tvalid_1's rmse: 1.01259\n",
      "[1200]\ttraining's rmse: 1.00098\tvalid_1's rmse: 1.01027\n",
      "[1400]\ttraining's rmse: 0.9973\tvalid_1's rmse: 1.00813\n",
      "[1600]\ttraining's rmse: 0.992678\tvalid_1's rmse: 1.00504\n",
      "[1800]\ttraining's rmse: 0.990019\tvalid_1's rmse: 1.0038\n",
      "[2000]\ttraining's rmse: 0.986463\tvalid_1's rmse: 1.00165\n",
      "[2200]\ttraining's rmse: 0.984166\tvalid_1's rmse: 1.00078\n",
      "[2400]\ttraining's rmse: 0.981085\tvalid_1's rmse: 0.99911\n",
      "[2600]\ttraining's rmse: 0.978644\tvalid_1's rmse: 0.998053\n",
      "[2800]\ttraining's rmse: 0.97589\tvalid_1's rmse: 0.996625\n",
      "[3000]\ttraining's rmse: 0.973695\tvalid_1's rmse: 0.995726\n",
      "[3200]\ttraining's rmse: 0.9711\tvalid_1's rmse: 0.994485\n",
      "Early stopping, best iteration is:\n",
      "[3210]\ttraining's rmse: 0.971034\tvalid_1's rmse: 0.994475\n",
      "  rmse =  99.44753942014867\n",
      "============================================================\n",
      "(227616,) (113808,)\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[200]\ttraining's rmse: 1.46519\tvalid_1's rmse: 1.46417\n",
      "[400]\ttraining's rmse: 1.03128\tvalid_1's rmse: 1.03456\n",
      "[600]\ttraining's rmse: 1.01442\tvalid_1's rmse: 1.01995\n",
      "[800]\ttraining's rmse: 1.00897\tvalid_1's rmse: 1.01628\n",
      "[1000]\ttraining's rmse: 1.00472\tvalid_1's rmse: 1.01375\n",
      "[1200]\ttraining's rmse: 1.00103\tvalid_1's rmse: 1.01172\n",
      "[1400]\ttraining's rmse: 0.997395\tvalid_1's rmse: 1.00963\n",
      "[1600]\ttraining's rmse: 0.992898\tvalid_1's rmse: 1.0067\n",
      "[1800]\ttraining's rmse: 0.99003\tvalid_1's rmse: 1.00533\n",
      "[2000]\ttraining's rmse: 0.986363\tvalid_1's rmse: 1.00307\n",
      "[2200]\ttraining's rmse: 0.983957\tvalid_1's rmse: 1.00212\n",
      "[2400]\ttraining's rmse: 0.98092\tvalid_1's rmse: 1.00049\n",
      "[2600]\ttraining's rmse: 0.978431\tvalid_1's rmse: 0.999354\n",
      "[2800]\ttraining's rmse: 0.975428\tvalid_1's rmse: 0.997633\n",
      "[3000]\ttraining's rmse: 0.973423\tvalid_1's rmse: 0.996914\n",
      "[3200]\ttraining's rmse: 0.970738\tvalid_1's rmse: 0.995524\n",
      "Early stopping, best iteration is:\n",
      "[3281]\ttraining's rmse: 0.970127\tvalid_1's rmse: 0.995428\n",
      "  rmse =  99.54279057051576\n",
      "============================================================\n",
      "(227616,) (113808,)\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[200]\ttraining's rmse: 1.46463\tvalid_1's rmse: 1.46606\n",
      "[400]\ttraining's rmse: 1.03098\tvalid_1's rmse: 1.03555\n",
      "[600]\ttraining's rmse: 1.01426\tvalid_1's rmse: 1.02085\n",
      "[800]\ttraining's rmse: 1.00842\tvalid_1's rmse: 1.01674\n",
      "[1000]\ttraining's rmse: 1.0045\tvalid_1's rmse: 1.01455\n",
      "[1200]\ttraining's rmse: 1.00061\tvalid_1's rmse: 1.01237\n",
      "[1400]\ttraining's rmse: 0.996984\tvalid_1's rmse: 1.01037\n",
      "[1600]\ttraining's rmse: 0.99255\tvalid_1's rmse: 1.0075\n",
      "[1800]\ttraining's rmse: 0.989354\tvalid_1's rmse: 1.00587\n",
      "[2000]\ttraining's rmse: 0.985719\tvalid_1's rmse: 1.00366\n",
      "[2200]\ttraining's rmse: 0.983359\tvalid_1's rmse: 1.00276\n",
      "[2400]\ttraining's rmse: 0.980249\tvalid_1's rmse: 1.00107\n",
      "[2600]\ttraining's rmse: 0.977779\tvalid_1's rmse: 1.00002\n",
      "[2800]\ttraining's rmse: 0.974875\tvalid_1's rmse: 0.998407\n",
      "[3000]\ttraining's rmse: 0.972785\tvalid_1's rmse: 0.997596\n",
      "[3200]\ttraining's rmse: 0.970076\tvalid_1's rmse: 0.996178\n",
      "Early stopping, best iteration is:\n",
      "[3349]\ttraining's rmse: 0.968769\tvalid_1's rmse: 0.995815\n",
      "  rmse =  99.58148568546977\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "clfs_lgb, imp_lgb, oof_lgb, pred_lgb = run_cv_lgb(train_df1, target, \n",
    "                                                  test_df1, leaves=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "def train_cat_model(X_train, y_train, X_valid, y_valid, features, param, X_test, \n",
    "                    num_round):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_train, X_valid: training and valid data\n",
    "        y_train, y_valid: training and valid target\n",
    "        X_test: test-data\n",
    "        features: training features\n",
    "    Return:\n",
    "        oof-pred, test_preds, model, model_imp\n",
    "    \"\"\"\n",
    "    param['iterations'] = num_round\n",
    "    \n",
    "    _train = Pool(X_train[features], label=y_train)#, cat_features=cate_features_index)\n",
    "    _valid = Pool(X_valid[features], label=y_valid)#, cat_features=cate_features_index)\n",
    "\n",
    "    watchlist = [_train, _valid]\n",
    "    clf = CatBoostRegressor(**param)\n",
    "    clf.fit(_train, \n",
    "            eval_set=watchlist, \n",
    "            verbose=200,\n",
    "            use_best_model=True)\n",
    "        \n",
    "    oof  = clf.predict(X_valid[features])\n",
    "    test_pred  = clf.predict(X_test[features])\n",
    "\n",
    "    cat_imp = pd.DataFrame(data=[clf.feature_names_, \n",
    "                                 list(clf.feature_importances_)]).T\n",
    "    cat_imp.columns = ['feature','imp']\n",
    "    \n",
    "    return oof, test_pred, clf, cat_imp\n",
    "\n",
    "\n",
    "def run_cv_cat(train_df, target, test_df, depth):\n",
    "\n",
    "    params = {\n",
    "        'loss_function'         : \"RMSE\", \n",
    "#         'eval_metric'           : \"AUC\",\n",
    "        'random_strength'       : 1.5,\n",
    "        'border_count'          : 128,\n",
    "#         'scale_pos_weight'      : 3.507,\n",
    "        'depth'                 : depth, \n",
    "        'early_stopping_rounds' : 50,\n",
    "        'random_seed'           : 1337,\n",
    "        'task_type'             : 'CPU', \n",
    "#         'subsample'             = 0.7, \n",
    "        'iterations'            : 10000, \n",
    "        'learning_rate'         : 0.09,\n",
    "        'thread_count'          : 4\n",
    "    }\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    n_splits = 3\n",
    "    random_seed = 1234\n",
    "    feature_imp = pd.DataFrame()\n",
    "    \n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    oof_cat = np.zeros(len(train_df))\n",
    "    predictions = np.zeros((len(test_df),n_splits))\n",
    "    clfs = []\n",
    "##########################\n",
    "    for fold_, (train_index, valid_index) in enumerate(folds.split(train_df, target)):\n",
    "        print(train_index.shape, valid_index.shape)\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "    \n",
    "        y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "        X_train, X_valid = train_df.iloc[train_index,:], train_df.iloc[valid_index,:]\n",
    "        features = X_train.columns\n",
    "        \n",
    "        num_rounds = 10000\n",
    "        oof, test_pred, clf, cat_imp = train_cat_model(X_train, y_train, \n",
    "                                                       X_valid, y_valid, \n",
    "                                                       features, params, \n",
    "                                                       test_df, num_rounds)\n",
    "    \n",
    "        oof_cat[valid_index] = oof\n",
    "        predictions[:,fold_] = test_pred\n",
    "        \n",
    "        cat_imp['fold'] = fold_\n",
    "        feature_imp = pd.concat([feature_imp, cat_imp], axis=0)\n",
    "        clfs.append(clf)\n",
    "        \n",
    "        score = mean_squared_error(y_valid, oof)\n",
    "        print( \"  auc = \", 100*np.sqrt(score) )\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    feature_imp.imp = feature_imp.imp.astype('float')\n",
    "    feature_imp = feature_imp.groupby(['feature'])['imp'].mean()\n",
    "    feature_imp = pd.DataFrame(data=[feature_imp.index, feature_imp.values]).T\n",
    "    feature_imp.columns=['feature','imp']\n",
    "    feature_imp = feature_imp.sort_values(by='imp')\n",
    "\n",
    "    return clfs, feature_imp, oof_cat, predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227616,) (113808,)\n",
      "Fold 0\n",
      "0:\tlearn: 7.1087168\ttest: 7.1087168\ttest1: 7.1130523\tbest: 7.1130523 (0)\ttotal: 20.8ms\tremaining: 3m 27s\n",
      "200:\tlearn: 1.0182283\ttest: 1.0182283\ttest1: 1.0183900\tbest: 1.0183900 (200)\ttotal: 6.07s\tremaining: 4m 56s\n",
      "400:\tlearn: 1.0051033\ttest: 1.0051033\ttest1: 1.0070166\tbest: 1.0070166 (400)\ttotal: 12.1s\tremaining: 4m 49s\n",
      "600:\tlearn: 0.9972679\ttest: 0.9972679\ttest1: 1.0008241\tbest: 1.0008216 (599)\ttotal: 18s\tremaining: 4m 41s\n",
      "800:\tlearn: 0.9920203\ttest: 0.9920203\ttest1: 0.9968622\tbest: 0.9968622 (800)\ttotal: 23.8s\tremaining: 4m 33s\n",
      "1000:\tlearn: 0.9881551\ttest: 0.9881551\ttest1: 0.9941965\tbest: 0.9941965 (1000)\ttotal: 29.6s\tremaining: 4m 26s\n",
      "1200:\tlearn: 0.9847933\ttest: 0.9847933\ttest1: 0.9921452\tbest: 0.9921452 (1200)\ttotal: 35.5s\tremaining: 4m 20s\n",
      "1400:\tlearn: 0.9824931\ttest: 0.9824931\ttest1: 0.9911621\tbest: 0.9911561 (1399)\ttotal: 41.4s\tremaining: 4m 14s\n",
      "1600:\tlearn: 0.9803233\ttest: 0.9803233\ttest1: 0.9900051\tbest: 0.9900044 (1599)\ttotal: 47.2s\tremaining: 4m 7s\n",
      "1800:\tlearn: 0.9784058\ttest: 0.9784058\ttest1: 0.9892871\tbest: 0.9892871 (1800)\ttotal: 53s\tremaining: 4m 1s\n",
      "2000:\tlearn: 0.9765982\ttest: 0.9765982\ttest1: 0.9885996\tbest: 0.9885976 (1997)\ttotal: 58.8s\tremaining: 3m 55s\n",
      "2200:\tlearn: 0.9751652\ttest: 0.9751652\ttest1: 0.9883719\tbest: 0.9883625 (2183)\ttotal: 1m 4s\tremaining: 3m 48s\n",
      "2400:\tlearn: 0.9738581\ttest: 0.9738581\ttest1: 0.9880961\tbest: 0.9880961 (2400)\ttotal: 1m 10s\tremaining: 3m 42s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9880593117\n",
      "bestIteration = 2427\n",
      "\n",
      "Shrink model to first 2428 iterations.\n",
      "  auc =  98.80593103868149\n",
      "============================================================\n",
      "(227616,) (113808,)\n",
      "Fold 1\n",
      "0:\tlearn: 7.1110609\ttest: 7.1110609\ttest1: 7.1076075\tbest: 7.1076075 (0)\ttotal: 31.7ms\tremaining: 5m 16s\n",
      "200:\tlearn: 1.0189467\ttest: 1.0189467\ttest1: 1.0210699\tbest: 1.0210699 (200)\ttotal: 6.4s\tremaining: 5m 12s\n",
      "400:\tlearn: 1.0057477\ttest: 1.0057477\ttest1: 1.0097422\tbest: 1.0097422 (400)\ttotal: 12.5s\tremaining: 4m 59s\n",
      "600:\tlearn: 0.9973958\ttest: 0.9973958\ttest1: 1.0028644\tbest: 1.0028644 (600)\ttotal: 18.7s\tremaining: 4m 52s\n",
      "800:\tlearn: 0.9914702\ttest: 0.9914702\ttest1: 0.9983306\tbest: 0.9983306 (800)\ttotal: 24.9s\tremaining: 4m 45s\n",
      "1000:\tlearn: 0.9872964\ttest: 0.9872964\ttest1: 0.9955084\tbest: 0.9955084 (1000)\ttotal: 31.1s\tremaining: 4m 39s\n",
      "1200:\tlearn: 0.9842590\ttest: 0.9842590\ttest1: 0.9938824\tbest: 0.9938824 (1200)\ttotal: 37.3s\tremaining: 4m 33s\n",
      "1400:\tlearn: 0.9816380\ttest: 0.9816380\ttest1: 0.9924363\tbest: 0.9924320 (1398)\ttotal: 43.6s\tremaining: 4m 27s\n",
      "1600:\tlearn: 0.9794547\ttest: 0.9794547\ttest1: 0.9915221\tbest: 0.9915221 (1600)\ttotal: 50s\tremaining: 4m 22s\n",
      "1800:\tlearn: 0.9775295\ttest: 0.9775295\ttest1: 0.9908846\tbest: 0.9908846 (1800)\ttotal: 57.1s\tremaining: 4m 19s\n",
      "2000:\tlearn: 0.9757515\ttest: 0.9757515\ttest1: 0.9903230\tbest: 0.9903208 (1996)\ttotal: 1m 3s\tremaining: 4m 12s\n",
      "2200:\tlearn: 0.9742005\ttest: 0.9742005\ttest1: 0.9898959\tbest: 0.9898818 (2168)\ttotal: 1m 9s\tremaining: 4m 5s\n",
      "2400:\tlearn: 0.9728313\ttest: 0.9728313\ttest1: 0.9896550\tbest: 0.9896520 (2397)\ttotal: 1m 15s\tremaining: 3m 58s\n",
      "2600:\tlearn: 0.9715913\ttest: 0.9715913\ttest1: 0.9894769\tbest: 0.9894713 (2597)\ttotal: 1m 21s\tremaining: 3m 53s\n",
      "2800:\tlearn: 0.9702650\ttest: 0.9702650\ttest1: 0.9891203\tbest: 0.9891203 (2800)\ttotal: 1m 27s\tremaining: 3m 43s\n",
      "3000:\tlearn: 0.9691323\ttest: 0.9691323\ttest1: 0.9888510\tbest: 0.9888468 (2999)\ttotal: 1m 32s\tremaining: 3m 35s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9887649269\n",
      "bestIteration = 3077\n",
      "\n",
      "Shrink model to first 3078 iterations.\n",
      "  auc =  98.87649254496156\n",
      "============================================================\n",
      "(227616,) (113808,)\n",
      "Fold 2\n",
      "0:\tlearn: 7.1102802\ttest: 7.1102802\ttest1: 7.1094043\tbest: 7.1094043 (0)\ttotal: 19.8ms\tremaining: 3m 17s\n",
      "200:\tlearn: 1.0178079\ttest: 1.0178079\ttest1: 1.0206242\tbest: 1.0206242 (200)\ttotal: 5.3s\tremaining: 4m 18s\n",
      "400:\tlearn: 1.0040467\ttest: 1.0040467\ttest1: 1.0081294\tbest: 1.0081294 (400)\ttotal: 11.3s\tremaining: 4m 31s\n",
      "600:\tlearn: 0.9964114\ttest: 0.9964114\ttest1: 1.0019758\tbest: 1.0019758 (600)\ttotal: 17.3s\tremaining: 4m 30s\n",
      "800:\tlearn: 0.9915294\ttest: 0.9915294\ttest1: 0.9984527\tbest: 0.9984527 (800)\ttotal: 23.1s\tremaining: 4m 25s\n",
      "1000:\tlearn: 0.9874123\ttest: 0.9874123\ttest1: 0.9956293\tbest: 0.9956293 (1000)\ttotal: 29s\tremaining: 4m 20s\n",
      "1200:\tlearn: 0.9843637\ttest: 0.9843637\ttest1: 0.9936438\tbest: 0.9936438 (1200)\ttotal: 34.7s\tremaining: 4m 14s\n",
      "1400:\tlearn: 0.9815983\ttest: 0.9815983\ttest1: 0.9919727\tbest: 0.9919727 (1400)\ttotal: 40.6s\tremaining: 4m 9s\n",
      "1600:\tlearn: 0.9795270\ttest: 0.9795270\ttest1: 0.9910646\tbest: 0.9910602 (1594)\ttotal: 46.4s\tremaining: 4m 3s\n",
      "1800:\tlearn: 0.9776755\ttest: 0.9776755\ttest1: 0.9903219\tbest: 0.9903194 (1798)\ttotal: 52.3s\tremaining: 3m 58s\n",
      "2000:\tlearn: 0.9759971\ttest: 0.9759971\ttest1: 0.9896849\tbest: 0.9896849 (2000)\ttotal: 58.1s\tremaining: 3m 52s\n",
      "2200:\tlearn: 0.9746167\ttest: 0.9746167\ttest1: 0.9893845\tbest: 0.9893745 (2189)\ttotal: 1m 3s\tremaining: 3m 46s\n",
      "2400:\tlearn: 0.9732578\ttest: 0.9732578\ttest1: 0.9890173\tbest: 0.9890134 (2370)\ttotal: 1m 9s\tremaining: 3m 40s\n",
      "2600:\tlearn: 0.9719481\ttest: 0.9719481\ttest1: 0.9886998\tbest: 0.9886998 (2600)\ttotal: 1m 15s\tremaining: 3m 35s\n",
      "2800:\tlearn: 0.9707770\ttest: 0.9707770\ttest1: 0.9884234\tbest: 0.9884219 (2796)\ttotal: 1m 21s\tremaining: 3m 29s\n",
      "3000:\tlearn: 0.9696502\ttest: 0.9696502\ttest1: 0.9882936\tbest: 0.9882849 (2970)\ttotal: 1m 27s\tremaining: 3m 23s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9882833501\n",
      "bestIteration = 3019\n",
      "\n",
      "Shrink model to first 3020 iterations.\n",
      "  auc =  98.82833502067156\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "clfs_cat, imp_cat, oof_cat, pred_cat = run_cv_cat(train_df1, target, test_df1, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_xgb_model(X_train, y_train, X_valid, y_valid, features, param, X_test, \n",
    "                    num_round):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_train, X_valid: training and valid data\n",
    "        y_train, y_valid: training and valid target\n",
    "        X_test: test-data\n",
    "        features: training features\n",
    "    Return:\n",
    "        oof-pred, test_preds, model, model_imp\n",
    "    \"\"\"\n",
    "    _train = xgb.DMatrix(X_train[features], label=y_train, feature_names=list(features))\n",
    "    _valid = xgb.DMatrix(X_valid[features], label=y_valid,feature_names=list(features))\n",
    "    \n",
    "    watchlist = [(_valid, 'valid')]\n",
    "    clf = xgb.train(dtrain=_train, \n",
    "                    num_boost_round=num_round, \n",
    "                    evals=watchlist,\n",
    "                    early_stopping_rounds=25, \n",
    "                    verbose_eval=200, \n",
    "                    params=param)\n",
    "    \n",
    "    valid_frame = xgb.DMatrix(X_valid[features],feature_names=list(features))\n",
    "    oof  = clf.predict(valid_frame, ntree_limit=clf.best_ntree_limit)\n",
    "\n",
    "\n",
    "    test_frame = xgb.DMatrix(X_test[features],feature_names=list(features))\n",
    "    test_pred = clf.predict(test_frame, ntree_limit=clf.best_ntree_limit)\n",
    "\n",
    "    \n",
    "    xgb_imp = pd.DataFrame(data=[list(clf.get_fscore().keys()), \n",
    "                                 list(clf.get_fscore().values())]).T\n",
    "    xgb_imp.columns = ['feature','imp']\n",
    "    xgb_imp.imp = xgb_imp.imp.astype('float')\n",
    "    \n",
    "    return oof, test_pred, clf, xgb_imp\n",
    "\n",
    "\n",
    "def run_cv_xgb(train_df, target, test_df, depth):\n",
    "\n",
    "    features = train_df.columns\n",
    "    params = {\n",
    "        'eval_metric'     : 'rmse',\n",
    "        'seed'            : 1337,\n",
    "        'eta'             : 0.05,\n",
    "        'subsample'       : 0.7,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'silent'          : 1,\n",
    "        'nthread'         : 4,\n",
    "#         'Scale_pos_weight': 3.607,\n",
    "#         'objective'       : 'reg:squarederror',\n",
    "        'max_depth'       : depth,\n",
    "        'alpha'           : 0.05\n",
    "    }\n",
    "    \n",
    "    n_splits = 3\n",
    "    random_seed = 1234\n",
    "    feature_imp = pd.DataFrame()\n",
    "    \n",
    "    folds = KFold(n_splits=n_splits, shuffle=True, random_state=random_seed)\n",
    "    oof_xgb = np.zeros(len(train_df))\n",
    "    predictions = np.zeros((len(test_df),n_splits))\n",
    "    clfs = []\n",
    "##########################\n",
    "    for fold_, (train_index, valid_index) in enumerate(folds.split(train_df, target)):\n",
    "        print(train_index.shape, valid_index.shape)\n",
    "        print(\"Fold {}\".format(fold_))\n",
    "    \n",
    "        y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "        X_train, X_valid = train_df.iloc[train_index,:], train_df.iloc[valid_index,:]\n",
    "        features = X_train.columns\n",
    "        \n",
    "\n",
    "        num_rounds = 10000\n",
    "        oof, test_pred, clf, xgb_imp = train_xgb_model(X_train, y_train, \n",
    "                                                       X_valid, y_valid, \n",
    "                                                       features, params, \n",
    "                                                       test_df, num_rounds)\n",
    "        \n",
    "        xgb_imp['fold'] = fold_\n",
    "        feature_imp = pd.concat([feature_imp, xgb_imp], axis=0)\n",
    "    \n",
    "        oof_xgb[valid_index] = oof\n",
    "        predictions[:,fold_] = test_pred\n",
    "        clfs.append(clf)\n",
    "        \n",
    "        score = mean_squared_error(y_valid, oof)\n",
    "        print( \"  auc = \", 100*np.sqrt(score) )\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    feature_imp.imp = feature_imp.imp.astype('float')\n",
    "    feature_imp = feature_imp.groupby(['feature'])['imp'].mean()\n",
    "    feature_imp = pd.DataFrame(data=[feature_imp.index, feature_imp.values]).T\n",
    "    feature_imp.columns=['feature','imp']\n",
    "    feature_imp = feature_imp.sort_values(by='imp')\n",
    "\n",
    "\n",
    "    return clfs, feature_imp, oof_xgb, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227616,) (113808,)\n",
      "Fold 0\n",
      "[0]\tvalid-rmse:6.94846\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "[200]\tvalid-rmse:1.02016\n",
      "[400]\tvalid-rmse:1.01442\n",
      "[600]\tvalid-rmse:1.01005\n",
      "[800]\tvalid-rmse:1.00453\n",
      "[1000]\tvalid-rmse:0.999952\n",
      "[1200]\tvalid-rmse:0.996541\n",
      "[1400]\tvalid-rmse:0.994686\n",
      "[1600]\tvalid-rmse:0.992758\n",
      "[1800]\tvalid-rmse:0.991263\n",
      "[2000]\tvalid-rmse:0.990132\n",
      "[2200]\tvalid-rmse:0.989238\n",
      "[2400]\tvalid-rmse:0.988517\n",
      "[2600]\tvalid-rmse:0.987852\n",
      "Stopping. Best iteration:\n",
      "[2596]\tvalid-rmse:0.987844\n",
      "\n",
      "  auc =  98.78438239224694\n",
      "============================================================\n",
      "(227616,) (113808,)\n",
      "Fold 1\n",
      "[0]\tvalid-rmse:6.94318\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "[200]\tvalid-rmse:1.02129\n",
      "[400]\tvalid-rmse:1.01675\n",
      "[600]\tvalid-rmse:1.01156\n",
      "[800]\tvalid-rmse:1.00631\n",
      "[1000]\tvalid-rmse:1.00209\n",
      "[1200]\tvalid-rmse:0.998696\n",
      "[1400]\tvalid-rmse:0.9965\n",
      "[1600]\tvalid-rmse:0.994389\n",
      "[1800]\tvalid-rmse:0.99262\n",
      "[2000]\tvalid-rmse:0.991479\n",
      "[2200]\tvalid-rmse:0.990637\n",
      "[2400]\tvalid-rmse:0.989865\n",
      "Stopping. Best iteration:\n",
      "[2461]\tvalid-rmse:0.989666\n",
      "\n",
      "  auc =  98.96655200822629\n",
      "============================================================\n",
      "(227616,) (113808,)\n",
      "Fold 2\n",
      "[0]\tvalid-rmse:6.94497\n",
      "Will train until valid-rmse hasn't improved in 25 rounds.\n",
      "[200]\tvalid-rmse:1.0221\n",
      "[400]\tvalid-rmse:1.0174\n",
      "[600]\tvalid-rmse:1.01219\n",
      "[800]\tvalid-rmse:1.00663\n",
      "[1000]\tvalid-rmse:1.00233\n",
      "[1200]\tvalid-rmse:0.998127\n",
      "[1400]\tvalid-rmse:0.996168\n",
      "[1600]\tvalid-rmse:0.99423\n",
      "[1800]\tvalid-rmse:0.992731\n",
      "[2000]\tvalid-rmse:0.991304\n",
      "[2200]\tvalid-rmse:0.990327\n",
      "[2400]\tvalid-rmse:0.989608\n",
      "[2600]\tvalid-rmse:0.98916\n",
      "Stopping. Best iteration:\n",
      "[2578]\tvalid-rmse:0.989159\n",
      "\n",
      "  auc =  98.91587490762562\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "clfs_xgb, imp_xgb, oof_xgb, pred_xgb = run_cv_xgb(train_df1, target, test_df1, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7f43b8b77e10>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.pairplot(train_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
