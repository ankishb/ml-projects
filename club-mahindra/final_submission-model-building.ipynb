{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os, gc\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "sns.set(context='notebook', style='whitegrid', palette='deep', font='sans-serif', \n",
    "        font_scale=2, color_codes=True, rc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((488189, 62), (146765, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test = pd.read_csv('data/train_test.csv')\n",
    "sub_df = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "train_test.shape, sub_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((341424,), (341424,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = 341424\n",
    "\n",
    "target = train_test.amount_spent_per_room_night_scaled\n",
    "memberids = train_test.memberid\n",
    "target = target[:train_len]\n",
    "memberids = memberids[:train_len]\n",
    "\n",
    "target.shape, memberids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((273139,), (68285,), (273139,), (68285,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "group_kfold1 = GroupKFold(n_splits=5)\n",
    "for train_index, test_index in group_kfold1.split(train_test.iloc[:train_len], target, memberids):\n",
    "    break\n",
    "\n",
    "y_tr, y_val = target[train_index], target[test_index]\n",
    "        \n",
    "train_index.shape, test_index.shape, y_tr.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def model_lgb(X_train, y_train, X_valid, y_valid, test, features):\n",
    "    print(X_train.shape) \n",
    "    def train_lgb_model(f_frac, b_frac, \n",
    "                        l1, l2, split_gain,\n",
    "                        leaves, data_in_leaf, hessian):\n",
    "    \n",
    "        param = {}\n",
    "\n",
    "        param['feature_fraction'] = max(min(f_frac, 1), 0)\n",
    "        param['bagging_fraction'] = max(min(b_frac, 1), 0)\n",
    "\n",
    "        param['lambda_l1'] = max(l1, 0)\n",
    "        param['lambda_l2'] = max(l2, 0)\n",
    "        param['min_split_gain'] = split_gain\n",
    "#     #     params['min_child_weight'] = min_child_weight\n",
    "\n",
    "        param['num_leaves'] = int(leaves)\n",
    "        param['min_data_in_leaf'] = int(data_in_leaf)\n",
    "        param['min_sum_hessian_in_leaf'] = max(hessian, 0)\n",
    "\n",
    "        param_const = {\n",
    "            'max_bins'               : 63,\n",
    "            'learning_rate'          : 0.01,\n",
    "            'num_threads'            : 4,\n",
    "            'metric'                 : 'rmse',\n",
    "            'boost'                  : 'gbdt',\n",
    "            'tree_learner'           : 'serial',\n",
    "            'objective'              : 'root_mean_squared_error',\n",
    "            'verbosity'              : 1,\n",
    "        }\n",
    "\n",
    "        for key, item in param_const.items():\n",
    "            param[key] = item\n",
    "    \n",
    "#         print(param)\n",
    "\n",
    "        _train = lgb.Dataset(X_train[features], label=y_train, feature_name=list(features))\n",
    "        _valid = lgb.Dataset(X_valid[features], label=y_valid,feature_name=list(features))\n",
    "\n",
    "        clf = lgb.train(param, _train, 10000, \n",
    "                        valid_sets = [_train, _valid], \n",
    "                        verbose_eval=200, \n",
    "                        early_stopping_rounds = 25)                  \n",
    "\n",
    "        oof = clf.predict(X_valid[features], num_iteration=clf.best_iteration)\n",
    "        score = mean_squared_error(y_valid, oof)\n",
    "        print(\"rmse: \", np.sqrt(score)*100)\n",
    "        \n",
    "        pred = clf.predict(test[features], num_iteration=clf.best_iteration)\n",
    "        \n",
    "        return clf, oof, pred\n",
    "\n",
    "    clf, oof, pred = train_lgb_model(**{\n",
    "        'b_frac'       : 0.3677516358370858,\n",
    "        'data_in_leaf' : 495.44417416221626,\n",
    "        'f_frac'       : 0.5422060360159515,\n",
    "        'hessian'      : 5.039378213231793,\n",
    "        'l1'           : 1.0642598045225304,\n",
    "        'l2'           : 2.564544963055539,\n",
    "        'leaves'       : 89.62655396835916,\n",
    "        'split_gain'   : 0.16542750189034394\n",
    "    })\n",
    "    \n",
    "    return clf, oof, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def model_cat(X_train, y_train, X_valid, y_valid, test, features):\n",
    "    print(X_train.shape)\n",
    "    def train_cat_model(r_str, b_temp, l2, depth):\n",
    "    \n",
    "        params = {}\n",
    "        params['random_strength']     = max(min(r_str, 1), 0)\n",
    "        params['bagging_temperature'] = max(b_temp, 0)\n",
    "        params['l2_leaf_reg'] = max(l2, 0)\n",
    "        params['depth']     = int(depth)\n",
    "\n",
    "        param_const = {\n",
    "            'border_count'          : 63,\n",
    "            'early_stopping_rounds' : 50,\n",
    "            'random_seed'           : 1337,\n",
    "            'task_type'             : 'CPU', \n",
    "            'loss_function'         : \"RMSE\", \n",
    "    #         'subsample'             = 0.7, \n",
    "            'iterations'            : 10000, \n",
    "            'learning_rate'         : 0.01,\n",
    "            'thread_count'          : 4,\n",
    "#             'bootstrap_type'        : 'No'\n",
    "        }\n",
    "\n",
    "        for key, item in param_const.items():\n",
    "            params[key] = item\n",
    "    \n",
    "        \n",
    "\n",
    "        _train = Pool(X_train[features], label=y_train)#, cat_features=cate_features_index)\n",
    "        _valid = Pool(X_valid[features], label=y_valid)#, cat_features=cate_features_index)\n",
    "\n",
    "        watchlist = [_train, _valid]\n",
    "        clf = CatBoostRegressor(**params)\n",
    "        clf.fit(_train, \n",
    "                eval_set=watchlist, \n",
    "                verbose=500,\n",
    "                use_best_model=True)\n",
    "\n",
    "        oof  = clf.predict(X_valid[features])\n",
    "        score = mean_squared_error(y_valid, oof)\n",
    "        print(\"rmse: \", np.sqrt(score)*100)\n",
    "        \n",
    "        pred = clf.predict(test[features])\n",
    "        \n",
    "        return clf, oof, pred\n",
    "\n",
    "    clf, oof, pred = train_cat_model(**{\n",
    "        'b_temp': 0.08307474720468191,\n",
    "        'depth' : 7.596402546589758,\n",
    "        'l2'    : 3.9791105400066655,\n",
    "        'r_str' : 1.1206250787323229\n",
    "    })\n",
    "    \n",
    "    return clf, oof, pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop= ['res_staResidence_median','tr_flag','reservationstatusid_code',\n",
    "               'res_resortType_median','res_stResort_median','res_cluster_median']\n",
    "train_test.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "for col in train_test.columns:\n",
    "    if col != 'amount_spent_per_room_night_scaled':\n",
    "        train_test[col] = train_test[col].astype('category').cat.codes\n",
    "        \n",
    "train_test.drop('amount_spent_per_room_night_scaled', axis=1, inplace=True)\n",
    "train_test.drop(['booking_date','checkin_date','checkout_date','memberid'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((273139, 51), (68285, 51), (146765, 51))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ = train_test.iloc[train_index]\n",
    "valid_ = train_test.iloc[test_index]\n",
    "test_df = train_test.iloc[train_len:].reset_index(drop=True)\n",
    "\n",
    "train_.shape, valid_.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(273139, 51)\n",
      "Training until validation scores don't improve for 25 rounds.\n",
      "[200]\ttraining's rmse: 0.988628\tvalid_1's rmse: 0.993064\n",
      "[400]\ttraining's rmse: 0.970306\tvalid_1's rmse: 0.979044\n",
      "[600]\ttraining's rmse: 0.962145\tvalid_1's rmse: 0.974981\n",
      "[800]\ttraining's rmse: 0.956503\tvalid_1's rmse: 0.973268\n",
      "[1000]\ttraining's rmse: 0.951924\tvalid_1's rmse: 0.972372\n",
      "[1200]\ttraining's rmse: 0.948081\tvalid_1's rmse: 0.971955\n",
      "[1400]\ttraining's rmse: 0.944721\tvalid_1's rmse: 0.971741\n",
      "Early stopping, best iteration is:\n",
      "[1547]\ttraining's rmse: 0.94235\tvalid_1's rmse: 0.971603\n",
      "rmse:  97.16025150314397\n"
     ]
    }
   ],
   "source": [
    "clf1, oof1, pred1 = model_lgb(train_, y_tr, valid_, y_val, test_df, train_.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(273139, 51)\n",
      "0:\tlearn: 7.7196219\ttest: 7.7196219\ttest1: 7.7263838\tbest: 7.7263838 (0)\ttotal: 86.8ms\tremaining: 14m 28s\n",
      "500:\tlearn: 0.9884650\ttest: 0.9884650\ttest1: 0.9912968\tbest: 0.9912968 (500)\ttotal: 25.2s\tremaining: 7m 58s\n",
      "1000:\tlearn: 0.9742311\ttest: 0.9742311\ttest1: 0.9790774\tbest: 0.9790774 (1000)\ttotal: 50.4s\tremaining: 7m 32s\n",
      "1500:\tlearn: 0.9686144\ttest: 0.9686144\ttest1: 0.9758477\tbest: 0.9758477 (1500)\ttotal: 1m 18s\tremaining: 7m 24s\n",
      "2000:\tlearn: 0.9644463\ttest: 0.9644463\ttest1: 0.9742194\tbest: 0.9742194 (2000)\ttotal: 1m 42s\tremaining: 6m 49s\n",
      "2500:\tlearn: 0.9608381\ttest: 0.9608381\ttest1: 0.9733244\tbest: 0.9733244 (2500)\ttotal: 2m 7s\tremaining: 6m 20s\n",
      "3000:\tlearn: 0.9575685\ttest: 0.9575685\ttest1: 0.9727127\tbest: 0.9727127 (3000)\ttotal: 2m 31s\tremaining: 5m 53s\n",
      "3500:\tlearn: 0.9546080\ttest: 0.9546080\ttest1: 0.9723188\tbest: 0.9723186 (3499)\ttotal: 2m 55s\tremaining: 5m 25s\n",
      "4000:\tlearn: 0.9518666\ttest: 0.9518666\ttest1: 0.9720984\tbest: 0.9720984 (4000)\ttotal: 3m 19s\tremaining: 4m 58s\n",
      "4500:\tlearn: 0.9491678\ttest: 0.9491678\ttest1: 0.9719100\tbest: 0.9719100 (4500)\ttotal: 3m 44s\tremaining: 4m 33s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9718607053\n",
      "bestIteration = 4597\n",
      "\n",
      "Shrink model to first 4598 iterations.\n",
      "rmse:  97.18607038500815\n"
     ]
    }
   ],
   "source": [
    "clf2, oof2, pred2 = model_cat(train_, y_tr, valid_, y_val, test_df, train_.columns)\n",
    "# rmse:  97.10604730539535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 97.11157945200361\n",
      "================\n",
      "Saved Prediction\n",
      "================\n"
     ]
    }
   ],
   "source": [
    "pred_all = np.column_stack([pred1, pred2])\n",
    "oof_all  = np.column_stack([oof1, oof2])\n",
    "\n",
    "pred_all = pd.DataFrame(data=pred_all, columns=['pred1','pred2'])\n",
    "oof_all = pd.DataFrame(data=oof_all, columns=['oof1','oof2'])\n",
    "\n",
    "print(\"Combined\", 100*np.sqrt(mean_squared_error(oof_all.mean(axis=1), y_val)))\n",
    "\n",
    "sub_df_combine = sub_df.copy()\n",
    "sub_df_combine.amount_spent_per_room_night_scaled = pred_all.mean(axis=1)\n",
    "\n",
    "sub_df_combine.to_csv('final_submissions.csv',index=None)\n",
    "\n",
    "\n",
    "print(\"================\")\n",
    "print(\"Saved Prediction\")\n",
    "print(\"================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
